[2019-02-07 11:27:42] [marian] Marian v1.7.7 45d3ce8 2019-02-03 11:18:10 +0000
[2019-02-07 11:27:42] [marian] Running on gpu-e-2 as process 87031 with command line:
[2019-02-07 11:27:42] [marian] /home/cs-grun1/marian/marian-dev/build-176fix/marian --model ./model.npz --type transformer --train-sets /home/cs-grun1/wmt19/data/corpus00.uniq.clean.nrm.csen.en.gz /home/cs-grun1/wmt19/data/corpus00.uniq.clean.nrm.csen.cs.gz --shuffle-in-ram --vocabs ./vocab.encs.spm ./vocab.encs.spm --dim-vocabs 32000 32000 --max-length 120 --mini-batch-fit -w 10000 --mini-batch 1000 --maxi-batch 1000 --devices 0 1 2 3 --sync-sgd --layer-normalization --tied-embeddings-all --exponential-smoothing --transformer-dropout 0.1 --label-smoothing 0.1 --transformer-preprocess n --transformer-postprocess da --transformer-heads 8 --enc-depth 6 --dec-depth 6 --learn-rate 0.0003 --lr-report --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --valid-freq 5000 --save-freq 5000 --disp-freq 1000 --disp-first 10 --valid-metrics ce-mean-words bleu-detok --valid-translation-output ./devset.bpe.cs.output --quiet-translation --valid-sets /home/cs-grun1/wmt19/data/newstest2016.en /home/cs-grun1/wmt19/data/newstest2016.cs --valid-mini-batch 32 --beam-size 8 --normalize 1 --early-stopping 5 --overwrite --keep-best --log ./train.log --valid-log ./valid.log
[2019-02-07 11:27:42] [config] after-batches: 0
[2019-02-07 11:27:42] [config] after-epochs: 0
[2019-02-07 11:27:42] [config] allow-unk: false
[2019-02-07 11:27:42] [config] beam-size: 8
[2019-02-07 11:27:42] [config] bert-class-symbol: "[CLS]"
[2019-02-07 11:27:42] [config] bert-mask-symbol: "[MASK]"
[2019-02-07 11:27:42] [config] bert-masking-fraction: 0.15
[2019-02-07 11:27:42] [config] bert-sep-symbol: "[SEP]"
[2019-02-07 11:27:42] [config] best-deep: false
[2019-02-07 11:27:42] [config] clip-gemm: 0
[2019-02-07 11:27:42] [config] clip-norm: 5
[2019-02-07 11:27:42] [config] cost-type: ce-mean
[2019-02-07 11:27:42] [config] cpu-threads: 0
[2019-02-07 11:27:42] [config] data-weighting: ""
[2019-02-07 11:27:42] [config] data-weighting-type: sentence
[2019-02-07 11:27:42] [config] dec-cell: gru
[2019-02-07 11:27:42] [config] dec-cell-base-depth: 2
[2019-02-07 11:27:42] [config] dec-cell-high-depth: 1
[2019-02-07 11:27:42] [config] dec-depth: 6
[2019-02-07 11:27:42] [config] devices:
[2019-02-07 11:27:42] [config]   - 0
[2019-02-07 11:27:42] [config]   - 1
[2019-02-07 11:27:42] [config]   - 2
[2019-02-07 11:27:42] [config]   - 3
[2019-02-07 11:27:42] [config] dim-emb: 512
[2019-02-07 11:27:42] [config] dim-rnn: 1024
[2019-02-07 11:27:42] [config] dim-vocabs:
[2019-02-07 11:27:42] [config]   - 32000
[2019-02-07 11:27:42] [config]   - 32000
[2019-02-07 11:27:42] [config] disp-first: 10
[2019-02-07 11:27:42] [config] disp-freq: 1000
[2019-02-07 11:27:42] [config] disp-label-counts: false
[2019-02-07 11:27:42] [config] dropout-rnn: 0
[2019-02-07 11:27:42] [config] dropout-src: 0
[2019-02-07 11:27:42] [config] dropout-trg: 0
[2019-02-07 11:27:42] [config] dump-config: ""
[2019-02-07 11:27:42] [config] early-stopping: 5
[2019-02-07 11:27:42] [config] embedding-fix-src: false
[2019-02-07 11:27:42] [config] embedding-fix-trg: false
[2019-02-07 11:27:42] [config] embedding-normalization: false
[2019-02-07 11:27:42] [config] embedding-vectors:
[2019-02-07 11:27:42] [config]   []
[2019-02-07 11:27:42] [config] enc-cell: gru
[2019-02-07 11:27:42] [config] enc-cell-depth: 1
[2019-02-07 11:27:42] [config] enc-depth: 6
[2019-02-07 11:27:42] [config] enc-type: bidirectional
[2019-02-07 11:27:42] [config] exponential-smoothing: 0.0001
[2019-02-07 11:27:42] [config] grad-dropping-momentum: 0
[2019-02-07 11:27:42] [config] grad-dropping-rate: 0
[2019-02-07 11:27:42] [config] grad-dropping-warmup: 100
[2019-02-07 11:27:42] [config] guided-alignment: none
[2019-02-07 11:27:42] [config] guided-alignment-cost: mse
[2019-02-07 11:27:42] [config] guided-alignment-weight: 0.1
[2019-02-07 11:27:42] [config] ignore-model-config: false
[2019-02-07 11:27:42] [config] input-types:
[2019-02-07 11:27:42] [config]   []
[2019-02-07 11:27:42] [config] interpolate-env-vars: false
[2019-02-07 11:27:42] [config] keep-best: true
[2019-02-07 11:27:42] [config] label-smoothing: 0.1
[2019-02-07 11:27:42] [config] layer-normalization: true
[2019-02-07 11:27:42] [config] learn-rate: 0.0003
[2019-02-07 11:27:42] [config] log: ./train.log
[2019-02-07 11:27:42] [config] log-level: info
[2019-02-07 11:27:42] [config] log-time-zone: ""
[2019-02-07 11:27:42] [config] lr-decay: 0
[2019-02-07 11:27:42] [config] lr-decay-freq: 50000
[2019-02-07 11:27:42] [config] lr-decay-inv-sqrt:
[2019-02-07 11:27:42] [config]   - 16000
[2019-02-07 11:27:42] [config] lr-decay-repeat-warmup: false
[2019-02-07 11:27:42] [config] lr-decay-reset-optimizer: false
[2019-02-07 11:27:42] [config] lr-decay-start:
[2019-02-07 11:27:42] [config]   - 10
[2019-02-07 11:27:42] [config]   - 1
[2019-02-07 11:27:42] [config] lr-decay-strategy: epoch+stalled
[2019-02-07 11:27:42] [config] lr-report: true
[2019-02-07 11:27:42] [config] lr-warmup: 16000
[2019-02-07 11:27:42] [config] lr-warmup-at-reload: false
[2019-02-07 11:27:42] [config] lr-warmup-cycle: false
[2019-02-07 11:27:42] [config] lr-warmup-start-rate: 0
[2019-02-07 11:27:42] [config] max-length: 120
[2019-02-07 11:27:42] [config] max-length-crop: false
[2019-02-07 11:27:42] [config] max-length-factor: 3
[2019-02-07 11:27:42] [config] maxi-batch: 1000
[2019-02-07 11:27:42] [config] maxi-batch-sort: trg
[2019-02-07 11:27:42] [config] mini-batch: 1000
[2019-02-07 11:27:42] [config] mini-batch-fit: true
[2019-02-07 11:27:42] [config] mini-batch-fit-step: 10
[2019-02-07 11:27:42] [config] mini-batch-overstuff: 1
[2019-02-07 11:27:42] [config] mini-batch-track-lr: false
[2019-02-07 11:27:42] [config] mini-batch-understuff: 1
[2019-02-07 11:27:42] [config] mini-batch-warmup: 0
[2019-02-07 11:27:42] [config] mini-batch-words: 0
[2019-02-07 11:27:42] [config] mini-batch-words-ref: 0
[2019-02-07 11:27:42] [config] model: ./model.npz
[2019-02-07 11:27:42] [config] multi-loss-type: sum
[2019-02-07 11:27:42] [config] multi-node: false
[2019-02-07 11:27:42] [config] multi-node-overlap: true
[2019-02-07 11:27:42] [config] n-best: false
[2019-02-07 11:27:42] [config] no-nccl: false
[2019-02-07 11:27:42] [config] no-reload: false
[2019-02-07 11:27:42] [config] no-restore-corpus: false
[2019-02-07 11:27:42] [config] no-shuffle: false
[2019-02-07 11:27:42] [config] normalize: 1
[2019-02-07 11:27:42] [config] num-devices: 0
[2019-02-07 11:27:42] [config] optimizer: adam
[2019-02-07 11:27:42] [config] optimizer-delay: 1
[2019-02-07 11:27:42] [config] optimizer-params:
[2019-02-07 11:27:42] [config]   - 0.9
[2019-02-07 11:27:42] [config]   - 0.98
[2019-02-07 11:27:42] [config]   - 1e-09
[2019-02-07 11:27:42] [config] overwrite: true
[2019-02-07 11:27:42] [config] pretrained-model: ""
[2019-02-07 11:27:42] [config] quiet: false
[2019-02-07 11:27:42] [config] quiet-translation: true
[2019-02-07 11:27:42] [config] relative-paths: false
[2019-02-07 11:27:42] [config] right-left: false
[2019-02-07 11:27:42] [config] save-freq: 5000
[2019-02-07 11:27:42] [config] seed: 0
[2019-02-07 11:27:42] [config] sentencepiece-alphas:
[2019-02-07 11:27:42] [config]   []
[2019-02-07 11:27:42] [config] sentencepiece-max-lines: 10000000
[2019-02-07 11:27:42] [config] sentencepiece-options: ""
[2019-02-07 11:27:42] [config] shuffle-in-ram: true
[2019-02-07 11:27:42] [config] skip: false
[2019-02-07 11:27:42] [config] sqlite: ""
[2019-02-07 11:27:42] [config] sqlite-drop: false
[2019-02-07 11:27:42] [config] sync-sgd: true
[2019-02-07 11:27:42] [config] tempdir: /tmp
[2019-02-07 11:27:42] [config] tied-embeddings: false
[2019-02-07 11:27:42] [config] tied-embeddings-all: true
[2019-02-07 11:27:42] [config] tied-embeddings-src: false
[2019-02-07 11:27:42] [config] train-sets:
[2019-02-07 11:27:42] [config]   - /home/cs-grun1/wmt19/data/corpus00.uniq.clean.nrm.csen.en.gz
[2019-02-07 11:27:42] [config]   - /home/cs-grun1/wmt19/data/corpus00.uniq.clean.nrm.csen.cs.gz
[2019-02-07 11:27:42] [config] transformer-aan-activation: swish
[2019-02-07 11:27:42] [config] transformer-aan-depth: 2
[2019-02-07 11:27:42] [config] transformer-aan-nogate: false
[2019-02-07 11:27:42] [config] transformer-decoder-autoreg: self-attention
[2019-02-07 11:27:42] [config] transformer-dim-aan: 2048
[2019-02-07 11:27:42] [config] transformer-dim-ffn: 2048
[2019-02-07 11:27:42] [config] transformer-dropout: 0.1
[2019-02-07 11:27:42] [config] transformer-dropout-attention: 0
[2019-02-07 11:27:42] [config] transformer-dropout-ffn: 0
[2019-02-07 11:27:42] [config] transformer-ffn-activation: swish
[2019-02-07 11:27:42] [config] transformer-ffn-depth: 2
[2019-02-07 11:27:42] [config] transformer-guided-alignment-layer: last
[2019-02-07 11:27:42] [config] transformer-heads: 8
[2019-02-07 11:27:42] [config] transformer-no-projection: false
[2019-02-07 11:27:42] [config] transformer-postprocess: da
[2019-02-07 11:27:42] [config] transformer-postprocess-emb: d
[2019-02-07 11:27:42] [config] transformer-preprocess: n
[2019-02-07 11:27:42] [config] transformer-tied-layers:
[2019-02-07 11:27:42] [config]   []
[2019-02-07 11:27:42] [config] transformer-train-positions: false
[2019-02-07 11:27:42] [config] type: transformer
[2019-02-07 11:27:42] [config] ulr: false
[2019-02-07 11:27:42] [config] ulr-dim-emb: 0
[2019-02-07 11:27:42] [config] ulr-dropout: 0
[2019-02-07 11:27:42] [config] ulr-keys-vectors: ""
[2019-02-07 11:27:42] [config] ulr-query-vectors: ""
[2019-02-07 11:27:42] [config] ulr-softmax-temperature: 1
[2019-02-07 11:27:42] [config] ulr-trainable-transformation: false
[2019-02-07 11:27:42] [config] valid-freq: 5000
[2019-02-07 11:27:42] [config] valid-log: ./valid.log
[2019-02-07 11:27:42] [config] valid-max-length: 1000
[2019-02-07 11:27:42] [config] valid-metrics:
[2019-02-07 11:27:42] [config]   - ce-mean-words
[2019-02-07 11:27:42] [config]   - bleu-detok
[2019-02-07 11:27:42] [config] valid-mini-batch: 32
[2019-02-07 11:27:42] [config] valid-script-path: ""
[2019-02-07 11:27:42] [config] valid-sets:
[2019-02-07 11:27:42] [config]   - /home/cs-grun1/wmt19/data/newstest2016.en
[2019-02-07 11:27:42] [config]   - /home/cs-grun1/wmt19/data/newstest2016.cs
[2019-02-07 11:27:42] [config] valid-translation-output: ./devset.bpe.cs.output
[2019-02-07 11:27:42] [config] vocabs:
[2019-02-07 11:27:42] [config]   - ./vocab.encs.spm
[2019-02-07 11:27:42] [config]   - ./vocab.encs.spm
[2019-02-07 11:27:42] [config] word-penalty: 0
[2019-02-07 11:27:42] [config] workspace: 10000
[2019-02-07 11:27:42] [config] Model is being created with Marian v1.7.7 45d3ce8 2019-02-03 11:18:10 +0000
[2019-02-07 11:27:42] Using synchronous training
[2019-02-07 11:27:42] [SentencePiece] Training SentencePiece vocabulary ./vocab.encs.spm
[2019-02-07 11:27:42] [SentencePiece] Creating temporary file /tmp/marian.nZVCVK 
[2019-02-07 11:27:42] [SentencePiece] Sampling at most 10000000 lines from /home/cs-grun1/wmt19/data/corpus00.uniq.clean.nrm.csen.cs.gz, /home/cs-grun1/wmt19/data/corpus00.uniq.clean.nrm.csen.en.gz
[2019-02-07 11:28:32] [SentencePiece] Selected 10000000 lines
[2019-02-07 11:33:25] [SentencePiece] Removing ./vocab.encs.spm.vocab
[2019-02-07 11:33:25] [SentencePiece] Renaming ./vocab.encs.spm.model to ./vocab.encs.spm
[2019-02-07 11:33:25] [data] Loading SentencePiece vocabulary from file ./vocab.encs.spm
[2019-02-07 11:33:25] [data] Setting vocabulary size for input 0 to 32000
[2019-02-07 11:33:25] [data] Loading SentencePiece vocabulary from file ./vocab.encs.spm
[2019-02-07 11:33:25] [data] Setting vocabulary size for input 1 to 32000
[2019-02-07 11:33:25] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-02-07 11:33:25] [batching] Collecting statistics for batch fitting with step size 10
[2019-02-07 11:33:26] [memory] Extending reserved space to 10112 MB (device gpu0)
[2019-02-07 11:33:27] [memory] Extending reserved space to 10112 MB (device gpu1)
[2019-02-07 11:33:27] [memory] Extending reserved space to 10112 MB (device gpu2)
[2019-02-07 11:33:27] [memory] Extending reserved space to 10112 MB (device gpu3)
[2019-02-07 11:33:28] [comm] Using NCCL 2.3.7 for GPU communication
[2019-02-07 11:33:28] [comm] NCCLCommunicator constructed successfully.
[2019-02-07 11:33:28] [training] Using 4 GPUs
[2019-02-07 11:33:28] [memory] Reserving 230 MB, device gpu0
[2019-02-07 11:33:28] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-02-07 11:33:28] [memory] Reserving 230 MB, device gpu0
[2019-02-07 11:33:49] [batching] Done. Typical MB size is 27396 target words
[2019-02-07 11:33:49] [memory] Extending reserved space to 10112 MB (device gpu0)
[2019-02-07 11:33:49] [memory] Extending reserved space to 10112 MB (device gpu1)
[2019-02-07 11:33:49] [memory] Extending reserved space to 10112 MB (device gpu2)
[2019-02-07 11:33:49] [memory] Extending reserved space to 10112 MB (device gpu3)
[2019-02-07 11:33:49] [comm] Using NCCL 2.3.7 for GPU communication
[2019-02-07 11:33:49] [comm] NCCLCommunicator constructed successfully.
[2019-02-07 11:33:49] [training] Using 4 GPUs
[2019-02-07 11:33:49] Training started
[2019-02-07 11:33:49] [data] Shuffling data
[2019-02-07 11:34:27] [data] Done reading 39221657 sentences
[2019-02-07 11:34:29] [data] Done shuffling 39221657 sentences (cached in RAM)
[2019-02-07 11:35:47] [training] Batches are processed as 1 process(es) x 4 devices/process
[2019-02-07 11:35:47] [memory] Reserving 230 MB, device gpu2
[2019-02-07 11:35:47] [memory] Reserving 230 MB, device gpu1
[2019-02-07 11:35:47] [memory] Reserving 230 MB, device gpu3
[2019-02-07 11:35:47] [memory] Reserving 230 MB, device gpu0
[2019-02-07 11:35:48] [memory] Reserving 230 MB, device gpu2
[2019-02-07 11:35:48] [memory] Reserving 230 MB, device gpu1
[2019-02-07 11:35:48] [memory] Reserving 230 MB, device gpu0
[2019-02-07 11:35:48] [memory] Reserving 230 MB, device gpu3
[2019-02-07 11:35:48] [memory] Reserving 57 MB, device gpu0
[2019-02-07 11:35:48] [memory] Reserving 57 MB, device gpu1
[2019-02-07 11:35:48] [memory] Reserving 57 MB, device gpu2
[2019-02-07 11:35:48] [memory] Reserving 57 MB, device gpu3
[2019-02-07 11:35:48] [memory] Reserving 115 MB, device gpu0
[2019-02-07 11:35:48] [memory] Reserving 115 MB, device gpu2
[2019-02-07 11:35:48] [memory] Reserving 115 MB, device gpu3
[2019-02-07 11:35:48] [memory] Reserving 115 MB, device gpu1
[2019-02-07 11:35:48] Ep. 1 : Up. 1 : Sen. 1,008 : Cost 6892.25244141 : Time 143.55s : 196.61 words/s : L.r. 1.8750e-08
[2019-02-07 11:35:49] Ep. 1 : Up. 2 : Sen. 4,112 : Cost 2915.27734375 : Time 0.66s : 47110.49 words/s : L.r. 3.7500e-08
[2019-02-07 11:35:49] Ep. 1 : Up. 3 : Sen. 5,120 : Cost 5856.33056641 : Time 0.49s : 46906.95 words/s : L.r. 5.6250e-08
[2019-02-07 11:35:50] Ep. 1 : Up. 4 : Sen. 8,224 : Cost 1990.48327637 : Time 0.44s : 42800.12 words/s : L.r. 7.5000e-08
[2019-02-07 11:35:50] Ep. 1 : Up. 5 : Sen. 8,444 : Cost 14086.73339844 : Time 0.41s : 35568.69 words/s : L.r. 9.3750e-08
[2019-02-07 11:35:51] Ep. 1 : Up. 6 : Sen. 11,548 : Cost 2153.84765625 : Time 0.51s : 42477.56 words/s : L.r. 1.1250e-07
[2019-02-07 11:35:51] Ep. 1 : Up. 7 : Sen. 13,076 : Cost 4451.68212891 : Time 0.51s : 48110.15 words/s : L.r. 1.3125e-07
[2019-02-07 11:35:52] Ep. 1 : Up. 8 : Sen. 14,084 : Cost 6030.18652344 : Time 0.47s : 49741.27 words/s : L.r. 1.5000e-07
[2019-02-07 11:35:52] Ep. 1 : Up. 9 : Sen. 15,612 : Cost 2952.72680664 : Time 0.45s : 37461.40 words/s : L.r. 1.6875e-07
[2019-02-07 11:35:53] Ep. 1 : Up. 10 : Sen. 16,914 : Cost 5411.80761719 : Time 0.47s : 52479.92 words/s : L.r. 1.8750e-07
[2019-02-07 11:43:25] Ep. 1 : Up. 1000 : Sen. 1,261,374 : Cost 912.71868896 : Time 452.61s : 44173.15 words/s : L.r. 1.8750e-05
[2019-02-07 11:51:06] Ep. 1 : Up. 2000 : Sen. 2,513,700 : Cost 123.13861847 : Time 460.53s : 44260.12 words/s : L.r. 3.7500e-05
[2019-02-07 11:58:43] Ep. 1 : Up. 3000 : Sen. 3,788,597 : Cost 106.27693176 : Time 457.18s : 44077.48 words/s : L.r. 5.6250e-05
[2019-02-07 12:06:20] Ep. 1 : Up. 4000 : Sen. 5,041,876 : Cost 99.56932068 : Time 456.43s : 44175.48 words/s : L.r. 7.5000e-05
[2019-02-07 12:13:58] Ep. 1 : Up. 5000 : Sen. 6,292,503 : Cost 92.52824402 : Time 458.32s : 44281.25 words/s : L.r. 9.3750e-05
[2019-02-07 12:13:58] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-07 12:13:59] Saving model weights and runtime parameters to ./model.npz
[2019-02-07 12:14:01] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-07 12:14:05] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-07 12:14:06] [valid] Ep. 1 : Up. 5000 : ce-mean-words : 5.50886 : new best
[2019-02-07 12:15:19] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-07 12:15:20] [valid] Ep. 1 : Up. 5000 : bleu-detok : 2.22744 : new best
[2019-02-07 12:22:58] Ep. 1 : Up. 6000 : Sen. 7,551,678 : Cost 84.48239136 : Time 539.98s : 37370.84 words/s : L.r. 1.1250e-04
[2019-02-07 12:30:35] Ep. 1 : Up. 7000 : Sen. 8,812,697 : Cost 78.92108154 : Time 456.69s : 44239.64 words/s : L.r. 1.3125e-04
[2019-02-07 12:38:13] Ep. 1 : Up. 8000 : Sen. 10,075,017 : Cost 74.08708191 : Time 458.17s : 44257.49 words/s : L.r. 1.5000e-04
[2019-02-07 12:45:51] Ep. 1 : Up. 9000 : Sen. 11,353,374 : Cost 68.55920410 : Time 457.86s : 44158.44 words/s : L.r. 1.6875e-04
[2019-02-07 12:53:27] Ep. 1 : Up. 10000 : Sen. 12,596,268 : Cost 67.01595306 : Time 456.26s : 44200.74 words/s : L.r. 1.8750e-04
[2019-02-07 12:53:27] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-07 12:53:28] Saving model weights and runtime parameters to ./model.npz
[2019-02-07 12:53:30] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-07 12:53:34] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-07 12:53:35] [valid] Ep. 1 : Up. 10000 : ce-mean-words : 3.23586 : new best
[2019-02-07 12:54:11] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-07 12:54:13] [valid] Ep. 1 : Up. 10000 : bleu-detok : 11.7509 : new best
[2019-02-07 13:01:52] Ep. 1 : Up. 11000 : Sen. 13,855,156 : Cost 63.81827927 : Time 504.81s : 40175.77 words/s : L.r. 2.0625e-04
[2019-02-07 13:09:29] Ep. 1 : Up. 12000 : Sen. 15,119,014 : Cost 61.17625427 : Time 457.26s : 44236.25 words/s : L.r. 2.2500e-04
[2019-02-07 13:17:08] Ep. 1 : Up. 13000 : Sen. 16,391,746 : Cost 59.30886459 : Time 459.07s : 44198.17 words/s : L.r. 2.4375e-04
[2019-02-07 13:24:44] Ep. 1 : Up. 14000 : Sen. 17,628,774 : Cost 59.05031586 : Time 455.96s : 44007.16 words/s : L.r. 2.6250e-04
[2019-02-07 13:32:23] Ep. 1 : Up. 15000 : Sen. 18,905,835 : Cost 56.74554443 : Time 459.02s : 44231.16 words/s : L.r. 2.8125e-04
[2019-02-07 13:32:23] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-07 13:32:24] Saving model weights and runtime parameters to ./model.npz
[2019-02-07 13:32:26] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-07 13:32:30] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-07 13:32:31] [valid] Ep. 1 : Up. 15000 : ce-mean-words : 2.45318 : new best
[2019-02-07 13:33:05] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-07 13:33:06] [valid] Ep. 1 : Up. 15000 : bleu-detok : 18.3725 : new best
[2019-02-07 13:40:44] Ep. 1 : Up. 16000 : Sen. 20,165,231 : Cost 56.58690262 : Time 501.17s : 40329.98 words/s : L.r. 3.0000e-04
[2019-02-07 13:48:20] Ep. 1 : Up. 17000 : Sen. 21,440,726 : Cost 54.63483429 : Time 456.13s : 44166.61 words/s : L.r. 2.9104e-04
[2019-02-07 13:56:00] Ep. 1 : Up. 18000 : Sen. 22,674,970 : Cost 56.17750931 : Time 459.52s : 44310.71 words/s : L.r. 2.8284e-04
[2019-02-07 14:03:37] Ep. 1 : Up. 19000 : Sen. 23,939,039 : Cost 53.92790604 : Time 457.70s : 44234.85 words/s : L.r. 2.7530e-04
[2019-02-07 14:11:15] Ep. 1 : Up. 20000 : Sen. 25,204,418 : Cost 53.01479340 : Time 457.81s : 44133.00 words/s : L.r. 2.6833e-04
[2019-02-07 14:11:15] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-07 14:11:17] Saving model weights and runtime parameters to ./model.npz
[2019-02-07 14:11:18] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-07 14:11:22] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-07 14:11:23] [valid] Ep. 1 : Up. 20000 : ce-mean-words : 2.14802 : new best
[2019-02-07 14:11:59] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-07 14:12:00] [valid] Ep. 1 : Up. 20000 : bleu-detok : 20.9274 : new best
[2019-02-07 14:19:38] Ep. 1 : Up. 21000 : Sen. 26,476,252 : Cost 52.33931732 : Time 502.58s : 40275.64 words/s : L.r. 2.6186e-04
[2019-02-07 14:27:16] Ep. 1 : Up. 22000 : Sen. 27,717,649 : Cost 53.10926437 : Time 457.96s : 44146.21 words/s : L.r. 2.5584e-04
[2019-02-07 14:34:53] Ep. 1 : Up. 23000 : Sen. 28,982,673 : Cost 51.65793610 : Time 457.28s : 44161.63 words/s : L.r. 2.5022e-04
[2019-02-07 14:42:32] Ep. 1 : Up. 24000 : Sen. 30,234,406 : Cost 52.22998810 : Time 458.63s : 44336.18 words/s : L.r. 2.4495e-04
[2019-02-07 14:50:11] Ep. 1 : Up. 25000 : Sen. 31,503,592 : Cost 50.89973450 : Time 459.01s : 44204.25 words/s : L.r. 2.4000e-04
[2019-02-07 14:50:11] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-07 14:50:12] Saving model weights and runtime parameters to ./model.npz
[2019-02-07 14:50:14] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-07 14:50:18] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-07 14:50:19] [valid] Ep. 1 : Up. 25000 : ce-mean-words : 1.99245 : new best
[2019-02-07 14:50:54] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-07 14:50:55] [valid] Ep. 1 : Up. 25000 : bleu-detok : 22.1326 : new best
[2019-02-07 14:58:31] Ep. 1 : Up. 26000 : Sen. 32,754,544 : Cost 50.86524963 : Time 500.02s : 40090.12 words/s : L.r. 2.3534e-04
[2019-02-07 15:06:09] Ep. 1 : Up. 27000 : Sen. 34,023,913 : Cost 50.26758957 : Time 457.79s : 44218.04 words/s : L.r. 2.3094e-04
[2019-02-07 15:13:46] Ep. 1 : Up. 28000 : Sen. 35,258,943 : Cost 51.26662445 : Time 457.13s : 44180.01 words/s : L.r. 2.2678e-04
[2019-02-07 15:21:23] Ep. 1 : Up. 29000 : Sen. 36,528,561 : Cost 49.63687515 : Time 457.15s : 44092.44 words/s : L.r. 2.2283e-04
[2019-02-07 15:29:03] Ep. 1 : Up. 30000 : Sen. 37,790,389 : Cost 50.04847717 : Time 460.36s : 44212.34 words/s : L.r. 2.1909e-04
[2019-02-07 15:29:03] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-07 15:29:05] Saving model weights and runtime parameters to ./model.npz
[2019-02-07 15:29:06] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-07 15:29:10] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-07 15:29:11] [valid] Ep. 1 : Up. 30000 : ce-mean-words : 1.90086 : new best
[2019-02-07 15:29:47] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-07 15:29:48] [valid] Ep. 1 : Up. 30000 : bleu-detok : 22.957 : new best
[2019-02-07 15:37:22] Ep. 1 : Up. 31000 : Sen. 39,042,046 : Cost 49.50317001 : Time 499.30s : 39974.26 words/s : L.r. 2.1553e-04
[2019-02-07 15:37:53] Seen 39117679 samples
[2019-02-07 15:37:53] Starting epoch 2
[2019-02-07 15:37:53] [data] Shuffling data
[2019-02-07 15:37:55] [data] Done shuffling 39221657 sentences (cached in RAM)
[2019-02-07 15:46:18] Ep. 2 : Up. 32000 : Sen. 1,177,134 : Cost 49.14041138 : Time 535.29s : 37423.74 words/s : L.r. 2.1213e-04
[2019-02-07 15:53:56] Ep. 2 : Up. 33000 : Sen. 2,438,736 : Cost 49.23828125 : Time 458.49s : 44121.27 words/s : L.r. 2.0889e-04
[2019-02-07 16:01:35] Ep. 2 : Up. 34000 : Sen. 3,701,472 : Cost 49.10074615 : Time 458.46s : 44199.59 words/s : L.r. 2.0580e-04
[2019-02-07 16:09:12] Ep. 2 : Up. 35000 : Sen. 4,949,315 : Cost 49.43403244 : Time 456.98s : 44167.41 words/s : L.r. 2.0284e-04
[2019-02-07 16:09:12] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-07 16:09:13] Saving model weights and runtime parameters to ./model.npz
[2019-02-07 16:09:15] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-07 16:09:19] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-07 16:09:19] [valid] Ep. 2 : Up. 35000 : ce-mean-words : 1.84175 : new best
[2019-02-07 16:09:55] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-07 16:09:56] [valid] Ep. 2 : Up. 35000 : bleu-detok : 23.5371 : new best
[2019-02-07 16:17:36] Ep. 2 : Up. 36000 : Sen. 6,208,460 : Cost 48.96545792 : Time 504.76s : 40245.93 words/s : L.r. 2.0000e-04
[2019-02-07 16:25:11] Ep. 2 : Up. 37000 : Sen. 7,458,951 : Cost 48.67695236 : Time 454.11s : 44040.43 words/s : L.r. 1.9728e-04
[2019-02-07 16:32:52] Ep. 2 : Up. 38000 : Sen. 8,740,669 : Cost 48.15934753 : Time 461.00s : 44355.90 words/s : L.r. 1.9467e-04
[2019-02-07 16:40:29] Ep. 2 : Up. 39000 : Sen. 9,993,632 : Cost 48.85052872 : Time 457.14s : 44231.40 words/s : L.r. 1.9215e-04
[2019-02-07 16:48:06] Ep. 2 : Up. 40000 : Sen. 11,253,317 : Cost 48.58957291 : Time 457.34s : 44329.33 words/s : L.r. 1.8974e-04
[2019-02-07 16:48:06] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-07 16:48:08] Saving model weights and runtime parameters to ./model.npz
[2019-02-07 16:48:09] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-07 16:48:13] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-07 16:48:14] [valid] Ep. 2 : Up. 40000 : ce-mean-words : 1.79795 : new best
[2019-02-07 16:48:50] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-07 16:48:51] [valid] Ep. 2 : Up. 40000 : bleu-detok : 23.9243 : new best
[2019-02-07 16:56:27] Ep. 2 : Up. 41000 : Sen. 12,501,654 : Cost 48.21190643 : Time 501.20s : 39928.94 words/s : L.r. 1.8741e-04
[2019-02-07 17:04:09] Ep. 2 : Up. 42000 : Sen. 13,773,553 : Cost 48.21732330 : Time 462.16s : 44417.62 words/s : L.r. 1.8516e-04
[2019-02-07 17:11:46] Ep. 2 : Up. 43000 : Sen. 15,038,425 : Cost 47.81699753 : Time 456.96s : 44092.18 words/s : L.r. 1.8300e-04
[2019-02-07 17:19:25] Ep. 2 : Up. 44000 : Sen. 16,294,623 : Cost 48.10895920 : Time 459.06s : 44137.73 words/s : L.r. 1.8091e-04
[2019-02-07 17:27:00] Ep. 2 : Up. 45000 : Sen. 17,541,155 : Cost 48.10061646 : Time 454.14s : 44124.55 words/s : L.r. 1.7889e-04
[2019-02-07 17:27:00] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-07 17:27:01] Saving model weights and runtime parameters to ./model.npz
[2019-02-07 17:27:03] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-07 17:27:07] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-07 17:27:08] [valid] Ep. 2 : Up. 45000 : ce-mean-words : 1.76438 : new best
[2019-02-07 17:27:44] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-07 17:27:44] [valid] Ep. 2 : Up. 45000 : bleu-detok : 24.2439 : new best
[2019-02-07 17:35:25] Ep. 2 : Up. 46000 : Sen. 18,824,266 : Cost 47.27190399 : Time 505.25s : 40342.46 words/s : L.r. 1.7693e-04
[2019-02-07 17:43:01] Ep. 2 : Up. 47000 : Sen. 20,069,778 : Cost 48.21722412 : Time 456.56s : 44187.47 words/s : L.r. 1.7504e-04
[2019-02-07 17:50:41] Ep. 2 : Up. 48000 : Sen. 21,325,845 : Cost 47.94544220 : Time 459.15s : 44223.75 words/s : L.r. 1.7321e-04
[2019-02-07 17:58:17] Ep. 2 : Up. 49000 : Sen. 22,582,681 : Cost 47.55952072 : Time 456.83s : 44178.81 words/s : L.r. 1.7143e-04
[2019-02-07 18:05:55] Ep. 2 : Up. 50000 : Sen. 23,846,178 : Cost 47.58211136 : Time 457.63s : 44322.11 words/s : L.r. 1.6971e-04
[2019-02-07 18:05:55] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-07 18:05:56] Saving model weights and runtime parameters to ./model.npz
[2019-02-07 18:05:58] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-07 18:06:02] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-07 18:06:03] [valid] Ep. 2 : Up. 50000 : ce-mean-words : 1.73877 : new best
[2019-02-07 18:06:39] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-07 18:06:40] [valid] Ep. 2 : Up. 50000 : bleu-detok : 24.5213 : new best
[2019-02-07 18:14:18] Ep. 2 : Up. 51000 : Sen. 25,119,571 : Cost 46.83069992 : Time 502.64s : 40101.02 words/s : L.r. 1.6803e-04
[2019-02-07 18:21:56] Ep. 2 : Up. 52000 : Sen. 26,382,148 : Cost 47.15806961 : Time 457.87s : 44123.93 words/s : L.r. 1.6641e-04
[2019-02-07 18:29:31] Ep. 2 : Up. 53000 : Sen. 27,656,557 : Cost 46.51753998 : Time 455.30s : 44094.86 words/s : L.r. 1.6483e-04
[2019-02-07 18:37:10] Ep. 2 : Up. 54000 : Sen. 28,889,204 : Cost 48.34007645 : Time 458.92s : 44198.27 words/s : L.r. 1.6330e-04
[2019-02-07 18:44:49] Ep. 2 : Up. 55000 : Sen. 30,170,637 : Cost 46.57281876 : Time 459.50s : 44246.03 words/s : L.r. 1.6181e-04
[2019-02-07 18:44:49] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-07 18:44:51] Saving model weights and runtime parameters to ./model.npz
[2019-02-07 18:44:52] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-07 18:44:56] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-07 18:44:57] [valid] Ep. 2 : Up. 55000 : ce-mean-words : 1.71674 : new best
[2019-02-07 18:45:33] [valid] Ep. 2 : Up. 55000 : bleu-detok : 24.5073 : stalled 1 times (last best: 24.5213)
[2019-02-07 18:53:11] Ep. 2 : Up. 56000 : Sen. 31,418,683 : Cost 47.60086823 : Time 502.26s : 40250.24 words/s : L.r. 1.6036e-04
[2019-02-07 19:00:47] Ep. 2 : Up. 57000 : Sen. 32,670,587 : Cost 46.91009521 : Time 455.46s : 44013.74 words/s : L.r. 1.5894e-04
[2019-02-07 19:08:24] Ep. 2 : Up. 58000 : Sen. 33,925,000 : Cost 47.31063080 : Time 457.01s : 44294.11 words/s : L.r. 1.5757e-04
[2019-02-07 19:16:02] Ep. 2 : Up. 59000 : Sen. 35,180,952 : Cost 46.98017883 : Time 458.28s : 44122.66 words/s : L.r. 1.5623e-04
[2019-02-07 19:23:41] Ep. 2 : Up. 60000 : Sen. 36,440,079 : Cost 47.26392746 : Time 459.01s : 44353.73 words/s : L.r. 1.5492e-04
[2019-02-07 19:23:41] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-07 19:23:43] Saving model weights and runtime parameters to ./model.npz
[2019-02-07 19:23:44] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-07 19:23:48] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-07 19:23:49] [valid] Ep. 2 : Up. 60000 : ce-mean-words : 1.69894 : new best
[2019-02-07 19:24:25] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-07 19:24:26] [valid] Ep. 2 : Up. 60000 : bleu-detok : 24.7863 : new best
[2019-02-07 19:32:05] Ep. 2 : Up. 61000 : Sen. 37,726,968 : Cost 46.05594254 : Time 503.71s : 40232.85 words/s : L.r. 1.5364e-04
[2019-02-07 19:39:42] Ep. 2 : Up. 62000 : Sen. 38,970,722 : Cost 47.18757629 : Time 457.06s : 44146.95 words/s : L.r. 1.5240e-04
[2019-02-07 19:40:41] Seen 39117679 samples
[2019-02-07 19:40:41] Starting epoch 3
[2019-02-07 19:40:41] [data] Shuffling data
[2019-02-07 19:40:43] [data] Done shuffling 39221657 sentences (cached in RAM)
[2019-02-07 19:48:33] Ep. 3 : Up. 63000 : Sen. 1,074,924 : Cost 46.84077835 : Time 531.06s : 37123.93 words/s : L.r. 1.5119e-04
[2019-02-07 19:56:10] Ep. 3 : Up. 64000 : Sen. 2,332,961 : Cost 46.37192917 : Time 456.62s : 44054.19 words/s : L.r. 1.5000e-04
[2019-02-07 20:03:47] Ep. 3 : Up. 65000 : Sen. 3,574,749 : Cost 46.94144440 : Time 457.02s : 44144.14 words/s : L.r. 1.4884e-04
[2019-02-07 20:03:47] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-07 20:03:48] Saving model weights and runtime parameters to ./model.npz
[2019-02-07 20:03:50] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-07 20:03:53] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-07 20:03:54] [valid] Ep. 3 : Up. 65000 : ce-mean-words : 1.68493 : new best
[2019-02-07 20:04:31] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-07 20:04:32] [valid] Ep. 3 : Up. 65000 : bleu-detok : 24.9753 : new best
[2019-02-07 20:12:11] Ep. 3 : Up. 66000 : Sen. 4,848,088 : Cost 46.36730957 : Time 504.62s : 40303.15 words/s : L.r. 1.4771e-04
[2019-02-07 20:19:47] Ep. 3 : Up. 67000 : Sen. 6,106,843 : Cost 46.07595062 : Time 455.42s : 43997.70 words/s : L.r. 1.4660e-04
[2019-02-07 20:27:28] Ep. 3 : Up. 68000 : Sen. 7,381,236 : Cost 46.43417358 : Time 461.38s : 44320.66 words/s : L.r. 1.4552e-04
[2019-02-07 20:35:06] Ep. 3 : Up. 69000 : Sen. 8,619,531 : Cost 46.97791290 : Time 457.46s : 44060.36 words/s : L.r. 1.4446e-04
[2019-02-07 20:42:44] Ep. 3 : Up. 70000 : Sen. 9,895,700 : Cost 46.04755020 : Time 458.86s : 44363.28 words/s : L.r. 1.4343e-04
[2019-02-07 20:42:44] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-07 20:42:46] Saving model weights and runtime parameters to ./model.npz
[2019-02-07 20:42:47] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-07 20:42:51] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-07 20:42:52] [valid] Ep. 3 : Up. 70000 : ce-mean-words : 1.6714 : new best
[2019-02-07 20:43:29] [valid] Ep. 3 : Up. 70000 : bleu-detok : 24.9348 : stalled 1 times (last best: 24.9753)
[2019-02-07 20:51:07] Ep. 3 : Up. 71000 : Sen. 11,173,447 : Cost 45.68413925 : Time 502.09s : 40227.08 words/s : L.r. 1.4241e-04
[2019-02-07 20:58:43] Ep. 3 : Up. 72000 : Sen. 12,414,609 : Cost 46.75014114 : Time 456.01s : 44166.93 words/s : L.r. 1.4142e-04
[2019-02-07 21:06:22] Ep. 3 : Up. 73000 : Sen. 13,671,250 : Cost 46.67214584 : Time 459.17s : 44185.71 words/s : L.r. 1.4045e-04
[2019-02-07 21:14:01] Ep. 3 : Up. 74000 : Sen. 14,948,967 : Cost 45.70859909 : Time 458.88s : 44236.35 words/s : L.r. 1.3950e-04
[2019-02-07 21:21:38] Ep. 3 : Up. 75000 : Sen. 16,197,466 : Cost 46.55698776 : Time 457.18s : 44191.55 words/s : L.r. 1.3856e-04
[2019-02-07 21:21:38] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-07 21:21:39] Saving model weights and runtime parameters to ./model.npz
[2019-02-07 21:21:41] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-07 21:21:45] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-07 21:21:46] [valid] Ep. 3 : Up. 75000 : ce-mean-words : 1.6616 : new best
[2019-02-07 21:22:22] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-07 21:22:23] [valid] Ep. 3 : Up. 75000 : bleu-detok : 25.0808 : new best
[2019-02-07 21:30:01] Ep. 3 : Up. 76000 : Sen. 17,437,817 : Cost 46.78292084 : Time 503.04s : 40115.34 words/s : L.r. 1.3765e-04
[2019-02-07 21:37:39] Ep. 3 : Up. 77000 : Sen. 18,714,795 : Cost 45.47998810 : Time 457.76s : 44213.89 words/s : L.r. 1.3675e-04
[2019-02-07 21:45:18] Ep. 3 : Up. 78000 : Sen. 19,978,976 : Cost 46.20662689 : Time 459.09s : 44194.41 words/s : L.r. 1.3587e-04
[2019-02-07 21:52:55] Ep. 3 : Up. 79000 : Sen. 21,252,870 : Cost 45.46108627 : Time 457.51s : 44134.65 words/s : L.r. 1.3501e-04
[2019-02-07 22:00:35] Ep. 3 : Up. 80000 : Sen. 22,470,701 : Cost 47.96898270 : Time 459.33s : 44277.29 words/s : L.r. 1.3416e-04
[2019-02-07 22:00:35] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-07 22:00:36] Saving model weights and runtime parameters to ./model.npz
[2019-02-07 22:00:37] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-07 22:00:42] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-07 22:00:43] [valid] Ep. 3 : Up. 80000 : ce-mean-words : 1.65261 : new best
[2019-02-07 22:01:19] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-07 22:01:20] [valid] Ep. 3 : Up. 80000 : bleu-detok : 25.1725 : new best
[2019-02-07 22:08:59] Ep. 3 : Up. 81000 : Sen. 23,766,978 : Cost 44.89129639 : Time 504.46s : 40222.99 words/s : L.r. 1.3333e-04
[2019-02-07 22:16:35] Ep. 3 : Up. 82000 : Sen. 25,023,240 : Cost 45.83248138 : Time 456.15s : 44079.60 words/s : L.r. 1.3252e-04
[2019-02-07 22:24:11] Ep. 3 : Up. 83000 : Sen. 26,278,310 : Cost 45.80342102 : Time 455.37s : 44075.16 words/s : L.r. 1.3172e-04
[2019-02-07 22:31:50] Ep. 3 : Up. 84000 : Sen. 27,518,845 : Cost 47.23836899 : Time 459.47s : 44496.26 words/s : L.r. 1.3093e-04
[2019-02-07 22:39:26] Ep. 3 : Up. 85000 : Sen. 28,806,680 : Cost 44.78302002 : Time 456.35s : 44122.51 words/s : L.r. 1.3016e-04
[2019-02-07 22:39:26] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-07 22:39:28] Saving model weights and runtime parameters to ./model.npz
[2019-02-07 22:39:29] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-07 22:39:33] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-07 22:39:34] [valid] Ep. 3 : Up. 85000 : ce-mean-words : 1.64381 : new best
[2019-02-07 22:40:10] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-07 22:40:11] [valid] Ep. 3 : Up. 85000 : bleu-detok : 25.2092 : new best
[2019-02-07 22:47:50] Ep. 3 : Up. 86000 : Sen. 30,074,217 : Cost 45.65374756 : Time 504.08s : 40207.27 words/s : L.r. 1.2940e-04
[2019-02-07 22:55:29] Ep. 3 : Up. 87000 : Sen. 31,325,452 : Cost 46.33796310 : Time 458.24s : 44255.94 words/s : L.r. 1.2865e-04
[2019-02-07 23:03:08] Ep. 3 : Up. 88000 : Sen. 32,594,198 : Cost 45.70708847 : Time 459.37s : 44206.89 words/s : L.r. 1.2792e-04
[2019-02-07 23:10:44] Ep. 3 : Up. 89000 : Sen. 33,850,302 : Cost 45.89840317 : Time 455.89s : 44207.68 words/s : L.r. 1.2720e-04
[2019-02-07 23:18:23] Ep. 3 : Up. 90000 : Sen. 35,119,038 : Cost 45.56592560 : Time 459.25s : 44219.18 words/s : L.r. 1.2649e-04
[2019-02-07 23:18:23] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-07 23:18:25] Saving model weights and runtime parameters to ./model.npz
[2019-02-07 23:18:26] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-07 23:18:30] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-07 23:18:31] [valid] Ep. 3 : Up. 90000 : ce-mean-words : 1.63495 : new best
[2019-02-07 23:19:07] [valid] Ep. 3 : Up. 90000 : bleu-detok : 25.1915 : stalled 1 times (last best: 25.2092)
[2019-02-07 23:26:46] Ep. 3 : Up. 91000 : Sen. 36,370,805 : Cost 46.13972092 : Time 502.42s : 40187.79 words/s : L.r. 1.2579e-04
[2019-02-07 23:34:23] Ep. 3 : Up. 92000 : Sen. 37,639,794 : Cost 45.41695786 : Time 457.50s : 44253.50 words/s : L.r. 1.2511e-04
[2019-02-07 23:42:02] Ep. 3 : Up. 93000 : Sen. 38,894,825 : Cost 45.86999512 : Time 458.53s : 44101.40 words/s : L.r. 1.2443e-04
[2019-02-07 23:43:29] Seen 39117679 samples
[2019-02-07 23:43:29] Starting epoch 4
[2019-02-07 23:43:29] [data] Shuffling data
[2019-02-07 23:43:31] [data] Done shuffling 39221657 sentences (cached in RAM)
[2019-02-07 23:50:54] Ep. 4 : Up. 94000 : Sen. 1,007,852 : Cost 45.66095734 : Time 532.12s : 37210.81 words/s : L.r. 1.2377e-04
[2019-02-07 23:58:29] Ep. 4 : Up. 95000 : Sen. 2,260,586 : Cost 45.43514633 : Time 455.17s : 44093.64 words/s : L.r. 1.2312e-04
[2019-02-07 23:58:29] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-07 23:58:30] Saving model weights and runtime parameters to ./model.npz
[2019-02-07 23:58:32] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-07 23:58:36] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-07 23:58:37] [valid] Ep. 4 : Up. 95000 : ce-mean-words : 1.6269 : new best
[2019-02-07 23:59:13] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-07 23:59:14] [valid] Ep. 4 : Up. 95000 : bleu-detok : 25.382 : new best
[2019-02-08 00:06:53] Ep. 4 : Up. 96000 : Sen. 3,522,677 : Cost 45.54599380 : Time 504.48s : 40213.24 words/s : L.r. 1.2247e-04
[2019-02-08 00:14:31] Ep. 4 : Up. 97000 : Sen. 4,775,618 : Cost 45.73277283 : Time 457.73s : 44177.21 words/s : L.r. 1.2184e-04
[2019-02-08 00:22:10] Ep. 4 : Up. 98000 : Sen. 6,062,987 : Cost 44.81358719 : Time 458.52s : 44321.08 words/s : L.r. 1.2122e-04
[2019-02-08 00:29:49] Ep. 4 : Up. 99000 : Sen. 7,323,847 : Cost 45.58470535 : Time 459.09s : 44222.46 words/s : L.r. 1.2060e-04
[2019-02-08 00:37:27] Ep. 4 : Up. 100000 : Sen. 8,558,936 : Cost 46.48595428 : Time 458.03s : 44260.57 words/s : L.r. 1.2000e-04
[2019-02-08 00:37:27] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-08 00:37:28] Saving model weights and runtime parameters to ./model.npz
[2019-02-08 00:37:30] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-08 00:37:33] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-08 00:37:34] [valid] Ep. 4 : Up. 100000 : ce-mean-words : 1.62134 : new best
[2019-02-08 00:38:11] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-08 00:38:12] [valid] Ep. 4 : Up. 100000 : bleu-detok : 25.5439 : new best
[2019-02-08 00:45:52] Ep. 4 : Up. 101000 : Sen. 9,850,597 : Cost 44.41589737 : Time 505.12s : 40101.58 words/s : L.r. 1.1940e-04
[2019-02-08 00:53:31] Ep. 4 : Up. 102000 : Sen. 11,117,028 : Cost 45.30117416 : Time 458.79s : 44141.52 words/s : L.r. 1.1882e-04
[2019-02-08 01:01:08] Ep. 4 : Up. 103000 : Sen. 12,367,181 : Cost 45.88214874 : Time 457.62s : 44247.20 words/s : L.r. 1.1824e-04
[2019-02-08 01:08:48] Ep. 4 : Up. 104000 : Sen. 13,608,377 : Cost 46.39459991 : Time 459.63s : 44277.70 words/s : L.r. 1.1767e-04
[2019-02-08 01:16:23] Ep. 4 : Up. 105000 : Sen. 14,871,669 : Cost 44.88456726 : Time 455.38s : 44039.06 words/s : L.r. 1.1711e-04
[2019-02-08 01:16:23] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-08 01:16:25] Saving model weights and runtime parameters to ./model.npz
[2019-02-08 01:16:26] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-08 01:16:30] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-08 01:16:31] [valid] Ep. 4 : Up. 105000 : ce-mean-words : 1.616 : new best
[2019-02-08 01:17:08] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-08 01:17:09] [valid] Ep. 4 : Up. 105000 : bleu-detok : 25.6138 : new best
[2019-02-08 01:24:49] Ep. 4 : Up. 106000 : Sen. 16,146,607 : Cost 45.06254578 : Time 505.35s : 40188.63 words/s : L.r. 1.1655e-04
[2019-02-08 01:32:25] Ep. 4 : Up. 107000 : Sen. 17,376,418 : Cost 46.39982605 : Time 455.85s : 44204.80 words/s : L.r. 1.1601e-04
[2019-02-08 01:40:02] Ep. 4 : Up. 108000 : Sen. 18,673,733 : Cost 44.02285767 : Time 457.11s : 44190.09 words/s : L.r. 1.1547e-04
[2019-02-08 01:47:39] Ep. 4 : Up. 109000 : Sen. 19,907,735 : Cost 46.35049057 : Time 457.51s : 44278.31 words/s : L.r. 1.1494e-04
[2019-02-08 01:55:17] Ep. 4 : Up. 110000 : Sen. 21,161,466 : Cost 45.48812866 : Time 457.44s : 44156.54 words/s : L.r. 1.1442e-04
[2019-02-08 01:55:17] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-08 01:55:18] Saving model weights and runtime parameters to ./model.npz
[2019-02-08 01:55:20] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-08 01:55:24] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-08 01:55:25] [valid] Ep. 4 : Up. 110000 : ce-mean-words : 1.61055 : new best
[2019-02-08 01:56:01] [valid] Ep. 4 : Up. 110000 : bleu-detok : 25.5758 : stalled 1 times (last best: 25.6138)
[2019-02-08 02:03:39] Ep. 4 : Up. 111000 : Sen. 22,435,139 : Cost 44.88434219 : Time 502.17s : 40207.41 words/s : L.r. 1.1390e-04
[2019-02-08 02:11:17] Ep. 4 : Up. 112000 : Sen. 23,699,304 : Cost 45.13536835 : Time 458.50s : 44167.82 words/s : L.r. 1.1339e-04
[2019-02-08 02:18:56] Ep. 4 : Up. 113000 : Sen. 24,962,335 : Cost 45.38987732 : Time 459.01s : 44277.70 words/s : L.r. 1.1289e-04
[2019-02-08 02:26:32] Ep. 4 : Up. 114000 : Sen. 26,213,380 : Cost 45.45114136 : Time 455.47s : 44202.24 words/s : L.r. 1.1239e-04
[2019-02-08 02:34:09] Ep. 4 : Up. 115000 : Sen. 27,463,731 : Cost 45.47703171 : Time 457.69s : 44135.72 words/s : L.r. 1.1190e-04
[2019-02-08 02:34:09] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-08 02:34:11] Saving model weights and runtime parameters to ./model.npz
[2019-02-08 02:34:12] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-08 02:34:16] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-08 02:34:17] [valid] Ep. 4 : Up. 115000 : ce-mean-words : 1.60528 : new best
[2019-02-08 02:34:53] [valid] Ep. 4 : Up. 115000 : bleu-detok : 25.5247 : stalled 2 times (last best: 25.6138)
[2019-02-08 02:42:31] Ep. 4 : Up. 116000 : Sen. 28,729,413 : Cost 45.13119888 : Time 501.87s : 40389.33 words/s : L.r. 1.1142e-04
[2019-02-08 02:50:10] Ep. 4 : Up. 117000 : Sen. 29,991,304 : Cost 45.27671432 : Time 458.88s : 44111.31 words/s : L.r. 1.1094e-04
[2019-02-08 02:57:49] Ep. 4 : Up. 118000 : Sen. 31,282,740 : Cost 44.13461304 : Time 458.78s : 44102.78 words/s : L.r. 1.1047e-04
[2019-02-08 03:05:27] Ep. 4 : Up. 119000 : Sen. 32,544,161 : Cost 45.33476639 : Time 457.57s : 44249.03 words/s : L.r. 1.1000e-04
[2019-02-08 03:13:06] Ep. 4 : Up. 120000 : Sen. 33,779,640 : Cost 46.12517548 : Time 459.10s : 44200.76 words/s : L.r. 1.0954e-04
[2019-02-08 03:13:06] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-08 03:13:07] Saving model weights and runtime parameters to ./model.npz
[2019-02-08 03:13:09] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-08 03:13:12] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-08 03:13:13] [valid] Ep. 4 : Up. 120000 : ce-mean-words : 1.60012 : new best
[2019-02-08 03:13:49] [valid] Ep. 4 : Up. 120000 : bleu-detok : 25.5375 : stalled 3 times (last best: 25.6138)
[2019-02-08 03:21:28] Ep. 4 : Up. 121000 : Sen. 35,033,190 : Cost 45.53507233 : Time 502.45s : 40330.70 words/s : L.r. 1.0909e-04
[2019-02-08 03:29:03] Ep. 4 : Up. 122000 : Sen. 36,297,734 : Cost 44.90208817 : Time 455.37s : 44152.49 words/s : L.r. 1.0864e-04
[2019-02-08 03:36:44] Ep. 4 : Up. 123000 : Sen. 37,552,156 : Cost 45.43855286 : Time 460.10s : 44154.19 words/s : L.r. 1.0820e-04
[2019-02-08 03:44:21] Ep. 4 : Up. 124000 : Sen. 38,839,289 : Cost 44.17857742 : Time 457.68s : 44115.24 words/s : L.r. 1.0776e-04
[2019-02-08 03:46:16] Seen 39117679 samples
[2019-02-08 03:46:16] Starting epoch 5
[2019-02-08 03:46:16] [data] Shuffling data
[2019-02-08 03:46:18] [data] Done shuffling 39221657 sentences (cached in RAM)
[2019-02-08 03:53:12] Ep. 5 : Up. 125000 : Sen. 930,938 : Cost 45.67509842 : Time 530.70s : 37153.35 words/s : L.r. 1.0733e-04
[2019-02-08 03:53:12] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-08 03:53:13] Saving model weights and runtime parameters to ./model.npz
[2019-02-08 03:53:15] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-08 03:53:19] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-08 03:53:20] [valid] Ep. 5 : Up. 125000 : ce-mean-words : 1.59513 : new best
[2019-02-08 03:53:56] [valid] Ep. 5 : Up. 125000 : bleu-detok : 25.3857 : stalled 4 times (last best: 25.6138)
[2019-02-08 04:01:35] Ep. 5 : Up. 126000 : Sen. 2,201,431 : Cost 44.71747589 : Time 503.55s : 40385.04 words/s : L.r. 1.0690e-04
[2019-02-08 04:09:10] Ep. 5 : Up. 127000 : Sen. 3,445,761 : Cost 45.34253311 : Time 454.89s : 44213.34 words/s : L.r. 1.0648e-04
[2019-02-08 04:16:51] Ep. 5 : Up. 128000 : Sen. 4,709,651 : Cost 44.96707535 : Time 460.17s : 44170.25 words/s : L.r. 1.0607e-04
[2019-02-08 04:24:27] Ep. 5 : Up. 129000 : Sen. 5,965,026 : Cost 45.01841354 : Time 456.08s : 44190.27 words/s : L.r. 1.0565e-04
[2019-02-08 04:32:06] Ep. 5 : Up. 130000 : Sen. 7,233,996 : Cost 45.00061417 : Time 459.25s : 44370.61 words/s : L.r. 1.0525e-04
[2019-02-08 04:32:06] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-08 04:32:07] Saving model weights and runtime parameters to ./model.npz
[2019-02-08 04:32:09] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-08 04:32:13] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-08 04:32:14] [valid] Ep. 5 : Up. 130000 : ce-mean-words : 1.5918 : new best
[2019-02-08 04:32:50] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-08 04:32:51] [valid] Ep. 5 : Up. 130000 : bleu-detok : 25.642 : new best
[2019-02-08 04:40:28] Ep. 5 : Up. 131000 : Sen. 8,467,869 : Cost 45.58159256 : Time 501.69s : 40142.47 words/s : L.r. 1.0484e-04
[2019-02-08 04:48:06] Ep. 5 : Up. 132000 : Sen. 9,749,149 : Cost 44.27521896 : Time 458.43s : 44093.94 words/s : L.r. 1.0445e-04
[2019-02-08 04:55:43] Ep. 5 : Up. 133000 : Sen. 11,006,847 : Cost 45.04354095 : Time 457.18s : 44203.83 words/s : L.r. 1.0405e-04
[2019-02-08 05:03:23] Ep. 5 : Up. 134000 : Sen. 12,274,983 : Cost 44.96140289 : Time 459.57s : 44250.80 words/s : L.r. 1.0366e-04
[2019-02-08 05:11:00] Ep. 5 : Up. 135000 : Sen. 13,527,742 : Cost 45.20497131 : Time 457.24s : 44186.42 words/s : L.r. 1.0328e-04
[2019-02-08 05:11:00] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-08 05:11:02] Saving model weights and runtime parameters to ./model.npz
[2019-02-08 05:11:03] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-08 05:11:08] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-08 05:11:09] [valid] Ep. 5 : Up. 135000 : ce-mean-words : 1.5884 : new best
[2019-02-08 05:11:45] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-08 05:11:46] [valid] Ep. 5 : Up. 135000 : bleu-detok : 25.8367 : new best
[2019-02-08 05:19:23] Ep. 5 : Up. 136000 : Sen. 14,792,857 : Cost 44.36994171 : Time 503.14s : 39942.21 words/s : L.r. 1.0290e-04
[2019-02-08 05:27:00] Ep. 5 : Up. 137000 : Sen. 16,042,587 : Cost 45.16173553 : Time 456.42s : 44218.98 words/s : L.r. 1.0252e-04
[2019-02-08 05:34:38] Ep. 5 : Up. 138000 : Sen. 17,290,253 : Cost 45.46749496 : Time 458.00s : 44200.46 words/s : L.r. 1.0215e-04
[2019-02-08 05:42:16] Ep. 5 : Up. 139000 : Sen. 18,580,298 : Cost 43.68235016 : Time 458.35s : 44063.36 words/s : L.r. 1.0178e-04
[2019-02-08 05:49:53] Ep. 5 : Up. 140000 : Sen. 19,832,316 : Cost 45.30267715 : Time 457.02s : 44322.52 words/s : L.r. 1.0142e-04
[2019-02-08 05:49:53] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-08 05:49:54] Saving model weights and runtime parameters to ./model.npz
[2019-02-08 05:49:56] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-08 05:50:00] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-08 05:50:01] [valid] Ep. 5 : Up. 140000 : ce-mean-words : 1.58491 : new best
[2019-02-08 05:50:37] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-08 05:50:38] [valid] Ep. 5 : Up. 140000 : bleu-detok : 25.8666 : new best
[2019-02-08 05:58:17] Ep. 5 : Up. 141000 : Sen. 21,082,837 : Cost 45.25442123 : Time 504.15s : 40173.84 words/s : L.r. 1.0106e-04
[2019-02-08 06:05:54] Ep. 5 : Up. 142000 : Sen. 22,315,424 : Cost 45.83565521 : Time 457.04s : 44201.39 words/s : L.r. 1.0070e-04
[2019-02-08 06:13:31] Ep. 5 : Up. 143000 : Sen. 23,614,495 : Cost 43.58141327 : Time 457.27s : 44253.00 words/s : L.r. 1.0035e-04
[2019-02-08 06:21:09] Ep. 5 : Up. 144000 : Sen. 24,853,889 : Cost 45.51849747 : Time 458.04s : 44139.01 words/s : L.r. 1.0000e-04
[2019-02-08 06:28:46] Ep. 5 : Up. 145000 : Sen. 26,107,424 : Cost 44.86211777 : Time 456.50s : 44157.12 words/s : L.r. 9.9655e-05
[2019-02-08 06:28:46] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-08 06:28:47] Saving model weights and runtime parameters to ./model.npz
[2019-02-08 06:28:49] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-08 06:28:53] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-08 06:28:54] [valid] Ep. 5 : Up. 145000 : ce-mean-words : 1.58137 : new best
[2019-02-08 06:29:31] [valid] Ep. 5 : Up. 145000 : bleu-detok : 25.7881 : stalled 1 times (last best: 25.8666)
[2019-02-08 06:37:11] Ep. 5 : Up. 146000 : Sen. 27,367,465 : Cost 45.08191681 : Time 505.53s : 40284.02 words/s : L.r. 9.9313e-05
[2019-02-08 06:44:51] Ep. 5 : Up. 147000 : Sen. 28,668,414 : Cost 43.78624725 : Time 459.29s : 44181.70 words/s : L.r. 9.8974e-05
[2019-02-08 06:52:28] Ep. 5 : Up. 148000 : Sen. 29,907,967 : Cost 45.43563843 : Time 456.89s : 44215.36 words/s : L.r. 9.8639e-05
[2019-02-08 07:00:04] Ep. 5 : Up. 149000 : Sen. 31,166,829 : Cost 45.04545975 : Time 456.67s : 44288.92 words/s : L.r. 9.8308e-05
[2019-02-08 07:07:42] Ep. 5 : Up. 150000 : Sen. 32,407,672 : Cost 45.12630844 : Time 457.83s : 44053.06 words/s : L.r. 9.7980e-05
[2019-02-08 07:07:42] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-08 07:07:44] Saving model weights and runtime parameters to ./model.npz
[2019-02-08 07:07:45] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-08 07:07:49] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-08 07:07:50] [valid] Ep. 5 : Up. 150000 : ce-mean-words : 1.57835 : new best
[2019-02-08 07:08:27] [valid] Ep. 5 : Up. 150000 : bleu-detok : 25.7615 : stalled 2 times (last best: 25.8666)
[2019-02-08 07:16:03] Ep. 5 : Up. 151000 : Sen. 33,673,801 : Cost 44.70032501 : Time 501.23s : 40251.38 words/s : L.r. 9.7655e-05
[2019-02-08 07:23:43] Ep. 5 : Up. 152000 : Sen. 34,937,292 : Cost 44.82318115 : Time 459.74s : 44199.18 words/s : L.r. 9.7333e-05
[2019-02-08 07:31:22] Ep. 5 : Up. 153000 : Sen. 36,207,931 : Cost 44.53524399 : Time 458.60s : 44296.46 words/s : L.r. 9.7014e-05
[2019-02-08 07:38:58] Ep. 5 : Up. 154000 : Sen. 37,460,466 : Cost 44.91812897 : Time 455.90s : 44119.09 words/s : L.r. 9.6699e-05
[2019-02-08 07:46:32] Ep. 5 : Up. 155000 : Sen. 38,688,858 : Cost 45.44015503 : Time 454.57s : 44066.76 words/s : L.r. 9.6386e-05
[2019-02-08 07:46:32] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-08 07:46:34] Saving model weights and runtime parameters to ./model.npz
[2019-02-08 07:46:35] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-08 07:46:39] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-08 07:46:40] [valid] Ep. 5 : Up. 155000 : ce-mean-words : 1.5757 : new best
[2019-02-08 07:47:19] [valid] Ep. 5 : Up. 155000 : bleu-detok : 25.723 : stalled 3 times (last best: 25.8666)
[2019-02-08 07:49:51] Seen 39117679 samples
[2019-02-08 07:49:51] Starting epoch 6
[2019-02-08 07:49:51] [data] Shuffling data
[2019-02-08 07:49:54] [data] Done shuffling 39221657 sentences (cached in RAM)
[2019-02-08 07:56:10] Ep. 6 : Up. 156000 : Sen. 833,569 : Cost 43.45482254 : Time 578.26s : 34112.52 words/s : L.r. 9.6077e-05
[2019-02-08 08:03:49] Ep. 6 : Up. 157000 : Sen. 2,093,578 : Cost 44.83315277 : Time 459.00s : 44329.66 words/s : L.r. 9.5770e-05
[2019-02-08 08:11:31] Ep. 6 : Up. 158000 : Sen. 3,371,300 : Cost 44.31471634 : Time 461.34s : 44246.51 words/s : L.r. 9.5467e-05
[2019-02-08 08:19:06] Ep. 6 : Up. 159000 : Sen. 4,608,454 : Cost 45.17213058 : Time 455.21s : 44073.74 words/s : L.r. 9.5166e-05
[2019-02-08 08:26:44] Ep. 6 : Up. 160000 : Sen. 5,885,023 : Cost 44.02275085 : Time 458.31s : 44198.25 words/s : L.r. 9.4868e-05
[2019-02-08 08:26:44] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-08 08:26:46] Saving model weights and runtime parameters to ./model.npz
[2019-02-08 08:26:47] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-08 08:26:51] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-08 08:26:52] [valid] Ep. 6 : Up. 160000 : ce-mean-words : 1.57396 : new best
[2019-02-08 08:27:29] [valid] Ep. 6 : Up. 160000 : bleu-detok : 25.7389 : stalled 4 times (last best: 25.8666)
[2019-02-08 08:35:08] Ep. 6 : Up. 161000 : Sen. 7,152,098 : Cost 44.50067139 : Time 503.51s : 40265.92 words/s : L.r. 9.4573e-05
[2019-02-08 08:42:44] Ep. 6 : Up. 162000 : Sen. 8,386,642 : Cost 45.29606628 : Time 455.74s : 44175.22 words/s : L.r. 9.4281e-05
[2019-02-08 08:50:23] Ep. 6 : Up. 163000 : Sen. 9,627,490 : Cost 45.35649109 : Time 458.92s : 44215.66 words/s : L.r. 9.3991e-05
[2019-02-08 08:57:59] Ep. 6 : Up. 164000 : Sen. 10,904,752 : Cost 43.75787735 : Time 456.81s : 44078.94 words/s : L.r. 9.3704e-05
[2019-02-08 09:05:38] Ep. 6 : Up. 165000 : Sen. 12,175,381 : Cost 44.46695328 : Time 458.95s : 44289.95 words/s : L.r. 9.3420e-05
[2019-02-08 09:05:38] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-08 09:05:40] Saving model weights and runtime parameters to ./model.npz
[2019-02-08 09:05:41] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-08 09:05:45] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-08 09:05:46] [valid] Ep. 6 : Up. 165000 : ce-mean-words : 1.57223 : new best
[2019-02-08 09:06:24] [valid] Ep. 6 : Up. 165000 : bleu-detok : 25.6904 : stalled 5 times (last best: 25.8666)
[2019-02-08 09:14:00] Ep. 6 : Up. 166000 : Sen. 13,427,735 : Cost 44.61721420 : Time 502.23s : 39999.98 words/s : L.r. 9.3138e-05
[2019-02-08 09:21:38] Ep. 6 : Up. 167000 : Sen. 14,705,166 : Cost 43.87551880 : Time 457.52s : 44159.21 words/s : L.r. 9.2859e-05
[2019-02-08 09:29:17] Ep. 6 : Up. 168000 : Sen. 15,953,411 : Cost 45.21906281 : Time 459.21s : 44235.72 words/s : L.r. 9.2582e-05
[2019-02-08 09:36:56] Ep. 6 : Up. 169000 : Sen. 17,217,632 : Cost 44.43460083 : Time 458.34s : 44128.02 words/s : L.r. 9.2308e-05
[2019-02-08 09:44:33] Ep. 6 : Up. 170000 : Sen. 18,488,628 : Cost 44.43303680 : Time 457.42s : 44332.19 words/s : L.r. 9.2036e-05
[2019-02-08 09:44:33] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-08 09:44:34] Saving model weights and runtime parameters to ./model.npz
[2019-02-08 09:44:36] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-08 09:44:40] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-08 09:44:41] [valid] Ep. 6 : Up. 170000 : ce-mean-words : 1.56941 : new best
[2019-02-08 09:45:19] [valid] Ep. 6 : Up. 170000 : bleu-detok : 25.6851 : stalled 6 times (last best: 25.8666)
[2019-02-08 09:52:58] Ep. 6 : Up. 171000 : Sen. 19,717,684 : Cost 45.79976273 : Time 504.64s : 40206.75 words/s : L.r. 9.1766e-05
[2019-02-08 10:00:36] Ep. 6 : Up. 172000 : Sen. 20,998,276 : Cost 43.88461304 : Time 458.59s : 44158.81 words/s : L.r. 9.1499e-05
[2019-02-08 10:08:14] Ep. 6 : Up. 173000 : Sen. 22,257,103 : Cost 44.66196060 : Time 457.32s : 44211.58 words/s : L.r. 9.1234e-05
[2019-02-08 10:15:53] Ep. 6 : Up. 174000 : Sen. 23,529,839 : Cost 44.23410034 : Time 459.59s : 44216.79 words/s : L.r. 9.0972e-05
[2019-02-08 10:23:29] Ep. 6 : Up. 175000 : Sen. 24,773,346 : Cost 44.86384201 : Time 455.38s : 44062.48 words/s : L.r. 9.0711e-05
[2019-02-08 10:23:29] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-08 10:23:30] Saving model weights and runtime parameters to ./model.npz
[2019-02-08 10:23:31] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-08 10:23:36] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-08 10:23:37] [valid] Ep. 6 : Up. 175000 : ce-mean-words : 1.56701 : new best
[2019-02-08 10:24:13] [valid] Ep. 6 : Up. 175000 : bleu-detok : 25.7336 : stalled 7 times (last best: 25.8666)
[2019-02-08 10:31:52] Ep. 6 : Up. 176000 : Sen. 26,030,416 : Cost 44.96317291 : Time 503.67s : 40363.54 words/s : L.r. 9.0453e-05
[2019-02-08 10:39:31] Ep. 6 : Up. 177000 : Sen. 27,298,802 : Cost 44.24919510 : Time 458.42s : 44259.90 words/s : L.r. 9.0198e-05
[2019-02-08 10:47:07] Ep. 6 : Up. 178000 : Sen. 28,555,341 : Cost 44.44461060 : Time 456.06s : 44085.08 words/s : L.r. 8.9944e-05
[2019-02-08 10:54:43] Ep. 6 : Up. 179000 : Sen. 29,808,843 : Cost 44.87086868 : Time 456.06s : 44337.42 words/s : L.r. 8.9692e-05
[2019-02-08 11:02:21] Ep. 6 : Up. 180000 : Sen. 31,084,638 : Cost 44.00619125 : Time 458.36s : 44177.91 words/s : L.r. 8.9443e-05
[2019-02-08 11:02:21] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-08 11:02:23] Saving model weights and runtime parameters to ./model.npz
[2019-02-08 11:02:24] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-08 11:02:28] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-08 11:02:29] [valid] Ep. 6 : Up. 180000 : ce-mean-words : 1.56491 : new best
[2019-02-08 11:03:08] [valid] Ep. 6 : Up. 180000 : bleu-detok : 25.7745 : stalled 8 times (last best: 25.8666)
[2019-02-08 11:10:46] Ep. 6 : Up. 181000 : Sen. 32,337,629 : Cost 44.69045639 : Time 504.74s : 40110.09 words/s : L.r. 8.9195e-05
[2019-02-08 11:18:24] Ep. 6 : Up. 182000 : Sen. 33,598,325 : Cost 44.57896423 : Time 458.21s : 44178.59 words/s : L.r. 8.8950e-05
[2019-02-08 11:26:00] Ep. 6 : Up. 183000 : Sen. 34,846,484 : Cost 44.82698822 : Time 455.97s : 44218.89 words/s : L.r. 8.8707e-05
[2019-02-08 11:33:38] Ep. 6 : Up. 184000 : Sen. 36,103,307 : Cost 44.61790466 : Time 458.39s : 44138.42 words/s : L.r. 8.8465e-05
[2019-02-08 11:41:17] Ep. 6 : Up. 185000 : Sen. 37,394,500 : Cost 43.78887558 : Time 458.77s : 44323.55 words/s : L.r. 8.8226e-05
[2019-02-08 11:41:17] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-08 11:41:19] Saving model weights and runtime parameters to ./model.npz
[2019-02-08 11:41:20] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-08 11:41:24] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-08 11:41:25] [valid] Ep. 6 : Up. 185000 : ce-mean-words : 1.56267 : new best
[2019-02-08 11:42:01] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-08 11:42:02] [valid] Ep. 6 : Up. 185000 : bleu-detok : 25.8882 : new best
[2019-02-08 11:49:37] Ep. 6 : Up. 186000 : Sen. 38,650,063 : Cost 44.27884674 : Time 500.07s : 40085.30 words/s : L.r. 8.7988e-05
[2019-02-08 11:52:40] Seen 39117679 samples
[2019-02-08 11:52:40] Starting epoch 7
[2019-02-08 11:52:40] [data] Shuffling data
[2019-02-08 11:52:42] [data] Done shuffling 39221657 sentences (cached in RAM)
[2019-02-08 11:58:28] Ep. 7 : Up. 187000 : Sen. 744,551 : Cost 44.86524200 : Time 530.48s : 37192.63 words/s : L.r. 8.7753e-05
[2019-02-08 12:06:06] Ep. 7 : Up. 188000 : Sen. 2,005,072 : Cost 44.49281693 : Time 458.75s : 44273.65 words/s : L.r. 8.7519e-05
[2019-02-08 12:13:44] Ep. 7 : Up. 189000 : Sen. 3,257,380 : Cost 44.56642151 : Time 457.58s : 44208.15 words/s : L.r. 8.7287e-05
[2019-02-08 12:21:20] Ep. 7 : Up. 190000 : Sen. 4,519,869 : Cost 43.86062622 : Time 456.26s : 43940.62 words/s : L.r. 8.7057e-05
[2019-02-08 12:21:20] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-08 12:21:22] Saving model weights and runtime parameters to ./model.npz
[2019-02-08 12:21:23] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-08 12:21:27] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-08 12:21:28] [valid] Ep. 7 : Up. 190000 : ce-mean-words : 1.56092 : new best
[2019-02-08 12:22:04] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-08 12:22:05] [valid] Ep. 7 : Up. 190000 : bleu-detok : 25.9553 : new best
[2019-02-08 12:29:45] Ep. 7 : Up. 191000 : Sen. 5,771,653 : Cost 45.02468491 : Time 504.36s : 40371.39 words/s : L.r. 8.6829e-05
[2019-02-08 12:37:24] Ep. 7 : Up. 192000 : Sen. 7,046,975 : Cost 44.06995773 : Time 459.63s : 44342.71 words/s : L.r. 8.6603e-05
[2019-02-08 12:45:00] Ep. 7 : Up. 193000 : Sen. 8,298,872 : Cost 44.31999207 : Time 455.53s : 44146.68 words/s : L.r. 8.6378e-05
[2019-02-08 12:52:37] Ep. 7 : Up. 194000 : Sen. 9,543,483 : Cost 44.93515778 : Time 457.11s : 44256.38 words/s : L.r. 8.6155e-05
[2019-02-08 13:00:16] Ep. 7 : Up. 195000 : Sen. 10,821,277 : Cost 43.69962311 : Time 458.72s : 44171.68 words/s : L.r. 8.5934e-05
[2019-02-08 13:00:16] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-08 13:00:17] Saving model weights and runtime parameters to ./model.npz
[2019-02-08 13:00:19] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-08 13:00:23] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-08 13:00:24] [valid] Ep. 7 : Up. 195000 : ce-mean-words : 1.5598 : new best
[2019-02-08 13:01:00] [valid] Ep. 7 : Up. 195000 : bleu-detok : 25.9043 : stalled 1 times (last best: 25.9553)
[2019-02-08 13:08:39] Ep. 7 : Up. 196000 : Sen. 12,092,396 : Cost 44.20298386 : Time 503.73s : 40300.47 words/s : L.r. 8.5714e-05
[2019-02-08 13:16:20] Ep. 7 : Up. 197000 : Sen. 13,334,761 : Cost 45.41532135 : Time 460.84s : 44311.60 words/s : L.r. 8.5496e-05
[2019-02-08 13:23:56] Ep. 7 : Up. 198000 : Sen. 14,612,097 : Cost 43.53337097 : Time 455.94s : 44051.78 words/s : L.r. 8.5280e-05
[2019-02-08 13:31:35] Ep. 7 : Up. 199000 : Sen. 15,873,911 : Cost 44.22179413 : Time 458.60s : 44119.04 words/s : L.r. 8.5066e-05
[2019-02-08 13:39:12] Ep. 7 : Up. 200000 : Sen. 17,136,046 : Cost 44.30290222 : Time 457.60s : 44176.86 words/s : L.r. 8.4853e-05
[2019-02-08 13:39:12] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-08 13:39:14] Saving model weights and runtime parameters to ./model.npz
[2019-02-08 13:39:16] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-08 13:39:20] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-08 13:39:21] [valid] Ep. 7 : Up. 200000 : ce-mean-words : 1.55853 : new best
[2019-02-08 13:39:58] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-08 13:39:59] [valid] Ep. 7 : Up. 200000 : bleu-detok : 25.9643 : new best
[2019-02-08 13:47:41] Ep. 7 : Up. 201000 : Sen. 18,402,080 : Cost 44.65863037 : Time 509.09s : 40260.33 words/s : L.r. 8.4641e-05
[2019-02-08 13:55:17] Ep. 7 : Up. 202000 : Sen. 19,656,525 : Cost 44.29953766 : Time 456.02s : 43998.74 words/s : L.r. 8.4432e-05
[2019-02-08 14:02:56] Ep. 7 : Up. 203000 : Sen. 20,919,846 : Cost 44.20148849 : Time 458.58s : 44152.97 words/s : L.r. 8.4223e-05
[2019-02-08 14:10:34] Ep. 7 : Up. 204000 : Sen. 22,184,533 : Cost 44.29564667 : Time 457.48s : 44208.59 words/s : L.r. 8.4017e-05
[2019-02-08 14:18:14] Ep. 7 : Up. 205000 : Sen. 23,442,779 : Cost 44.58103180 : Time 460.09s : 44236.85 words/s : L.r. 8.3812e-05
[2019-02-08 14:18:14] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-08 14:18:15] Saving model weights and runtime parameters to ./model.npz
[2019-02-08 14:18:16] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-08 14:18:20] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-08 14:18:21] [valid] Ep. 7 : Up. 205000 : ce-mean-words : 1.55665 : new best
[2019-02-08 14:18:58] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-08 14:18:59] [valid] Ep. 7 : Up. 205000 : bleu-detok : 26.0162 : new best
[2019-02-08 14:26:37] Ep. 7 : Up. 206000 : Sen. 24,695,200 : Cost 44.42741013 : Time 503.13s : 40089.71 words/s : L.r. 8.3608e-05
[2019-02-08 14:34:14] Ep. 7 : Up. 207000 : Sen. 25,962,035 : Cost 43.91955566 : Time 457.06s : 44058.62 words/s : L.r. 8.3406e-05
[2019-02-08 14:41:52] Ep. 7 : Up. 208000 : Sen. 27,198,208 : Cost 45.21776199 : Time 458.50s : 44196.39 words/s : L.r. 8.3205e-05
[2019-02-08 14:49:29] Ep. 7 : Up. 209000 : Sen. 28,497,331 : Cost 42.94088745 : Time 456.25s : 44144.94 words/s : L.r. 8.3006e-05
[2019-02-08 14:57:09] Ep. 7 : Up. 210000 : Sen. 29,746,167 : Cost 45.20594406 : Time 460.17s : 44426.28 words/s : L.r. 8.2808e-05
[2019-02-08 14:57:09] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-08 14:57:10] Saving model weights and runtime parameters to ./model.npz
[2019-02-08 14:57:12] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-08 14:57:16] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-08 14:57:17] [valid] Ep. 7 : Up. 210000 : ce-mean-words : 1.55467 : new best
[2019-02-08 14:57:53] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-08 14:57:54] [valid] Ep. 7 : Up. 210000 : bleu-detok : 26.03 : new best
[2019-02-08 15:05:30] Ep. 7 : Up. 211000 : Sen. 31,006,528 : Cost 43.92515945 : Time 501.23s : 40038.39 words/s : L.r. 8.2611e-05
[2019-02-08 15:13:08] Ep. 7 : Up. 212000 : Sen. 32,259,337 : Cost 44.85800934 : Time 457.68s : 44403.86 words/s : L.r. 8.2416e-05
[2019-02-08 15:20:45] Ep. 7 : Up. 213000 : Sen. 33,538,772 : Cost 43.42607880 : Time 457.40s : 44051.64 words/s : L.r. 8.2223e-05
[2019-02-08 15:28:21] Ep. 7 : Up. 214000 : Sen. 34,782,744 : Cost 44.81557465 : Time 456.30s : 44269.55 words/s : L.r. 8.2030e-05
[2019-02-08 15:35:58] Ep. 7 : Up. 215000 : Sen. 36,042,785 : Cost 44.01427841 : Time 456.28s : 44103.31 words/s : L.r. 8.1839e-05
[2019-02-08 15:35:58] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-08 15:35:59] Saving model weights and runtime parameters to ./model.npz
[2019-02-08 15:36:00] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-08 15:36:04] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-08 15:36:05] [valid] Ep. 7 : Up. 215000 : ce-mean-words : 1.55326 : new best
[2019-02-08 15:36:42] [valid] Ep. 7 : Up. 215000 : bleu-detok : 25.8523 : stalled 1 times (last best: 26.03)
[2019-02-08 15:44:22] Ep. 7 : Up. 216000 : Sen. 37,300,214 : Cost 44.63063049 : Time 504.00s : 40339.15 words/s : L.r. 8.1650e-05
[2019-02-08 15:51:58] Ep. 7 : Up. 217000 : Sen. 38,562,105 : Cost 43.98574448 : Time 456.75s : 44060.88 words/s : L.r. 8.1461e-05
[2019-02-08 15:55:29] Seen 39117679 samples
[2019-02-08 15:55:29] Starting epoch 8
[2019-02-08 15:55:29] [data] Shuffling data
[2019-02-08 15:55:31] [data] Done shuffling 39221657 sentences (cached in RAM)
[2019-02-08 16:00:53] Ep. 8 : Up. 218000 : Sen. 660,202 : Cost 45.31802750 : Time 534.39s : 37382.23 words/s : L.r. 8.1274e-05
[2019-02-08 16:08:29] Ep. 8 : Up. 219000 : Sen. 1,940,638 : Cost 43.08356476 : Time 456.61s : 44047.12 words/s : L.r. 8.1088e-05
[2019-02-08 16:16:08] Ep. 8 : Up. 220000 : Sen. 3,192,452 : Cost 44.41212082 : Time 458.33s : 44218.95 words/s : L.r. 8.0904e-05
[2019-02-08 16:16:08] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-08 16:16:09] Saving model weights and runtime parameters to ./model.npz
[2019-02-08 16:16:11] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-08 16:16:14] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-08 16:16:15] [valid] Ep. 8 : Up. 220000 : ce-mean-words : 1.55185 : new best
[2019-02-08 16:16:52] [valid] Ep. 8 : Up. 220000 : bleu-detok : 25.9396 : stalled 2 times (last best: 26.03)
[2019-02-08 16:24:29] Ep. 8 : Up. 221000 : Sen. 4,425,715 : Cost 44.94911194 : Time 501.60s : 40147.04 words/s : L.r. 8.0721e-05
[2019-02-08 16:32:04] Ep. 8 : Up. 222000 : Sen. 5,706,188 : Cost 43.03865814 : Time 455.15s : 44058.23 words/s : L.r. 8.0539e-05
[2019-02-08 16:39:43] Ep. 8 : Up. 223000 : Sen. 6,960,172 : Cost 44.57354736 : Time 458.43s : 44311.35 words/s : L.r. 8.0358e-05
[2019-02-08 16:47:20] Ep. 8 : Up. 224000 : Sen. 8,227,483 : Cost 43.85003281 : Time 456.96s : 44247.60 words/s : L.r. 8.0178e-05
[2019-02-08 16:55:00] Ep. 8 : Up. 225000 : Sen. 9,503,912 : Cost 43.82886505 : Time 460.48s : 44196.99 words/s : L.r. 8.0000e-05
[2019-02-08 16:55:00] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-08 16:55:02] Saving model weights and runtime parameters to ./model.npz
[2019-02-08 16:55:03] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-08 16:55:07] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-08 16:55:08] [valid] Ep. 8 : Up. 225000 : ce-mean-words : 1.55156 : new best
[2019-02-08 16:55:44] [valid] Ep. 8 : Up. 225000 : bleu-detok : 25.9665 : stalled 3 times (last best: 26.03)
[2019-02-08 17:03:20] Ep. 8 : Up. 226000 : Sen. 10,746,265 : Cost 44.54816818 : Time 499.95s : 40208.83 words/s : L.r. 7.9823e-05
[2019-02-08 17:10:59] Ep. 8 : Up. 227000 : Sen. 12,007,388 : Cost 44.25072098 : Time 458.74s : 44223.70 words/s : L.r. 7.9647e-05
[2019-02-08 17:18:36] Ep. 8 : Up. 228000 : Sen. 13,273,264 : Cost 43.88278198 : Time 456.97s : 44183.49 words/s : L.r. 7.9472e-05
[2019-02-08 17:26:14] Ep. 8 : Up. 229000 : Sen. 14,543,160 : Cost 43.83969879 : Time 458.37s : 44120.97 words/s : L.r. 7.9298e-05
[2019-02-08 17:33:51] Ep. 8 : Up. 230000 : Sen. 15,772,505 : Cost 45.21735001 : Time 456.61s : 44191.41 words/s : L.r. 7.9126e-05
[2019-02-08 17:33:51] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-08 17:33:52] Saving model weights and runtime parameters to ./model.npz
[2019-02-08 17:33:54] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-08 17:33:58] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-08 17:33:59] [valid] Ep. 8 : Up. 230000 : ce-mean-words : 1.55116 : new best
[2019-02-08 17:34:35] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-08 17:34:36] [valid] Ep. 8 : Up. 230000 : bleu-detok : 26.0839 : new best
[2019-02-08 17:42:16] Ep. 8 : Up. 231000 : Sen. 17,042,248 : Cost 44.03463364 : Time 504.94s : 40279.56 words/s : L.r. 7.8954e-05
[2019-02-08 17:49:54] Ep. 8 : Up. 232000 : Sen. 18,305,274 : Cost 43.97643280 : Time 457.81s : 44101.45 words/s : L.r. 7.8784e-05
[2019-02-08 17:57:30] Ep. 8 : Up. 233000 : Sen. 19,558,135 : Cost 44.19879150 : Time 456.23s : 44113.22 words/s : L.r. 7.8615e-05
[2019-02-08 18:05:09] Ep. 8 : Up. 234000 : Sen. 20,834,962 : Cost 43.64815140 : Time 459.00s : 44148.87 words/s : L.r. 7.8446e-05
[2019-02-08 18:12:43] Ep. 8 : Up. 235000 : Sen. 22,066,764 : Cost 44.84471130 : Time 454.41s : 44175.50 words/s : L.r. 7.8279e-05
[2019-02-08 18:12:43] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-08 18:12:45] Saving model weights and runtime parameters to ./model.npz
[2019-02-08 18:12:46] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-08 18:12:50] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-08 18:12:51] [valid] Ep. 8 : Up. 235000 : ce-mean-words : 1.55017 : new best
[2019-02-08 18:13:28] [valid] Ep. 8 : Up. 235000 : bleu-detok : 26.0215 : stalled 1 times (last best: 26.0839)
[2019-02-08 18:21:08] Ep. 8 : Up. 236000 : Sen. 23,329,521 : Cost 44.32063675 : Time 505.03s : 40301.43 words/s : L.r. 7.8113e-05
[2019-02-08 18:28:46] Ep. 8 : Up. 237000 : Sen. 24,597,033 : Cost 44.07601547 : Time 457.24s : 44275.75 words/s : L.r. 7.7948e-05
[2019-02-08 18:36:20] Ep. 8 : Up. 238000 : Sen. 25,843,379 : Cost 44.08313751 : Time 454.76s : 44021.81 words/s : L.r. 7.7784e-05
[2019-02-08 18:43:59] Ep. 8 : Up. 239000 : Sen. 27,108,652 : Cost 43.91215897 : Time 458.71s : 44191.57 words/s : L.r. 7.7622e-05
[2019-02-08 18:51:35] Ep. 8 : Up. 240000 : Sen. 28,355,480 : Cost 44.44257355 : Time 455.88s : 44143.29 words/s : L.r. 7.7460e-05
[2019-02-08 18:51:35] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-08 18:51:36] Saving model weights and runtime parameters to ./model.npz
[2019-02-08 18:51:38] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-08 18:51:42] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-08 18:51:43] [valid] Ep. 8 : Up. 240000 : ce-mean-words : 1.54873 : new best
[2019-02-08 18:52:19] [valid] Ep. 8 : Up. 240000 : bleu-detok : 25.9795 : stalled 2 times (last best: 26.0839)
[2019-02-08 18:59:57] Ep. 8 : Up. 241000 : Sen. 29,616,341 : Cost 44.23918533 : Time 501.65s : 40348.83 words/s : L.r. 7.7299e-05
[2019-02-08 19:07:38] Ep. 8 : Up. 242000 : Sen. 30,887,288 : Cost 43.98599243 : Time 461.05s : 44170.78 words/s : L.r. 7.7139e-05
[2019-02-08 19:15:15] Ep. 8 : Up. 243000 : Sen. 32,148,914 : Cost 44.10165787 : Time 457.41s : 44197.01 words/s : L.r. 7.6980e-05
[2019-02-08 19:22:53] Ep. 8 : Up. 244000 : Sen. 33,419,177 : Cost 43.73102188 : Time 457.87s : 44083.05 words/s : L.r. 7.6822e-05
[2019-02-08 19:30:33] Ep. 8 : Up. 245000 : Sen. 34,656,097 : Cost 45.33235550 : Time 460.07s : 44371.09 words/s : L.r. 7.6665e-05
[2019-02-08 19:30:33] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-08 19:30:35] Saving model weights and runtime parameters to ./model.npz
[2019-02-08 19:30:36] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-08 19:30:40] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-08 19:30:41] [valid] Ep. 8 : Up. 245000 : ce-mean-words : 1.5471 : new best
[2019-02-08 19:31:17] [valid] Ep. 8 : Up. 245000 : bleu-detok : 26.0788 : stalled 3 times (last best: 26.0839)
[2019-02-08 19:38:54] Ep. 8 : Up. 246000 : Sen. 35,939,113 : Cost 43.15723038 : Time 500.48s : 40208.95 words/s : L.r. 7.6509e-05
[2019-02-08 19:46:30] Ep. 8 : Up. 247000 : Sen. 37,193,040 : Cost 44.08321381 : Time 456.42s : 44099.12 words/s : L.r. 7.6354e-05
[2019-02-08 19:54:10] Ep. 8 : Up. 248000 : Sen. 38,471,193 : Cost 43.74981308 : Time 460.13s : 44204.78 words/s : L.r. 7.6200e-05
[2019-02-08 19:58:17] Seen 39117679 samples
[2019-02-08 19:58:17] Starting epoch 9
[2019-02-08 19:58:17] [data] Shuffling data
[2019-02-08 19:58:19] [data] Done shuffling 39221657 sentences (cached in RAM)
[2019-02-08 20:03:03] Ep. 9 : Up. 249000 : Sen. 570,711 : Cost 44.63010025 : Time 533.14s : 37129.53 words/s : L.r. 7.6047e-05
[2019-02-08 20:10:38] Ep. 9 : Up. 250000 : Sen. 1,819,283 : Cost 43.97695923 : Time 455.23s : 44074.07 words/s : L.r. 7.5895e-05
[2019-02-08 20:10:38] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-08 20:10:40] Saving model weights and runtime parameters to ./model.npz
[2019-02-08 20:10:41] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-08 20:10:45] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-08 20:10:46] [valid] Ep. 9 : Up. 250000 : ce-mean-words : 1.54559 : new best
[2019-02-08 20:11:23] [valid] Ep. 9 : Up. 250000 : bleu-detok : 25.9675 : stalled 4 times (last best: 26.0839)
[2019-02-08 20:19:02] Ep. 9 : Up. 251000 : Sen. 3,085,477 : Cost 43.98764038 : Time 503.43s : 40332.87 words/s : L.r. 7.5743e-05
[2019-02-08 20:26:41] Ep. 9 : Up. 252000 : Sen. 4,338,425 : Cost 44.46234131 : Time 459.59s : 44277.29 words/s : L.r. 7.5593e-05
[2019-02-08 20:34:18] Ep. 9 : Up. 253000 : Sen. 5,604,902 : Cost 43.51169586 : Time 456.34s : 44072.60 words/s : L.r. 7.5443e-05
[2019-02-08 20:41:56] Ep. 9 : Up. 254000 : Sen. 6,856,046 : Cost 44.29527664 : Time 458.13s : 44192.33 words/s : L.r. 7.5295e-05
[2019-02-08 20:49:35] Ep. 9 : Up. 255000 : Sen. 8,134,278 : Cost 43.49584579 : Time 458.67s : 44201.24 words/s : L.r. 7.5147e-05
[2019-02-08 20:49:35] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-08 20:49:36] Saving model weights and runtime parameters to ./model.npz
[2019-02-08 20:49:38] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-08 20:49:41] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-08 20:49:42] [valid] Ep. 9 : Up. 255000 : ce-mean-words : 1.54485 : new best
[2019-02-08 20:50:19] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-08 20:50:20] [valid] Ep. 9 : Up. 255000 : bleu-detok : 26.0879 : new best
[2019-02-08 20:58:00] Ep. 9 : Up. 256000 : Sen. 9,381,823 : Cost 44.68958664 : Time 504.99s : 40252.52 words/s : L.r. 7.5000e-05
[2019-02-08 21:05:37] Ep. 9 : Up. 257000 : Sen. 10,627,761 : Cost 44.42588806 : Time 457.50s : 44116.36 words/s : L.r. 7.4854e-05
[2019-02-08 21:13:14] Ep. 9 : Up. 258000 : Sen. 11,904,909 : Cost 43.24051666 : Time 457.40s : 44133.43 words/s : L.r. 7.4709e-05
[2019-02-08 21:20:53] Ep. 9 : Up. 259000 : Sen. 13,179,438 : Cost 43.65306473 : Time 458.66s : 44241.37 words/s : L.r. 7.4564e-05
[2019-02-08 21:28:29] Ep. 9 : Up. 260000 : Sen. 14,447,375 : Cost 43.65302277 : Time 455.82s : 44241.43 words/s : L.r. 7.4421e-05
[2019-02-08 21:28:29] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-08 21:28:31] Saving model weights and runtime parameters to ./model.npz
[2019-02-08 21:28:32] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-08 21:28:36] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-08 21:28:37] [valid] Ep. 9 : Up. 260000 : ce-mean-words : 1.54466 : new best
[2019-02-08 21:29:13] [valid] Ep. 9 : Up. 260000 : bleu-detok : 26.0377 : stalled 1 times (last best: 26.0879)
[2019-02-08 21:36:51] Ep. 9 : Up. 261000 : Sen. 15,674,018 : Cost 45.20431900 : Time 502.06s : 40281.88 words/s : L.r. 7.4278e-05
[2019-02-08 21:44:28] Ep. 9 : Up. 262000 : Sen. 16,931,883 : Cost 43.90758133 : Time 457.44s : 44126.43 words/s : L.r. 7.4136e-05
[2019-02-08 21:52:07] Ep. 9 : Up. 263000 : Sen. 18,185,516 : Cost 44.31865311 : Time 458.70s : 44159.45 words/s : L.r. 7.3995e-05
[2019-02-08 21:59:48] Ep. 9 : Up. 264000 : Sen. 19,475,816 : Cost 43.35359192 : Time 460.58s : 44273.23 words/s : L.r. 7.3855e-05
[2019-02-08 22:07:24] Ep. 9 : Up. 265000 : Sen. 20,735,456 : Cost 43.95892334 : Time 456.75s : 44212.77 words/s : L.r. 7.3715e-05
[2019-02-08 22:07:24] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-08 22:07:26] Saving model weights and runtime parameters to ./model.npz
[2019-02-08 22:07:27] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-08 22:07:31] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-08 22:07:32] [valid] Ep. 9 : Up. 265000 : ce-mean-words : 1.54359 : new best
[2019-02-08 22:08:09] [valid] Ep. 9 : Up. 265000 : bleu-detok : 26.0477 : stalled 2 times (last best: 26.0879)
[2019-02-08 22:15:44] Ep. 9 : Up. 266000 : Sen. 21,985,256 : Cost 43.95748520 : Time 499.26s : 40104.09 words/s : L.r. 7.3577e-05
[2019-02-08 22:23:22] Ep. 9 : Up. 267000 : Sen. 23,244,852 : Cost 43.93838501 : Time 457.76s : 44149.29 words/s : L.r. 7.3439e-05
[2019-02-08 22:31:01] Ep. 9 : Up. 268000 : Sen. 24,483,750 : Cost 45.12801361 : Time 459.65s : 44379.63 words/s : L.r. 7.3302e-05
[2019-02-08 22:38:40] Ep. 9 : Up. 269000 : Sen. 25,777,043 : Cost 42.86228180 : Time 458.73s : 44090.77 words/s : L.r. 7.3165e-05
[2019-02-08 22:46:16] Ep. 9 : Up. 270000 : Sen. 27,025,953 : Cost 44.19689178 : Time 456.28s : 44121.82 words/s : L.r. 7.3030e-05
[2019-02-08 22:46:16] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-08 22:46:18] Saving model weights and runtime parameters to ./model.npz
[2019-02-08 22:46:19] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-08 22:46:23] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-08 22:46:24] [valid] Ep. 9 : Up. 270000 : ce-mean-words : 1.54244 : new best
[2019-02-08 22:47:01] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-08 22:47:02] [valid] Ep. 9 : Up. 270000 : bleu-detok : 26.1844 : new best
[2019-02-08 22:54:39] Ep. 9 : Up. 271000 : Sen. 28,281,627 : Cost 43.98283005 : Time 503.15s : 40062.50 words/s : L.r. 7.2895e-05
[2019-02-08 23:02:17] Ep. 9 : Up. 272000 : Sen. 29,546,387 : Cost 44.00690460 : Time 457.27s : 44304.93 words/s : L.r. 7.2761e-05
[2019-02-08 23:09:55] Ep. 9 : Up. 273000 : Sen. 30,797,091 : Cost 44.35836029 : Time 458.36s : 44187.30 words/s : L.r. 7.2627e-05
[2019-02-08 23:17:33] Ep. 9 : Up. 274000 : Sen. 32,063,616 : Cost 43.63993835 : Time 457.99s : 44100.29 words/s : L.r. 7.2495e-05
[2019-02-08 23:25:12] Ep. 9 : Up. 275000 : Sen. 33,345,293 : Cost 43.58050537 : Time 458.92s : 44277.50 words/s : L.r. 7.2363e-05
[2019-02-08 23:25:12] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-08 23:25:13] Saving model weights and runtime parameters to ./model.npz
[2019-02-08 23:25:15] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-08 23:25:19] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-08 23:25:20] [valid] Ep. 9 : Up. 275000 : ce-mean-words : 1.54131 : new best
[2019-02-08 23:25:56] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-08 23:25:57] [valid] Ep. 9 : Up. 275000 : bleu-detok : 26.2435 : new best
[2019-02-08 23:27:54] [marian] Marian v1.7.7 45d3ce8 2019-02-03 11:18:10 +0000
[2019-02-08 23:27:54] [marian] Running on gpu-e-2 as process 184362 with command line:
[2019-02-08 23:27:54] [marian] /home/cs-grun1/marian/marian-dev/build-176fix/marian --model ./model.npz --type transformer --train-sets /home/cs-grun1/wmt19/data/corpus00.uniq.clean.nrm.csen.en.gz /home/cs-grun1/wmt19/data/corpus00.uniq.clean.nrm.csen.cs.gz --shuffle-in-ram --vocabs ./vocab.encs.spm ./vocab.encs.spm --dim-vocabs 32000 32000 --max-length 120 --mini-batch-fit -w 10000 --mini-batch 1000 --maxi-batch 1000 --devices 0 1 2 3 --sync-sgd --layer-normalization --tied-embeddings-all --exponential-smoothing --transformer-dropout 0.1 --label-smoothing 0.1 --transformer-preprocess n --transformer-postprocess da --transformer-heads 8 --enc-depth 6 --dec-depth 6 --learn-rate 0.0003 --lr-report --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --valid-freq 5000 --save-freq 5000 --disp-freq 1000 --disp-first 10 --valid-metrics ce-mean-words bleu-detok --valid-translation-output ./devset.bpe.cs.output --quiet-translation --valid-sets /home/cs-grun1/wmt19/data/newstest2016.en /home/cs-grun1/wmt19/data/newstest2016.cs --valid-mini-batch 32 --beam-size 8 --normalize 1 --early-stopping 5 --overwrite --keep-best --log ./train.log --valid-log ./valid.log
[2019-02-08 23:27:54] [config] after-batches: 0
[2019-02-08 23:27:54] [config] after-epochs: 0
[2019-02-08 23:27:54] [config] allow-unk: false
[2019-02-08 23:27:54] [config] beam-size: 8
[2019-02-08 23:27:54] [config] bert-class-symbol: "[CLS]"
[2019-02-08 23:27:54] [config] bert-mask-symbol: "[MASK]"
[2019-02-08 23:27:54] [config] bert-masking-fraction: 0.15
[2019-02-08 23:27:54] [config] bert-sep-symbol: "[SEP]"
[2019-02-08 23:27:54] [config] best-deep: false
[2019-02-08 23:27:54] [config] clip-gemm: 0
[2019-02-08 23:27:54] [config] clip-norm: 5
[2019-02-08 23:27:54] [config] cost-type: ce-mean
[2019-02-08 23:27:54] [config] cpu-threads: 0
[2019-02-08 23:27:54] [config] data-weighting: ""
[2019-02-08 23:27:54] [config] data-weighting-type: sentence
[2019-02-08 23:27:54] [config] dec-cell: gru
[2019-02-08 23:27:54] [config] dec-cell-base-depth: 2
[2019-02-08 23:27:54] [config] dec-cell-high-depth: 1
[2019-02-08 23:27:54] [config] dec-depth: 6
[2019-02-08 23:27:54] [config] devices:
[2019-02-08 23:27:54] [config]   - 0
[2019-02-08 23:27:54] [config]   - 1
[2019-02-08 23:27:54] [config]   - 2
[2019-02-08 23:27:54] [config]   - 3
[2019-02-08 23:27:54] [config] dim-emb: 512
[2019-02-08 23:27:54] [config] dim-rnn: 1024
[2019-02-08 23:27:54] [config] dim-vocabs:
[2019-02-08 23:27:54] [config]   - 32000
[2019-02-08 23:27:54] [config]   - 32000
[2019-02-08 23:27:54] [config] disp-first: 10
[2019-02-08 23:27:54] [config] disp-freq: 1000
[2019-02-08 23:27:54] [config] disp-label-counts: false
[2019-02-08 23:27:54] [config] dropout-rnn: 0
[2019-02-08 23:27:54] [config] dropout-src: 0
[2019-02-08 23:27:54] [config] dropout-trg: 0
[2019-02-08 23:27:54] [config] dump-config: ""
[2019-02-08 23:27:54] [config] early-stopping: 5
[2019-02-08 23:27:54] [config] embedding-fix-src: false
[2019-02-08 23:27:54] [config] embedding-fix-trg: false
[2019-02-08 23:27:54] [config] embedding-normalization: false
[2019-02-08 23:27:54] [config] embedding-vectors:
[2019-02-08 23:27:54] [config]   []
[2019-02-08 23:27:54] [config] enc-cell: gru
[2019-02-08 23:27:54] [config] enc-cell-depth: 1
[2019-02-08 23:27:54] [config] enc-depth: 6
[2019-02-08 23:27:54] [config] enc-type: bidirectional
[2019-02-08 23:27:54] [config] exponential-smoothing: 0.0001
[2019-02-08 23:27:54] [config] grad-dropping-momentum: 0
[2019-02-08 23:27:54] [config] grad-dropping-rate: 0
[2019-02-08 23:27:54] [config] grad-dropping-warmup: 100
[2019-02-08 23:27:54] [config] guided-alignment: none
[2019-02-08 23:27:54] [config] guided-alignment-cost: mse
[2019-02-08 23:27:54] [config] guided-alignment-weight: 0.1
[2019-02-08 23:27:54] [config] ignore-model-config: false
[2019-02-08 23:27:54] [config] input-types:
[2019-02-08 23:27:54] [config]   []
[2019-02-08 23:27:54] [config] interpolate-env-vars: false
[2019-02-08 23:27:54] [config] keep-best: true
[2019-02-08 23:27:54] [config] label-smoothing: 0.1
[2019-02-08 23:27:54] [config] layer-normalization: true
[2019-02-08 23:27:54] [config] learn-rate: 0.0003
[2019-02-08 23:27:54] [config] log: ./train.log
[2019-02-08 23:27:54] [config] log-level: info
[2019-02-08 23:27:54] [config] log-time-zone: ""
[2019-02-08 23:27:54] [config] lr-decay: 0
[2019-02-08 23:27:54] [config] lr-decay-freq: 50000
[2019-02-08 23:27:54] [config] lr-decay-inv-sqrt:
[2019-02-08 23:27:54] [config]   - 16000
[2019-02-08 23:27:54] [config] lr-decay-repeat-warmup: false
[2019-02-08 23:27:54] [config] lr-decay-reset-optimizer: false
[2019-02-08 23:27:54] [config] lr-decay-start:
[2019-02-08 23:27:54] [config]   - 10
[2019-02-08 23:27:54] [config]   - 1
[2019-02-08 23:27:54] [config] lr-decay-strategy: epoch+stalled
[2019-02-08 23:27:54] [config] lr-report: true
[2019-02-08 23:27:54] [config] lr-warmup: 16000
[2019-02-08 23:27:54] [config] lr-warmup-at-reload: false
[2019-02-08 23:27:54] [config] lr-warmup-cycle: false
[2019-02-08 23:27:54] [config] lr-warmup-start-rate: 0
[2019-02-08 23:27:54] [config] max-length: 120
[2019-02-08 23:27:54] [config] max-length-crop: false
[2019-02-08 23:27:54] [config] max-length-factor: 3
[2019-02-08 23:27:54] [config] maxi-batch: 1000
[2019-02-08 23:27:54] [config] maxi-batch-sort: trg
[2019-02-08 23:27:54] [config] mini-batch: 1000
[2019-02-08 23:27:54] [config] mini-batch-fit: true
[2019-02-08 23:27:54] [config] mini-batch-fit-step: 10
[2019-02-08 23:27:54] [config] mini-batch-overstuff: 1
[2019-02-08 23:27:54] [config] mini-batch-track-lr: false
[2019-02-08 23:27:54] [config] mini-batch-understuff: 1
[2019-02-08 23:27:54] [config] mini-batch-warmup: 0
[2019-02-08 23:27:54] [config] mini-batch-words: 0
[2019-02-08 23:27:54] [config] mini-batch-words-ref: 0
[2019-02-08 23:27:54] [config] model: ./model.npz
[2019-02-08 23:27:54] [config] multi-loss-type: sum
[2019-02-08 23:27:54] [config] multi-node: false
[2019-02-08 23:27:54] [config] multi-node-overlap: true
[2019-02-08 23:27:54] [config] n-best: false
[2019-02-08 23:27:54] [config] no-nccl: false
[2019-02-08 23:27:54] [config] no-reload: false
[2019-02-08 23:27:54] [config] no-restore-corpus: false
[2019-02-08 23:27:54] [config] no-shuffle: false
[2019-02-08 23:27:54] [config] normalize: 1
[2019-02-08 23:27:54] [config] num-devices: 0
[2019-02-08 23:27:54] [config] optimizer: adam
[2019-02-08 23:27:54] [config] optimizer-delay: 1
[2019-02-08 23:27:54] [config] optimizer-params:
[2019-02-08 23:27:54] [config]   - 0.9
[2019-02-08 23:27:54] [config]   - 0.98
[2019-02-08 23:27:54] [config]   - 1e-09
[2019-02-08 23:27:54] [config] overwrite: true
[2019-02-08 23:27:54] [config] pretrained-model: ""
[2019-02-08 23:27:54] [config] quiet: false
[2019-02-08 23:27:54] [config] quiet-translation: true
[2019-02-08 23:27:54] [config] relative-paths: false
[2019-02-08 23:27:54] [config] right-left: false
[2019-02-08 23:27:54] [config] save-freq: 5000
[2019-02-08 23:27:54] [config] seed: 0
[2019-02-08 23:27:54] [config] sentencepiece-alphas:
[2019-02-08 23:27:54] [config]   []
[2019-02-08 23:27:54] [config] sentencepiece-max-lines: 10000000
[2019-02-08 23:27:54] [config] sentencepiece-options: ""
[2019-02-08 23:27:54] [config] shuffle-in-ram: true
[2019-02-08 23:27:54] [config] skip: false
[2019-02-08 23:27:54] [config] sqlite: ""
[2019-02-08 23:27:54] [config] sqlite-drop: false
[2019-02-08 23:27:54] [config] sync-sgd: true
[2019-02-08 23:27:54] [config] tempdir: /tmp
[2019-02-08 23:27:54] [config] tied-embeddings: false
[2019-02-08 23:27:54] [config] tied-embeddings-all: true
[2019-02-08 23:27:54] [config] tied-embeddings-src: false
[2019-02-08 23:27:54] [config] train-sets:
[2019-02-08 23:27:54] [config]   - /home/cs-grun1/wmt19/data/corpus00.uniq.clean.nrm.csen.en.gz
[2019-02-08 23:27:54] [config]   - /home/cs-grun1/wmt19/data/corpus00.uniq.clean.nrm.csen.cs.gz
[2019-02-08 23:27:54] [config] transformer-aan-activation: swish
[2019-02-08 23:27:54] [config] transformer-aan-depth: 2
[2019-02-08 23:27:54] [config] transformer-aan-nogate: false
[2019-02-08 23:27:54] [config] transformer-decoder-autoreg: self-attention
[2019-02-08 23:27:54] [config] transformer-dim-aan: 2048
[2019-02-08 23:27:54] [config] transformer-dim-ffn: 2048
[2019-02-08 23:27:54] [config] transformer-dropout: 0.1
[2019-02-08 23:27:54] [config] transformer-dropout-attention: 0
[2019-02-08 23:27:54] [config] transformer-dropout-ffn: 0
[2019-02-08 23:27:54] [config] transformer-ffn-activation: swish
[2019-02-08 23:27:54] [config] transformer-ffn-depth: 2
[2019-02-08 23:27:54] [config] transformer-guided-alignment-layer: last
[2019-02-08 23:27:54] [config] transformer-heads: 8
[2019-02-08 23:27:54] [config] transformer-no-projection: false
[2019-02-08 23:27:54] [config] transformer-postprocess: da
[2019-02-08 23:27:54] [config] transformer-postprocess-emb: d
[2019-02-08 23:27:54] [config] transformer-preprocess: n
[2019-02-08 23:27:54] [config] transformer-tied-layers:
[2019-02-08 23:27:54] [config]   []
[2019-02-08 23:27:54] [config] transformer-train-positions: false
[2019-02-08 23:27:54] [config] type: transformer
[2019-02-08 23:27:54] [config] ulr: false
[2019-02-08 23:27:54] [config] ulr-dim-emb: 0
[2019-02-08 23:27:54] [config] ulr-dropout: 0
[2019-02-08 23:27:54] [config] ulr-keys-vectors: ""
[2019-02-08 23:27:54] [config] ulr-query-vectors: ""
[2019-02-08 23:27:54] [config] ulr-softmax-temperature: 1
[2019-02-08 23:27:54] [config] ulr-trainable-transformation: false
[2019-02-08 23:27:54] [config] valid-freq: 5000
[2019-02-08 23:27:54] [config] valid-log: ./valid.log
[2019-02-08 23:27:54] [config] valid-max-length: 1000
[2019-02-08 23:27:54] [config] valid-metrics:
[2019-02-08 23:27:54] [config]   - ce-mean-words
[2019-02-08 23:27:54] [config]   - bleu-detok
[2019-02-08 23:27:54] [config] valid-mini-batch: 32
[2019-02-08 23:27:54] [config] valid-script-path: ""
[2019-02-08 23:27:54] [config] valid-sets:
[2019-02-08 23:27:54] [config]   - /home/cs-grun1/wmt19/data/newstest2016.en
[2019-02-08 23:27:54] [config]   - /home/cs-grun1/wmt19/data/newstest2016.cs
[2019-02-08 23:27:54] [config] valid-translation-output: ./devset.bpe.cs.output
[2019-02-08 23:27:54] [config] version: v1.7.7 45d3ce8 2019-02-03 11:18:10 +0000
[2019-02-08 23:27:54] [config] vocabs:
[2019-02-08 23:27:54] [config]   - ./vocab.encs.spm
[2019-02-08 23:27:54] [config]   - ./vocab.encs.spm
[2019-02-08 23:27:54] [config] word-penalty: 0
[2019-02-08 23:27:54] [config] workspace: 10000
[2019-02-08 23:27:54] [config] Loaded model has been created with Marian v1.7.7 45d3ce8 2019-02-03 11:18:10 +0000
[2019-02-08 23:27:54] Using synchronous training
[2019-02-08 23:27:54] [data] Loading SentencePiece vocabulary from file ./vocab.encs.spm
[2019-02-08 23:27:54] [data] Setting vocabulary size for input 0 to 32000
[2019-02-08 23:27:54] [data] Loading SentencePiece vocabulary from file ./vocab.encs.spm
[2019-02-08 23:27:54] [data] Setting vocabulary size for input 1 to 32000
[2019-02-08 23:27:54] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-02-08 23:27:54] [batching] Collecting statistics for batch fitting with step size 10
[2019-02-08 23:27:55] [memory] Extending reserved space to 10112 MB (device gpu0)
[2019-02-08 23:27:55] [memory] Extending reserved space to 10112 MB (device gpu1)
[2019-02-08 23:27:56] [memory] Extending reserved space to 10112 MB (device gpu2)
[2019-02-08 23:27:57] [memory] Extending reserved space to 10112 MB (device gpu3)
[2019-02-08 23:27:57] [comm] Using NCCL 2.3.7 for GPU communication
[2019-02-08 23:27:57] [comm] NCCLCommunicator constructed successfully.
[2019-02-08 23:27:57] [training] Using 4 GPUs
[2019-02-08 23:27:57] [memory] Reserving 230 MB, device gpu0
[2019-02-08 23:27:57] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-02-08 23:27:57] [memory] Reserving 230 MB, device gpu0
[2019-02-08 23:28:18] [batching] Done. Typical MB size is 27396 target words
[2019-02-08 23:28:18] [memory] Extending reserved space to 10112 MB (device gpu0)
[2019-02-08 23:28:18] [memory] Extending reserved space to 10112 MB (device gpu1)
[2019-02-08 23:28:18] [memory] Extending reserved space to 10112 MB (device gpu2)
[2019-02-08 23:28:18] [memory] Extending reserved space to 10112 MB (device gpu3)
[2019-02-08 23:28:18] [comm] Using NCCL 2.3.7 for GPU communication
[2019-02-08 23:28:18] [comm] NCCLCommunicator constructed successfully.
[2019-02-08 23:28:18] [training] Using 4 GPUs
[2019-02-08 23:28:18] Loading model from ./model.npz.orig.npz
[2019-02-08 23:28:19] Loading model from ./model.npz.orig.npz
[2019-02-08 23:28:19] Loading model from ./model.npz.orig.npz
[2019-02-08 23:28:19] Loading model from ./model.npz.orig.npz
[2019-02-08 23:28:20] Loading Adam parameters from ./model.npz.optimizer.npz
[2019-02-08 23:28:20] [memory] Reserving 115 MB, device gpu0
[2019-02-08 23:28:20] [memory] Reserving 115 MB, device gpu1
[2019-02-08 23:28:20] [memory] Reserving 115 MB, device gpu2
[2019-02-08 23:28:20] [memory] Reserving 115 MB, device gpu3
[2019-02-08 23:28:20] [training] Model reloaded from ./model.npz
[2019-02-08 23:28:20] [data] Restoring the corpus state to epoch 9, batch 275000
[2019-02-08 23:28:20] [data] Shuffling data
[2019-02-08 23:28:59] [data] Done reading 39221657 sentences
[2019-02-08 23:29:01] [data] Done shuffling 39221657 sentences (cached in RAM)
[2019-02-09 00:12:23] Training started
[2019-02-09 00:12:23] [training] Batches are processed as 1 process(es) x 4 devices/process
[2019-02-09 00:12:23] [memory] Reserving 230 MB, device gpu1
[2019-02-09 00:12:23] [memory] Reserving 230 MB, device gpu2
[2019-02-09 00:12:23] [memory] Reserving 230 MB, device gpu3
[2019-02-09 00:12:23] [memory] Reserving 230 MB, device gpu0
[2019-02-09 00:12:23] [memory] Reserving 230 MB, device gpu1
[2019-02-09 00:12:23] [memory] Reserving 230 MB, device gpu3
[2019-02-09 00:12:23] [memory] Reserving 230 MB, device gpu0
[2019-02-09 00:12:23] [memory] Reserving 230 MB, device gpu2
[2019-02-09 00:12:23] Loading model from ./model.npz
[2019-02-09 00:12:24] [memory] Reserving 230 MB, device cpu0
[2019-02-09 00:12:24] [memory] Reserving 57 MB, device gpu0
[2019-02-09 00:12:24] [memory] Reserving 57 MB, device gpu1
[2019-02-09 00:12:24] [memory] Reserving 57 MB, device gpu2
[2019-02-09 00:12:24] [memory] Reserving 57 MB, device gpu3
[2019-02-09 00:20:01] Ep. 9 : Up. 276000 : Sen. 34,563,663 : Cost 45.60579681 : Time 3126.30s : 6485.39 words/s : L.r. 7.2232e-05
[2019-02-09 00:27:40] Ep. 9 : Up. 277000 : Sen. 35,857,391 : Cost 42.75308990 : Time 459.26s : 44090.92 words/s : L.r. 7.2101e-05
[2019-02-09 00:35:17] Ep. 9 : Up. 278000 : Sen. 37,117,211 : Cost 44.00181580 : Time 457.27s : 44117.29 words/s : L.r. 7.1971e-05
[2019-02-09 00:42:55] Ep. 9 : Up. 279000 : Sen. 38,352,284 : Cost 44.97529602 : Time 457.59s : 44317.37 words/s : L.r. 7.1842e-05
[2019-02-09 00:47:33] Seen 39117679 samples
[2019-02-09 00:47:33] Starting epoch 10
[2019-02-09 00:47:33] [data] Shuffling data
[2019-02-09 00:47:35] [data] Done shuffling 39221657 sentences (cached in RAM)
[2019-02-09 00:51:45] Ep. 10 : Up. 280000 : Sen. 459,295 : Cost 43.84804153 : Time 530.15s : 37094.68 words/s : L.r. 7.1714e-05
[2019-02-09 00:51:45] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-09 00:51:46] Saving model weights and runtime parameters to ./model.npz
[2019-02-09 00:51:47] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-09 00:51:51] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-09 00:51:52] [valid] Ep. 10 : Up. 280000 : ce-mean-words : 1.54073 : new best
[2019-02-09 00:52:28] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-09 00:52:28] [valid] Ep. 10 : Up. 280000 : bleu-detok : 26.2557 : new best
[2019-02-09 01:00:05] Ep. 10 : Up. 281000 : Sen. 1,729,674 : Cost 43.34545135 : Time 500.24s : 40273.19 words/s : L.r. 7.1586e-05
[2019-02-09 01:07:43] Ep. 10 : Up. 282000 : Sen. 2,996,444 : Cost 43.58074951 : Time 457.76s : 44204.69 words/s : L.r. 7.1459e-05
[2019-02-09 01:15:20] Ep. 10 : Up. 283000 : Sen. 4,241,340 : Cost 44.31917572 : Time 457.20s : 44199.96 words/s : L.r. 7.1333e-05
[2019-02-09 01:22:59] Ep. 10 : Up. 284000 : Sen. 5,521,011 : Cost 43.13373184 : Time 458.65s : 44185.06 words/s : L.r. 7.1207e-05
[2019-02-09 01:30:37] Ep. 10 : Up. 285000 : Sen. 6,788,432 : Cost 43.85079193 : Time 458.47s : 44264.05 words/s : L.r. 7.1082e-05
[2019-02-09 01:30:37] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-09 01:30:38] Saving model weights and runtime parameters to ./model.npz
[2019-02-09 01:30:40] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-09 01:30:44] [valid] Ep. 10 : Up. 285000 : ce-mean-words : 1.54088 : stalled 1 times (last best: 1.54073)
[2019-02-09 01:31:19] [valid] Ep. 10 : Up. 285000 : bleu-detok : 26.226 : stalled 1 times (last best: 26.2557)
[2019-02-09 01:38:56] Ep. 10 : Up. 286000 : Sen. 8,035,524 : Cost 44.10723877 : Time 498.55s : 40431.59 words/s : L.r. 7.0957e-05
[2019-02-09 01:46:31] Ep. 10 : Up. 287000 : Sen. 9,280,830 : Cost 44.15668869 : Time 455.25s : 44222.12 words/s : L.r. 7.0834e-05
[2019-02-09 01:54:09] Ep. 10 : Up. 288000 : Sen. 10,525,230 : Cost 44.66397095 : Time 458.29s : 44316.18 words/s : L.r. 7.0711e-05
[2019-02-09 02:01:48] Ep. 10 : Up. 289000 : Sen. 11,818,940 : Cost 42.87019348 : Time 459.20s : 44261.59 words/s : L.r. 7.0588e-05
[2019-02-09 02:09:24] Ep. 10 : Up. 290000 : Sen. 13,064,489 : Cost 44.12558365 : Time 455.73s : 44094.26 words/s : L.r. 7.0466e-05
[2019-02-09 02:09:24] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-09 02:09:25] Saving model weights and runtime parameters to ./model.npz
[2019-02-09 02:09:27] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-09 02:09:30] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-09 02:09:31] [valid] Ep. 10 : Up. 290000 : ce-mean-words : 1.54053 : new best
[2019-02-09 02:10:08] [valid] Ep. 10 : Up. 290000 : bleu-detok : 26.235 : stalled 2 times (last best: 26.2557)
[2019-02-09 02:17:46] Ep. 10 : Up. 291000 : Sen. 14,317,956 : Cost 44.24907684 : Time 501.77s : 40387.71 words/s : L.r. 7.0345e-05
[2019-02-09 02:25:25] Ep. 10 : Up. 292000 : Sen. 15,591,295 : Cost 43.54935074 : Time 458.74s : 44287.25 words/s : L.r. 7.0225e-05
[2019-02-09 02:33:01] Ep. 10 : Up. 293000 : Sen. 16,858,879 : Cost 43.40094757 : Time 456.77s : 44135.72 words/s : L.r. 7.0105e-05
[2019-02-09 02:40:38] Ep. 10 : Up. 294000 : Sen. 18,115,057 : Cost 43.97650909 : Time 456.53s : 44170.58 words/s : L.r. 6.9985e-05
[2019-02-09 02:48:17] Ep. 10 : Up. 295000 : Sen. 19,365,384 : Cost 44.28850174 : Time 458.82s : 44255.43 words/s : L.r. 6.9867e-05
[2019-02-09 02:48:17] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-09 02:48:18] Saving model weights and runtime parameters to ./model.npz
[2019-02-09 02:48:19] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-09 02:48:23] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-09 02:48:24] [valid] Ep. 10 : Up. 295000 : ce-mean-words : 1.53983 : new best
[2019-02-09 02:49:01] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-09 02:49:02] [valid] Ep. 10 : Up. 295000 : bleu-detok : 26.2615 : new best
[2019-02-09 02:56:41] Ep. 10 : Up. 296000 : Sen. 20,641,806 : Cost 43.21062851 : Time 504.00s : 40121.28 words/s : L.r. 6.9749e-05
[2019-02-09 03:04:16] Ep. 10 : Up. 297000 : Sen. 21,897,148 : Cost 43.99229431 : Time 455.30s : 44253.03 words/s : L.r. 6.9631e-05
[2019-02-09 03:11:55] Ep. 10 : Up. 298000 : Sen. 23,175,296 : Cost 43.58744812 : Time 459.35s : 44354.42 words/s : L.r. 6.9514e-05
[2019-02-09 03:19:36] Ep. 10 : Up. 299000 : Sen. 24,447,106 : Cost 43.74286652 : Time 460.83s : 44238.65 words/s : L.r. 6.9398e-05
[2019-02-09 03:27:12] Ep. 10 : Up. 300000 : Sen. 25,674,927 : Cost 44.78614044 : Time 455.81s : 44156.71 words/s : L.r. 6.9282e-05
[2019-02-09 03:27:12] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-09 03:27:13] Saving model weights and runtime parameters to ./model.npz
[2019-02-09 03:27:15] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-09 03:27:18] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-09 03:27:19] [valid] Ep. 10 : Up. 300000 : ce-mean-words : 1.53843 : new best
[2019-02-09 03:27:56] [valid] Ep. 10 : Up. 300000 : bleu-detok : 26.1889 : stalled 1 times (last best: 26.2615)
[2019-02-09 03:35:32] Ep. 10 : Up. 301000 : Sen. 26,935,181 : Cost 43.80469131 : Time 499.93s : 40342.14 words/s : L.r. 6.9167e-05
[2019-02-09 03:43:11] Ep. 10 : Up. 302000 : Sen. 28,188,432 : Cost 44.22863770 : Time 458.56s : 44208.57 words/s : L.r. 6.9052e-05
[2019-02-09 03:50:46] Ep. 10 : Up. 303000 : Sen. 29,451,894 : Cost 43.50210953 : Time 455.53s : 44120.18 words/s : L.r. 6.8938e-05
[2019-02-09 03:58:24] Ep. 10 : Up. 304000 : Sen. 30,704,695 : Cost 44.04069138 : Time 458.31s : 44176.93 words/s : L.r. 6.8825e-05
[2019-02-09 04:06:05] Ep. 10 : Up. 305000 : Sen. 31,986,484 : Cost 43.57801819 : Time 460.19s : 44367.50 words/s : L.r. 6.8712e-05
[2019-02-09 04:06:05] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-09 04:06:06] Saving model weights and runtime parameters to ./model.npz
[2019-02-09 04:06:07] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-09 04:06:11] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-09 04:06:12] [valid] Ep. 10 : Up. 305000 : ce-mean-words : 1.53701 : new best
[2019-02-09 04:06:49] [valid] Ep. 10 : Up. 305000 : bleu-detok : 26.2369 : stalled 2 times (last best: 26.2615)
[2019-02-09 04:14:27] Ep. 10 : Up. 306000 : Sen. 33,246,691 : Cost 43.78847885 : Time 502.77s : 40223.71 words/s : L.r. 6.8599e-05
[2019-02-09 04:22:06] Ep. 10 : Up. 307000 : Sen. 34,499,832 : Cost 44.21179962 : Time 458.25s : 44246.89 words/s : L.r. 6.8488e-05
[2019-02-09 04:29:42] Ep. 10 : Up. 308000 : Sen. 35,762,928 : Cost 43.68706512 : Time 456.32s : 44139.87 words/s : L.r. 6.8376e-05
[2019-02-09 04:37:22] Ep. 10 : Up. 309000 : Sen. 37,023,514 : Cost 43.99377060 : Time 459.60s : 44292.97 words/s : L.r. 6.8266e-05
[2019-02-09 04:44:59] Ep. 10 : Up. 310000 : Sen. 38,280,263 : Cost 44.02347183 : Time 457.25s : 44286.20 words/s : L.r. 6.8155e-05
[2019-02-09 04:44:59] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-09 04:45:00] Saving model weights and runtime parameters to ./model.npz
[2019-02-09 04:45:01] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-09 04:45:05] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-09 04:45:06] [valid] Ep. 10 : Up. 310000 : ce-mean-words : 1.53532 : new best
[2019-02-09 04:45:43] [valid] Ep. 10 : Up. 310000 : bleu-detok : 26.2239 : stalled 3 times (last best: 26.2615)
[2019-02-09 04:50:50] Seen 39117679 samples
[2019-02-09 04:50:50] Starting epoch 11
[2019-02-09 04:50:50] [data] Shuffling data
[2019-02-09 04:50:52] [data] Done shuffling 39221657 sentences (cached in RAM)
[2019-02-09 04:54:34] Ep. 11 : Up. 311000 : Sen. 411,908 : Cost 43.05747986 : Time 575.34s : 34247.81 words/s : L.r. 6.8046e-05
[2019-02-09 05:02:09] Ep. 11 : Up. 312000 : Sen. 1,633,215 : Cost 44.65276718 : Time 454.36s : 44040.96 words/s : L.r. 6.7937e-05
[2019-02-09 05:09:49] Ep. 11 : Up. 313000 : Sen. 2,916,381 : Cost 43.10978699 : Time 460.34s : 44258.20 words/s : L.r. 6.7828e-05
[2019-02-09 05:17:29] Ep. 11 : Up. 314000 : Sen. 4,168,432 : Cost 44.49679184 : Time 459.96s : 44394.00 words/s : L.r. 6.7720e-05
[2019-02-09 05:25:04] Ep. 11 : Up. 315000 : Sen. 5,431,132 : Cost 43.27828217 : Time 454.72s : 44076.99 words/s : L.r. 6.7612e-05
[2019-02-09 05:25:04] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-09 05:25:05] Saving model weights and runtime parameters to ./model.npz
[2019-02-09 05:25:06] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-09 05:25:09] [valid] Ep. 11 : Up. 315000 : ce-mean-words : 1.5355 : stalled 1 times (last best: 1.53532)
[2019-02-09 05:25:46] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-09 05:25:46] [valid] Ep. 11 : Up. 315000 : bleu-detok : 26.2697 : new best
[2019-02-09 05:33:26] Ep. 11 : Up. 316000 : Sen. 6,720,986 : Cost 42.80181503 : Time 502.42s : 40371.44 words/s : L.r. 6.7505e-05
[2019-02-09 05:41:03] Ep. 11 : Up. 317000 : Sen. 7,955,470 : Cost 44.65576553 : Time 457.36s : 44262.42 words/s : L.r. 6.7399e-05
[2019-02-09 05:48:40] Ep. 11 : Up. 318000 : Sen. 9,224,248 : Cost 43.08720779 : Time 456.34s : 44019.85 words/s : L.r. 6.7293e-05
[2019-02-09 05:56:16] Ep. 11 : Up. 319000 : Sen. 10,460,601 : Cost 44.53077316 : Time 456.63s : 44153.28 words/s : L.r. 6.7187e-05
[2019-02-09 06:03:56] Ep. 11 : Up. 320000 : Sen. 11,753,241 : Cost 42.95425797 : Time 459.86s : 44312.14 words/s : L.r. 6.7082e-05
[2019-02-09 06:03:56] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-09 06:03:57] Saving model weights and runtime parameters to ./model.npz
[2019-02-09 06:03:59] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-09 06:04:03] [valid] Ep. 11 : Up. 320000 : ce-mean-words : 1.53555 : stalled 2 times (last best: 1.53532)
[2019-02-09 06:04:39] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-09 06:04:39] [valid] Ep. 11 : Up. 320000 : bleu-detok : 26.2948 : new best
[2019-02-09 06:12:17] Ep. 11 : Up. 321000 : Sen. 12,996,896 : Cost 44.26760101 : Time 501.17s : 40355.92 words/s : L.r. 6.6977e-05
[2019-02-09 06:19:56] Ep. 11 : Up. 322000 : Sen. 14,261,889 : Cost 43.63631439 : Time 458.80s : 44197.79 words/s : L.r. 6.6873e-05
[2019-02-09 06:27:36] Ep. 11 : Up. 323000 : Sen. 15,515,160 : Cost 44.28293228 : Time 459.46s : 44296.93 words/s : L.r. 6.6770e-05
[2019-02-09 06:35:14] Ep. 11 : Up. 324000 : Sen. 16,805,981 : Cost 42.78865814 : Time 458.68s : 44186.76 words/s : L.r. 6.6667e-05
[2019-02-09 06:42:52] Ep. 11 : Up. 325000 : Sen. 18,057,773 : Cost 44.19774628 : Time 457.83s : 44307.53 words/s : L.r. 6.6564e-05
[2019-02-09 06:42:52] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-09 06:42:54] Saving model weights and runtime parameters to ./model.npz
[2019-02-09 06:42:55] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-09 06:42:59] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-09 06:43:00] [valid] Ep. 11 : Up. 325000 : ce-mean-words : 1.535 : new best
[2019-02-09 06:43:36] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-09 06:43:37] [valid] Ep. 11 : Up. 325000 : bleu-detok : 26.3279 : new best
[2019-02-09 06:51:15] Ep. 11 : Up. 326000 : Sen. 19,326,473 : Cost 43.53901291 : Time 503.21s : 40234.95 words/s : L.r. 6.6462e-05
[2019-02-09 06:58:54] Ep. 11 : Up. 327000 : Sen. 20,593,217 : Cost 43.72887802 : Time 459.13s : 44332.38 words/s : L.r. 6.6360e-05
[2019-02-09 07:06:32] Ep. 11 : Up. 328000 : Sen. 21,836,468 : Cost 44.31614685 : Time 457.17s : 44190.50 words/s : L.r. 6.6259e-05
[2019-02-09 07:14:09] Ep. 11 : Up. 329000 : Sen. 23,093,990 : Cost 43.90320206 : Time 457.31s : 44275.24 words/s : L.r. 6.6158e-05
[2019-02-09 07:21:45] Ep. 11 : Up. 330000 : Sen. 24,362,055 : Cost 43.17455292 : Time 456.34s : 44098.53 words/s : L.r. 6.6058e-05
[2019-02-09 07:21:45] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-09 07:21:47] Saving model weights and runtime parameters to ./model.npz
[2019-02-09 07:21:48] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-09 07:21:52] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-09 07:21:52] [valid] Ep. 11 : Up. 330000 : ce-mean-words : 1.53407 : new best
[2019-02-09 07:22:29] [valid] Ep. 11 : Up. 330000 : bleu-detok : 26.2785 : stalled 1 times (last best: 26.3279)
[2019-02-09 07:30:06] Ep. 11 : Up. 331000 : Sen. 25,598,160 : Cost 44.84951401 : Time 500.90s : 40345.36 words/s : L.r. 6.5958e-05
[2019-02-09 07:37:44] Ep. 11 : Up. 332000 : Sen. 26,872,444 : Cost 43.16021729 : Time 458.01s : 44280.56 words/s : L.r. 6.5859e-05
[2019-02-09 07:45:20] Ep. 11 : Up. 333000 : Sen. 28,122,190 : Cost 43.93489838 : Time 455.73s : 44111.97 words/s : L.r. 6.5760e-05
[2019-02-09 07:53:00] Ep. 11 : Up. 334000 : Sen. 29,400,965 : Cost 43.49104309 : Time 460.30s : 44312.52 words/s : L.r. 6.5661e-05
[2019-02-09 08:00:34] Ep. 11 : Up. 335000 : Sen. 30,648,438 : Cost 43.67618561 : Time 454.14s : 44058.32 words/s : L.r. 6.5563e-05
[2019-02-09 08:00:34] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-09 08:00:36] Saving model weights and runtime parameters to ./model.npz
[2019-02-09 08:00:37] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-09 08:00:40] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-09 08:00:41] [valid] Ep. 11 : Up. 335000 : ce-mean-words : 1.5329 : new best
[2019-02-09 08:01:19] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-09 08:01:20] [valid] Ep. 11 : Up. 335000 : bleu-detok : 26.3475 : new best
[2019-02-09 08:09:00] Ep. 11 : Up. 336000 : Sen. 31,913,203 : Cost 43.84786224 : Time 505.90s : 40239.27 words/s : L.r. 6.5465e-05
[2019-02-09 08:16:39] Ep. 11 : Up. 337000 : Sen. 33,176,130 : Cost 43.68115616 : Time 459.23s : 44135.45 words/s : L.r. 6.5368e-05
[2019-02-09 08:24:16] Ep. 11 : Up. 338000 : Sen. 34,444,184 : Cost 43.41423798 : Time 456.70s : 44214.65 words/s : L.r. 6.5271e-05
[2019-02-09 08:31:54] Ep. 11 : Up. 339000 : Sen. 35,715,799 : Cost 43.34507751 : Time 457.68s : 44184.68 words/s : L.r. 6.5175e-05
[2019-02-09 08:39:33] Ep. 11 : Up. 340000 : Sen. 36,961,680 : Cost 44.65074539 : Time 459.25s : 44375.35 words/s : L.r. 6.5079e-05
[2019-02-09 08:39:33] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-09 08:39:34] Saving model weights and runtime parameters to ./model.npz
[2019-02-09 08:39:36] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-09 08:39:39] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-09 08:39:40] [valid] Ep. 11 : Up. 340000 : ce-mean-words : 1.53163 : new best
[2019-02-09 08:40:16] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-09 08:40:17] [valid] Ep. 11 : Up. 340000 : bleu-detok : 26.3945 : new best
[2019-02-09 08:47:56] Ep. 11 : Up. 341000 : Sen. 38,234,408 : Cost 43.41769409 : Time 503.25s : 40337.92 words/s : L.r. 6.4984e-05
[2019-02-09 08:53:26] Seen 39117679 samples
[2019-02-09 08:53:26] Starting epoch 12
[2019-02-09 08:53:26] [data] Shuffling data
[2019-02-09 08:53:28] [data] Done shuffling 39221657 sentences (cached in RAM)
[2019-02-09 08:56:47] Ep. 12 : Up. 342000 : Sen. 328,588 : Cost 44.36528015 : Time 530.47s : 37157.99 words/s : L.r. 6.4889e-05
[2019-02-09 09:04:22] Ep. 12 : Up. 343000 : Sen. 1,567,870 : Cost 44.10262299 : Time 455.45s : 44107.77 words/s : L.r. 6.4794e-05
[2019-02-09 09:12:01] Ep. 12 : Up. 344000 : Sen. 2,852,166 : Cost 42.61821747 : Time 458.30s : 44119.52 words/s : L.r. 6.4700e-05
[2019-02-09 09:19:41] Ep. 12 : Up. 345000 : Sen. 4,116,968 : Cost 43.73831940 : Time 460.16s : 44238.92 words/s : L.r. 6.4606e-05
[2019-02-09 09:19:41] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-09 09:19:42] Saving model weights and runtime parameters to ./model.npz
[2019-02-09 09:19:43] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-09 09:19:47] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-09 09:19:48] [valid] Ep. 12 : Up. 345000 : ce-mean-words : 1.53141 : new best
[2019-02-09 09:20:24] [valid] Ep. 12 : Up. 345000 : bleu-detok : 26.268 : stalled 1 times (last best: 26.3945)
[2019-02-09 09:28:00] Ep. 12 : Up. 346000 : Sen. 5,380,132 : Cost 43.39691925 : Time 498.94s : 40309.76 words/s : L.r. 6.4512e-05
[2019-02-09 09:35:40] Ep. 12 : Up. 347000 : Sen. 6,622,580 : Cost 44.44430542 : Time 459.89s : 44379.41 words/s : L.r. 6.4419e-05
[2019-02-09 09:43:18] Ep. 12 : Up. 348000 : Sen. 7,896,724 : Cost 43.28582764 : Time 458.15s : 44204.35 words/s : L.r. 6.4327e-05
[2019-02-09 09:50:53] Ep. 12 : Up. 349000 : Sen. 9,167,620 : Cost 43.11818314 : Time 455.11s : 44238.53 words/s : L.r. 6.4235e-05
[2019-02-09 09:58:31] Ep. 12 : Up. 350000 : Sen. 10,393,275 : Cost 45.00767517 : Time 458.13s : 44409.49 words/s : L.r. 6.4143e-05
[2019-02-09 09:58:31] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-09 09:58:32] Saving model weights and runtime parameters to ./model.npz
[2019-02-09 09:58:33] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-09 09:58:37] [valid] Ep. 12 : Up. 350000 : ce-mean-words : 1.53149 : stalled 1 times (last best: 1.53141)
[2019-02-09 09:59:14] [valid] Ep. 12 : Up. 350000 : bleu-detok : 26.3175 : stalled 2 times (last best: 26.3945)
[2019-02-09 10:06:52] Ep. 12 : Up. 351000 : Sen. 11,688,477 : Cost 42.48706055 : Time 500.77s : 40280.00 words/s : L.r. 6.4051e-05
[2019-02-09 10:14:29] Ep. 12 : Up. 352000 : Sen. 12,936,342 : Cost 44.07674026 : Time 457.71s : 44190.96 words/s : L.r. 6.3960e-05
[2019-02-09 10:22:07] Ep. 12 : Up. 353000 : Sen. 14,193,630 : Cost 43.71917343 : Time 457.28s : 44222.57 words/s : L.r. 6.3870e-05
[2019-02-09 10:29:43] Ep. 12 : Up. 354000 : Sen. 15,462,692 : Cost 43.19440079 : Time 456.39s : 44114.41 words/s : L.r. 6.3779e-05
[2019-02-09 10:37:23] Ep. 12 : Up. 355000 : Sen. 16,740,282 : Cost 43.28453445 : Time 459.86s : 44309.65 words/s : L.r. 6.3689e-05
[2019-02-09 10:37:23] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-09 10:37:24] Saving model weights and runtime parameters to ./model.npz
[2019-02-09 10:37:25] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-09 10:37:30] [valid] Ep. 12 : Up. 355000 : ce-mean-words : 1.5318 : stalled 2 times (last best: 1.53141)
[2019-02-09 10:38:07] [valid] Ep. 12 : Up. 355000 : bleu-detok : 26.2544 : stalled 3 times (last best: 26.3945)
[2019-02-09 10:45:43] Ep. 12 : Up. 356000 : Sen. 17,980,546 : Cost 44.09182739 : Time 500.52s : 40127.43 words/s : L.r. 6.3600e-05
[2019-02-09 10:53:19] Ep. 12 : Up. 357000 : Sen. 19,221,749 : Cost 44.14425659 : Time 455.56s : 44188.51 words/s : L.r. 6.3511e-05
[2019-02-09 11:00:59] Ep. 12 : Up. 358000 : Sen. 20,475,358 : Cost 44.11052704 : Time 459.92s : 44285.52 words/s : L.r. 6.3422e-05
[2019-02-09 11:08:36] Ep. 12 : Up. 359000 : Sen. 21,733,187 : Cost 43.69891739 : Time 456.61s : 44127.53 words/s : L.r. 6.3334e-05
[2019-02-09 11:16:12] Ep. 12 : Up. 360000 : Sen. 23,006,112 : Cost 42.98449326 : Time 456.41s : 44147.66 words/s : L.r. 6.3246e-05
[2019-02-09 11:16:12] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-09 11:16:13] Saving model weights and runtime parameters to ./model.npz
[2019-02-09 11:16:15] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-09 11:16:18] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-09 11:16:19] [valid] Ep. 12 : Up. 360000 : ce-mean-words : 1.53097 : new best
[2019-02-09 11:16:56] [valid] Ep. 12 : Up. 360000 : bleu-detok : 26.3805 : stalled 4 times (last best: 26.3945)
[2019-02-09 11:24:35] Ep. 12 : Up. 361000 : Sen. 24,275,199 : Cost 43.72312546 : Time 503.50s : 40440.49 words/s : L.r. 6.3158e-05
[2019-02-09 11:32:11] Ep. 12 : Up. 362000 : Sen. 25,520,021 : Cost 43.79143906 : Time 455.69s : 44022.50 words/s : L.r. 6.3071e-05
[2019-02-09 11:39:47] Ep. 12 : Up. 363000 : Sen. 26,780,881 : Cost 43.55049515 : Time 456.21s : 44217.26 words/s : L.r. 6.2984e-05
[2019-02-09 11:47:25] Ep. 12 : Up. 364000 : Sen. 28,038,620 : Cost 43.67474747 : Time 457.40s : 44135.17 words/s : L.r. 6.2897e-05
[2019-02-09 11:55:03] Ep. 12 : Up. 365000 : Sen. 29,304,827 : Cost 43.48236847 : Time 458.02s : 44247.48 words/s : L.r. 6.2811e-05
[2019-02-09 11:55:03] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-09 11:55:04] Saving model weights and runtime parameters to ./model.npz
[2019-02-09 11:55:05] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-09 11:55:09] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-09 11:55:10] [valid] Ep. 12 : Up. 365000 : ce-mean-words : 1.52983 : new best
[2019-02-09 11:55:46] [valid] Ep. 12 : Up. 365000 : bleu-detok : 26.3914 : stalled 5 times (last best: 26.3945)
[2019-02-09 12:03:23] Ep. 12 : Up. 366000 : Sen. 30,537,924 : Cost 44.69775391 : Time 500.47s : 40401.81 words/s : L.r. 6.2725e-05
[2019-02-09 12:11:02] Ep. 12 : Up. 367000 : Sen. 31,827,800 : Cost 42.64306259 : Time 458.90s : 44192.14 words/s : L.r. 6.2639e-05
[2019-02-09 12:18:40] Ep. 12 : Up. 368000 : Sen. 33,081,226 : Cost 43.90943909 : Time 457.88s : 44220.58 words/s : L.r. 6.2554e-05
[2019-02-09 12:26:18] Ep. 12 : Up. 369000 : Sen. 34,336,724 : Cost 43.97581863 : Time 457.47s : 44288.30 words/s : L.r. 6.2470e-05
[2019-02-09 12:33:55] Ep. 12 : Up. 370000 : Sen. 35,595,484 : Cost 43.53995132 : Time 457.12s : 44136.86 words/s : L.r. 6.2385e-05
[2019-02-09 12:33:55] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-09 12:33:56] Saving model weights and runtime parameters to ./model.npz
[2019-02-09 12:33:57] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-09 12:34:01] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-09 12:34:01] [valid] Ep. 12 : Up. 370000 : ce-mean-words : 1.52838 : new best
[2019-02-09 12:34:38] [valid] Ep. 12 : Up. 370000 : bleu-detok : 26.3856 : stalled 6 times (last best: 26.3945)
[2019-02-09 12:42:17] Ep. 12 : Up. 371000 : Sen. 36,870,778 : Cost 43.39231110 : Time 502.68s : 40391.08 words/s : L.r. 6.2301e-05
[2019-02-09 12:49:53] Ep. 12 : Up. 372000 : Sen. 38,122,886 : Cost 43.68743134 : Time 455.78s : 44090.09 words/s : L.r. 6.2217e-05
[2019-02-09 12:56:02] Seen 39117679 samples
[2019-02-09 12:56:02] Starting epoch 13
[2019-02-09 12:56:02] [data] Shuffling data
[2019-02-09 12:56:04] [data] Done shuffling 39221657 sentences (cached in RAM)
[2019-02-09 12:58:44] Ep. 13 : Up. 373000 : Sen. 225,557 : Cost 44.04484177 : Time 531.00s : 37259.57 words/s : L.r. 6.2134e-05
[2019-02-09 13:06:23] Ep. 13 : Up. 374000 : Sen. 1,497,235 : Cost 43.43473434 : Time 458.42s : 44357.85 words/s : L.r. 6.2051e-05
[2019-02-09 13:14:01] Ep. 13 : Up. 375000 : Sen. 2,759,005 : Cost 43.46479416 : Time 458.69s : 44213.32 words/s : L.r. 6.1968e-05
[2019-02-09 13:14:01] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-09 13:14:02] Saving model weights and runtime parameters to ./model.npz
[2019-02-09 13:14:04] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-09 13:14:07] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-09 13:14:08] [valid] Ep. 13 : Up. 375000 : ce-mean-words : 1.5274 : new best
[2019-02-09 13:14:46] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-09 13:14:47] [valid] Ep. 13 : Up. 375000 : bleu-detok : 26.4385 : new best
[2019-02-09 13:22:22] Ep. 13 : Up. 376000 : Sen. 4,012,600 : Cost 43.33239365 : Time 500.66s : 40058.14 words/s : L.r. 6.1885e-05
[2019-02-09 13:29:59] Ep. 13 : Up. 377000 : Sen. 5,283,147 : Cost 43.09776306 : Time 457.58s : 44085.43 words/s : L.r. 6.1803e-05
[2019-02-09 13:37:39] Ep. 13 : Up. 378000 : Sen. 6,547,524 : Cost 43.75842285 : Time 459.69s : 44385.99 words/s : L.r. 6.1721e-05
[2019-02-09 13:45:17] Ep. 13 : Up. 379000 : Sen. 7,781,916 : Cost 44.46643066 : Time 457.99s : 44188.65 words/s : L.r. 6.1640e-05
[2019-02-09 13:52:52] Ep. 13 : Up. 380000 : Sen. 9,041,475 : Cost 43.25987625 : Time 454.59s : 44144.99 words/s : L.r. 6.1559e-05
[2019-02-09 13:52:52] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-09 13:52:53] Saving model weights and runtime parameters to ./model.npz
[2019-02-09 13:52:54] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-09 13:52:58] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-09 13:52:59] [valid] Ep. 13 : Up. 380000 : ce-mean-words : 1.52734 : new best
[2019-02-09 13:53:35] [valid] Ep. 13 : Up. 380000 : bleu-detok : 26.3625 : stalled 1 times (last best: 26.4385)
[2019-02-09 14:01:13] Ep. 13 : Up. 381000 : Sen. 10,302,854 : Cost 43.41504288 : Time 501.04s : 40285.76 words/s : L.r. 6.1478e-05
[2019-02-09 14:08:49] Ep. 13 : Up. 382000 : Sen. 11,567,876 : Cost 43.48531342 : Time 456.64s : 44285.06 words/s : L.r. 6.1397e-05
[2019-02-09 14:16:28] Ep. 13 : Up. 383000 : Sen. 12,847,596 : Cost 43.00979614 : Time 459.02s : 44259.93 words/s : L.r. 6.1317e-05
[2019-02-09 14:24:06] Ep. 13 : Up. 384000 : Sen. 14,084,024 : Cost 44.42570877 : Time 457.52s : 44198.27 words/s : L.r. 6.1237e-05
[2019-02-09 14:31:44] Ep. 13 : Up. 385000 : Sen. 15,350,427 : Cost 43.13712692 : Time 457.67s : 44073.03 words/s : L.r. 6.1158e-05
[2019-02-09 14:31:44] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-09 14:31:45] Saving model weights and runtime parameters to ./model.npz
[2019-02-09 14:31:46] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-09 14:31:50] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-09 14:31:50] [valid] Ep. 13 : Up. 385000 : ce-mean-words : 1.52713 : new best
[2019-02-09 14:32:27] [valid] Ep. 13 : Up. 385000 : bleu-detok : 26.3094 : stalled 2 times (last best: 26.4385)
[2019-02-09 14:40:06] Ep. 13 : Up. 386000 : Sen. 16,618,003 : Cost 43.32724762 : Time 501.92s : 40332.20 words/s : L.r. 6.1078e-05
[2019-02-09 14:47:42] Ep. 13 : Up. 387000 : Sen. 17,883,015 : Cost 43.56259537 : Time 456.94s : 44280.73 words/s : L.r. 6.0999e-05
[2019-02-09 14:55:20] Ep. 13 : Up. 388000 : Sen. 19,118,638 : Cost 44.55229950 : Time 458.01s : 44290.64 words/s : L.r. 6.0921e-05
[2019-02-09 15:02:54] Ep. 13 : Up. 389000 : Sen. 20,377,305 : Cost 42.93970871 : Time 453.76s : 43940.69 words/s : L.r. 6.0842e-05
[2019-02-09 15:10:36] Ep. 13 : Up. 390000 : Sen. 21,664,218 : Cost 43.08350754 : Time 461.47s : 44315.60 words/s : L.r. 6.0764e-05
[2019-02-09 15:10:36] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-09 15:10:37] Saving model weights and runtime parameters to ./model.npz
[2019-02-09 15:10:38] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-09 15:10:42] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-09 15:10:43] [valid] Ep. 13 : Up. 390000 : ce-mean-words : 1.52682 : new best
[2019-02-09 15:11:19] [valid] Ep. 13 : Up. 390000 : bleu-detok : 26.2556 : stalled 3 times (last best: 26.4385)
[2019-02-09 15:18:55] Ep. 13 : Up. 391000 : Sen. 22,902,167 : Cost 44.27467346 : Time 499.27s : 40345.16 words/s : L.r. 6.0687e-05
[2019-02-09 15:26:34] Ep. 13 : Up. 392000 : Sen. 24,164,383 : Cost 43.70582581 : Time 459.30s : 44215.78 words/s : L.r. 6.0609e-05
[2019-02-09 15:34:10] Ep. 13 : Up. 393000 : Sen. 25,430,582 : Cost 43.08509064 : Time 455.57s : 44128.39 words/s : L.r. 6.0532e-05
[2019-02-09 15:41:48] Ep. 13 : Up. 394000 : Sen. 26,665,266 : Cost 44.65412903 : Time 457.67s : 44271.17 words/s : L.r. 6.0455e-05
[2019-02-09 15:49:26] Ep. 13 : Up. 395000 : Sen. 27,950,090 : Cost 42.87678528 : Time 458.56s : 44228.79 words/s : L.r. 6.0379e-05
[2019-02-09 15:49:26] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-09 15:49:27] Saving model weights and runtime parameters to ./model.npz
[2019-02-09 15:49:29] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-09 15:49:32] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-09 15:49:33] [valid] Ep. 13 : Up. 395000 : ce-mean-words : 1.52617 : new best
[2019-02-09 15:50:09] [valid] Ep. 13 : Up. 395000 : bleu-detok : 26.3463 : stalled 4 times (last best: 26.4385)
[2019-02-09 15:57:47] Ep. 13 : Up. 396000 : Sen. 29,215,621 : Cost 43.48611450 : Time 501.28s : 40457.02 words/s : L.r. 6.0302e-05
[2019-02-09 16:05:26] Ep. 13 : Up. 397000 : Sen. 30,489,344 : Cost 43.25201797 : Time 458.95s : 44321.51 words/s : L.r. 6.0226e-05
[2019-02-09 16:13:02] Ep. 13 : Up. 398000 : Sen. 31,733,734 : Cost 44.05344391 : Time 455.64s : 44096.17 words/s : L.r. 6.0151e-05
[2019-02-09 16:20:41] Ep. 13 : Up. 399000 : Sen. 32,993,530 : Cost 43.69655609 : Time 459.12s : 44282.79 words/s : L.r. 6.0075e-05
[2019-02-09 16:28:18] Ep. 13 : Up. 400000 : Sen. 34,253,292 : Cost 43.49449158 : Time 456.94s : 44143.91 words/s : L.r. 6.0000e-05
[2019-02-09 16:28:18] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-09 16:28:19] Saving model weights and runtime parameters to ./model.npz
[2019-02-09 16:28:20] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-09 16:28:24] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-09 16:28:25] [valid] Ep. 13 : Up. 400000 : ce-mean-words : 1.52583 : new best
[2019-02-09 16:29:01] [valid] Ep. 13 : Up. 400000 : bleu-detok : 26.3503 : stalled 5 times (last best: 26.4385)
[2019-02-09 16:36:37] Ep. 13 : Up. 401000 : Sen. 35,500,473 : Cost 43.80238342 : Time 499.36s : 40254.21 words/s : L.r. 5.9925e-05
[2019-02-09 16:44:17] Ep. 13 : Up. 402000 : Sen. 36,790,655 : Cost 42.96184158 : Time 459.97s : 44399.54 words/s : L.r. 5.9851e-05
[2019-02-09 16:51:55] Ep. 13 : Up. 403000 : Sen. 38,039,391 : Cost 43.89655304 : Time 458.08s : 44080.47 words/s : L.r. 5.9776e-05
[2019-02-09 16:58:35] Seen 39117679 samples
[2019-02-09 16:58:35] Starting epoch 14
[2019-02-09 16:58:35] [data] Shuffling data
[2019-02-09 16:58:37] [data] Done shuffling 39221657 sentences (cached in RAM)
[2019-02-09 17:00:44] Ep. 14 : Up. 404000 : Sen. 140,333 : Cost 43.97524261 : Time 529.03s : 37277.27 words/s : L.r. 5.9702e-05
[2019-02-09 17:08:22] Ep. 14 : Up. 405000 : Sen. 1,407,615 : Cost 43.37541199 : Time 457.91s : 44321.64 words/s : L.r. 5.9628e-05
[2019-02-09 17:08:22] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-09 17:08:23] Saving model weights and runtime parameters to ./model.npz
[2019-02-09 17:08:25] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-09 17:08:28] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-09 17:08:29] [valid] Ep. 14 : Up. 405000 : ce-mean-words : 1.52519 : new best
[2019-02-09 17:09:05] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-09 17:09:06] [valid] Ep. 14 : Up. 405000 : bleu-detok : 26.5428 : new best
[2019-02-09 17:16:45] Ep. 14 : Up. 406000 : Sen. 2,678,566 : Cost 42.91080093 : Time 502.74s : 40278.56 words/s : L.r. 5.9555e-05
[2019-02-09 17:24:23] Ep. 14 : Up. 407000 : Sen. 3,936,300 : Cost 43.63894272 : Time 458.07s : 44214.79 words/s : L.r. 5.9482e-05
[2019-02-09 17:32:02] Ep. 14 : Up. 408000 : Sen. 5,204,551 : Cost 43.23561478 : Time 458.97s : 44204.99 words/s : L.r. 5.9409e-05
[2019-02-09 17:39:41] Ep. 14 : Up. 409000 : Sen. 6,442,680 : Cost 44.42773438 : Time 458.35s : 44292.39 words/s : L.r. 5.9336e-05
[2019-02-09 17:47:18] Ep. 14 : Up. 410000 : Sen. 7,719,095 : Cost 42.76788330 : Time 457.69s : 44053.24 words/s : L.r. 5.9264e-05
[2019-02-09 17:47:18] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-09 17:47:19] Saving model weights and runtime parameters to ./model.npz
[2019-02-09 17:47:21] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-09 17:47:24] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-09 17:47:25] [valid] Ep. 14 : Up. 410000 : ce-mean-words : 1.52475 : new best
[2019-02-09 17:48:01] [valid] Ep. 14 : Up. 410000 : bleu-detok : 26.5219 : stalled 1 times (last best: 26.5428)
[2019-02-09 17:55:40] Ep. 14 : Up. 411000 : Sen. 8,983,368 : Cost 43.63417053 : Time 501.91s : 40495.71 words/s : L.r. 5.9192e-05
[2019-02-09 18:03:18] Ep. 14 : Up. 412000 : Sen. 10,246,744 : Cost 43.46459579 : Time 457.76s : 44218.08 words/s : L.r. 5.9120e-05
[2019-02-09 18:10:56] Ep. 14 : Up. 413000 : Sen. 11,494,958 : Cost 44.07049942 : Time 458.14s : 44362.39 words/s : L.r. 5.9048e-05
[2019-02-09 18:18:34] Ep. 14 : Up. 414000 : Sen. 12,764,553 : Cost 43.20643997 : Time 458.09s : 44183.79 words/s : L.r. 5.8977e-05
[2019-02-09 18:26:09] Ep. 14 : Up. 415000 : Sen. 14,020,666 : Cost 43.36139679 : Time 455.31s : 44124.17 words/s : L.r. 5.8906e-05
[2019-02-09 18:26:09] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-09 18:26:11] Saving model weights and runtime parameters to ./model.npz
[2019-02-09 18:26:12] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-09 18:26:15] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-09 18:26:16] [valid] Ep. 14 : Up. 415000 : ce-mean-words : 1.52451 : new best
[2019-02-09 18:26:52] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-09 18:26:53] [valid] Ep. 14 : Up. 415000 : bleu-detok : 26.5656 : new best
[2019-02-09 18:34:32] Ep. 14 : Up. 416000 : Sen. 15,279,640 : Cost 43.51910782 : Time 502.17s : 40284.94 words/s : L.r. 5.8835e-05
[2019-02-09 18:42:10] Ep. 14 : Up. 417000 : Sen. 16,551,821 : Cost 43.22962952 : Time 458.29s : 44235.24 words/s : L.r. 5.8764e-05
[2019-02-09 18:49:47] Ep. 14 : Up. 418000 : Sen. 17,793,808 : Cost 44.14319611 : Time 457.49s : 44219.36 words/s : L.r. 5.8694e-05
[2019-02-09 18:57:25] Ep. 14 : Up. 419000 : Sen. 19,065,582 : Cost 43.11100769 : Time 457.22s : 44237.03 words/s : L.r. 5.8624e-05
[2019-02-09 19:05:01] Ep. 14 : Up. 420000 : Sen. 20,325,752 : Cost 43.30678177 : Time 456.73s : 44053.34 words/s : L.r. 5.8554e-05
[2019-02-09 19:05:01] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-09 19:05:03] Saving model weights and runtime parameters to ./model.npz
[2019-02-09 19:05:04] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-09 19:05:08] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-09 19:05:08] [valid] Ep. 14 : Up. 420000 : ce-mean-words : 1.52417 : new best
[2019-02-09 19:05:44] [valid] Ep. 14 : Up. 420000 : bleu-detok : 26.5298 : stalled 1 times (last best: 26.5656)
[2019-02-09 19:13:22] Ep. 14 : Up. 421000 : Sen. 21,573,620 : Cost 44.03601837 : Time 500.60s : 40489.59 words/s : L.r. 5.8484e-05
[2019-02-09 19:20:57] Ep. 14 : Up. 422000 : Sen. 22,817,223 : Cost 43.72763443 : Time 455.05s : 44122.14 words/s : L.r. 5.8415e-05
[2019-02-09 19:28:37] Ep. 14 : Up. 423000 : Sen. 24,083,876 : Cost 43.57281876 : Time 459.61s : 44267.52 words/s : L.r. 5.8346e-05
[2019-02-09 19:36:16] Ep. 14 : Up. 424000 : Sen. 25,360,046 : Cost 43.12612152 : Time 459.11s : 44294.52 words/s : L.r. 5.8277e-05
[2019-02-09 19:43:51] Ep. 14 : Up. 425000 : Sen. 26,617,293 : Cost 43.38004303 : Time 455.09s : 44042.14 words/s : L.r. 5.8209e-05
[2019-02-09 19:43:51] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-09 19:43:52] Saving model weights and runtime parameters to ./model.npz
[2019-02-09 19:43:53] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-09 19:43:57] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-09 19:43:58] [valid] Ep. 14 : Up. 425000 : ce-mean-words : 1.52368 : new best
[2019-02-09 19:44:36] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-09 19:44:37] [valid] Ep. 14 : Up. 425000 : bleu-detok : 26.5813 : new best
[2019-02-09 19:52:13] Ep. 14 : Up. 426000 : Sen. 27,869,314 : Cost 43.71563339 : Time 502.24s : 40243.57 words/s : L.r. 5.8140e-05
[2019-02-09 19:59:52] Ep. 14 : Up. 427000 : Sen. 29,125,483 : Cost 43.74544144 : Time 458.52s : 44242.61 words/s : L.r. 5.8072e-05
[2019-02-09 20:07:29] Ep. 14 : Up. 428000 : Sen. 30,409,136 : Cost 42.55224228 : Time 457.63s : 44066.22 words/s : L.r. 5.8004e-05
[2019-02-09 20:15:07] Ep. 14 : Up. 429000 : Sen. 31,638,401 : Cost 44.86437988 : Time 457.71s : 44388.65 words/s : L.r. 5.7937e-05
[2019-02-09 20:22:43] Ep. 14 : Up. 430000 : Sen. 32,919,965 : Cost 42.63869476 : Time 456.64s : 44143.08 words/s : L.r. 5.7869e-05
[2019-02-09 20:22:43] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-09 20:22:45] Saving model weights and runtime parameters to ./model.npz
[2019-02-09 20:22:46] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-09 20:22:50] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-09 20:22:51] [valid] Ep. 14 : Up. 430000 : ce-mean-words : 1.5233 : new best
[2019-02-09 20:23:29] [valid] Ep. 14 : Up. 430000 : bleu-detok : 26.5675 : stalled 1 times (last best: 26.5813)
[2019-02-09 20:31:08] Ep. 14 : Up. 431000 : Sen. 34,188,329 : Cost 43.36145401 : Time 504.69s : 40219.25 words/s : L.r. 5.7802e-05
[2019-02-09 20:38:45] Ep. 14 : Up. 432000 : Sen. 35,456,595 : Cost 43.36067963 : Time 457.30s : 44253.59 words/s : L.r. 5.7735e-05
[2019-02-09 20:46:24] Ep. 14 : Up. 433000 : Sen. 36,683,774 : Cost 44.75835419 : Time 458.60s : 44224.66 words/s : L.r. 5.7668e-05
[2019-02-09 20:53:59] Ep. 14 : Up. 434000 : Sen. 37,935,978 : Cost 43.30461502 : Time 454.51s : 43999.85 words/s : L.r. 5.7602e-05
[2019-02-09 21:01:11] Seen 39117679 samples
[2019-02-09 21:01:11] Starting epoch 15
[2019-02-09 21:01:11] [data] Shuffling data
[2019-02-09 21:01:13] [data] Done shuffling 39221657 sentences (cached in RAM)
[2019-02-09 21:02:49] Ep. 15 : Up. 435000 : Sen. 61,366 : Cost 43.11277390 : Time 529.91s : 37245.26 words/s : L.r. 5.7536e-05
[2019-02-09 21:02:49] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-09 21:02:50] Saving model weights and runtime parameters to ./model.npz
[2019-02-09 21:02:51] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-09 21:02:55] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-09 21:02:56] [valid] Ep. 15 : Up. 435000 : ce-mean-words : 1.52292 : new best
[2019-02-09 21:03:34] [valid] Ep. 15 : Up. 435000 : bleu-detok : 26.4078 : stalled 2 times (last best: 26.5813)
[2019-02-09 21:11:12] Ep. 15 : Up. 436000 : Sen. 1,318,213 : Cost 43.24277115 : Time 503.79s : 40042.48 words/s : L.r. 5.7470e-05
[2019-02-09 21:18:52] Ep. 15 : Up. 437000 : Sen. 2,575,483 : Cost 43.79550552 : Time 459.39s : 44323.09 words/s : L.r. 5.7404e-05
[2019-02-09 21:26:30] Ep. 15 : Up. 438000 : Sen. 3,839,286 : Cost 43.32712936 : Time 457.99s : 44201.41 words/s : L.r. 5.7338e-05
[2019-02-09 21:34:07] Ep. 15 : Up. 439000 : Sen. 5,102,912 : Cost 43.27029419 : Time 456.92s : 44208.53 words/s : L.r. 5.7273e-05
[2019-02-09 21:41:44] Ep. 15 : Up. 440000 : Sen. 6,358,422 : Cost 43.49878311 : Time 457.47s : 44224.42 words/s : L.r. 5.7208e-05
[2019-02-09 21:41:44] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-09 21:41:45] Saving model weights and runtime parameters to ./model.npz
[2019-02-09 21:41:46] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-09 21:41:51] [valid] Ep. 15 : Up. 440000 : ce-mean-words : 1.52306 : stalled 1 times (last best: 1.52292)
[2019-02-09 21:42:27] [valid] Ep. 15 : Up. 440000 : bleu-detok : 26.3983 : stalled 3 times (last best: 26.5813)
[2019-02-09 21:50:06] Ep. 15 : Up. 441000 : Sen. 7,623,645 : Cost 43.35475540 : Time 501.91s : 40465.18 words/s : L.r. 5.7143e-05
[2019-02-09 21:57:42] Ep. 15 : Up. 442000 : Sen. 8,888,915 : Cost 43.05474854 : Time 455.95s : 44094.83 words/s : L.r. 5.7078e-05
[2019-02-09 22:05:21] Ep. 15 : Up. 443000 : Sen. 10,136,938 : Cost 44.17140579 : Time 459.13s : 44434.75 words/s : L.r. 5.7014e-05
[2019-02-09 22:12:57] Ep. 15 : Up. 444000 : Sen. 11,369,643 : Cost 44.21920013 : Time 455.79s : 44171.88 words/s : L.r. 5.6949e-05
[2019-02-09 22:20:32] Ep. 15 : Up. 445000 : Sen. 12,648,953 : Cost 42.53984451 : Time 455.28s : 44071.21 words/s : L.r. 5.6885e-05
[2019-02-09 22:20:32] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-09 22:20:33] Saving model weights and runtime parameters to ./model.npz
[2019-02-09 22:20:35] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-09 22:20:39] [valid] Ep. 15 : Up. 445000 : ce-mean-words : 1.52326 : stalled 2 times (last best: 1.52292)
[2019-02-09 22:21:17] [valid] Ep. 15 : Up. 445000 : bleu-detok : 26.4115 : stalled 4 times (last best: 26.5813)
[2019-02-09 22:28:57] Ep. 15 : Up. 446000 : Sen. 13,905,789 : Cost 43.68885803 : Time 505.13s : 40234.04 words/s : L.r. 5.6822e-05
[2019-02-09 22:36:36] Ep. 15 : Up. 447000 : Sen. 15,184,669 : Cost 42.85676956 : Time 458.27s : 44111.11 words/s : L.r. 5.6758e-05
[2019-02-09 22:44:15] Ep. 15 : Up. 448000 : Sen. 16,425,444 : Cost 44.29426956 : Time 459.91s : 44251.15 words/s : L.r. 5.6695e-05
[2019-02-09 22:51:51] Ep. 15 : Up. 449000 : Sen. 17,679,660 : Cost 43.61012650 : Time 455.72s : 44255.24 words/s : L.r. 5.6632e-05
[2019-02-09 22:59:30] Ep. 15 : Up. 450000 : Sen. 18,958,359 : Cost 42.81974792 : Time 459.30s : 44133.85 words/s : L.r. 5.6569e-05
[2019-02-09 22:59:30] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-09 22:59:32] Saving model weights and runtime parameters to ./model.npz
[2019-02-09 22:59:33] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-09 22:59:37] [valid] Ep. 15 : Up. 450000 : ce-mean-words : 1.52295 : stalled 3 times (last best: 1.52292)
[2019-02-09 23:00:15] [valid] Ep. 15 : Up. 450000 : bleu-detok : 26.4336 : stalled 5 times (last best: 26.5813)
[2019-02-09 23:07:52] Ep. 15 : Up. 451000 : Sen. 20,222,157 : Cost 43.49277496 : Time 501.83s : 40322.28 words/s : L.r. 5.6506e-05
[2019-02-09 23:15:30] Ep. 15 : Up. 452000 : Sen. 21,498,720 : Cost 42.71221542 : Time 457.99s : 44131.78 words/s : L.r. 5.6443e-05
[2019-02-09 23:23:07] Ep. 15 : Up. 453000 : Sen. 22,731,923 : Cost 44.43718338 : Time 456.55s : 44217.40 words/s : L.r. 5.6381e-05
[2019-02-09 23:30:45] Ep. 15 : Up. 454000 : Sen. 23,998,472 : Cost 43.20261383 : Time 457.90s : 44207.83 words/s : L.r. 5.6319e-05
[2019-02-09 23:38:25] Ep. 15 : Up. 455000 : Sen. 25,260,367 : Cost 43.73683929 : Time 460.42s : 44291.66 words/s : L.r. 5.6257e-05
[2019-02-09 23:38:25] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-09 23:38:26] Saving model weights and runtime parameters to ./model.npz
[2019-02-09 23:38:28] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-09 23:38:31] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-09 23:38:32] [valid] Ep. 15 : Up. 455000 : ce-mean-words : 1.52267 : new best
[2019-02-09 23:39:10] [valid] Ep. 15 : Up. 455000 : bleu-detok : 26.4131 : stalled 6 times (last best: 26.5813)
[2019-02-09 23:46:43] Ep. 15 : Up. 456000 : Sen. 26,514,917 : Cost 42.92594910 : Time 497.67s : 39897.41 words/s : L.r. 5.6195e-05
[2019-02-09 23:54:22] Ep. 15 : Up. 457000 : Sen. 27,757,298 : Cost 44.27337265 : Time 459.13s : 44308.92 words/s : L.r. 5.6134e-05
[2019-02-10 00:02:01] Ep. 15 : Up. 458000 : Sen. 29,043,795 : Cost 42.85780716 : Time 458.87s : 44324.23 words/s : L.r. 5.6072e-05
[2019-02-10 00:09:38] Ep. 15 : Up. 459000 : Sen. 30,293,038 : Cost 43.79147339 : Time 456.87s : 44199.12 words/s : L.r. 5.6011e-05
[2019-02-10 00:17:13] Ep. 15 : Up. 460000 : Sen. 31,534,312 : Cost 43.65742493 : Time 455.15s : 44058.58 words/s : L.r. 5.5950e-05
[2019-02-10 00:17:13] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-10 00:17:14] Saving model weights and runtime parameters to ./model.npz
[2019-02-10 00:17:15] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-10 00:17:19] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-10 00:17:20] [valid] Ep. 15 : Up. 460000 : ce-mean-words : 1.52193 : new best
[2019-02-10 00:17:57] [valid] Ep. 15 : Up. 460000 : bleu-detok : 26.5335 : stalled 7 times (last best: 26.5813)
[2019-02-10 00:25:35] Ep. 15 : Up. 461000 : Sen. 32,803,028 : Cost 43.40752792 : Time 502.03s : 40467.58 words/s : L.r. 5.5890e-05
[2019-02-10 00:33:14] Ep. 15 : Up. 462000 : Sen. 34,068,731 : Cost 43.34252548 : Time 458.85s : 44158.50 words/s : L.r. 5.5829e-05
[2019-02-10 00:40:53] Ep. 15 : Up. 463000 : Sen. 35,331,315 : Cost 43.40810776 : Time 458.86s : 44179.26 words/s : L.r. 5.5769e-05
[2019-02-10 00:48:31] Ep. 15 : Up. 464000 : Sen. 36,588,349 : Cost 43.69750214 : Time 458.89s : 44179.44 words/s : L.r. 5.5709e-05
[2019-02-10 00:56:08] Ep. 15 : Up. 465000 : Sen. 37,860,161 : Cost 42.95010757 : Time 456.98s : 44122.83 words/s : L.r. 5.5649e-05
[2019-02-10 00:56:08] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-10 00:56:10] Saving model weights and runtime parameters to ./model.npz
[2019-02-10 00:56:11] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-10 00:56:15] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-10 00:56:15] [valid] Ep. 15 : Up. 465000 : ce-mean-words : 1.52079 : new best
[2019-02-10 00:56:51] [valid] Ep. 15 : Up. 465000 : bleu-detok : 26.4945 : stalled 8 times (last best: 26.5813)
[2019-02-10 01:04:25] Ep. 15 : Up. 466000 : Sen. 39,093,918 : Cost 43.65304184 : Time 496.77s : 39964.06 words/s : L.r. 5.5589e-05
[2019-02-10 01:04:35] Seen 39117679 samples
[2019-02-10 01:04:35] Starting epoch 16
[2019-02-10 01:04:35] [data] Shuffling data
[2019-02-10 01:04:37] [data] Done shuffling 39221657 sentences (cached in RAM)
[2019-02-10 01:13:19] Ep. 16 : Up. 467000 : Sen. 1,209,985 : Cost 44.18019867 : Time 534.25s : 37832.29 words/s : L.r. 5.5529e-05
[2019-02-10 01:20:56] Ep. 16 : Up. 468000 : Sen. 2,485,777 : Cost 42.59319305 : Time 456.60s : 44036.96 words/s : L.r. 5.5470e-05
[2019-02-10 01:28:36] Ep. 16 : Up. 469000 : Sen. 3,741,251 : Cost 43.62660980 : Time 459.83s : 44194.51 words/s : L.r. 5.5411e-05
[2019-02-10 01:36:13] Ep. 16 : Up. 470000 : Sen. 5,016,788 : Cost 42.67978668 : Time 456.76s : 44161.03 words/s : L.r. 5.5352e-05
[2019-02-10 01:36:13] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-10 01:36:14] Saving model weights and runtime parameters to ./model.npz
[2019-02-10 01:36:15] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-10 01:36:19] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-10 01:36:19] [valid] Ep. 16 : Up. 470000 : ce-mean-words : 1.52031 : new best
[2019-02-10 01:36:57] [valid] Ep. 16 : Up. 470000 : bleu-detok : 26.4311 : stalled 9 times (last best: 26.5813)
[2019-02-10 01:44:36] Ep. 16 : Up. 471000 : Sen. 6,287,979 : Cost 43.18352509 : Time 503.64s : 40352.09 words/s : L.r. 5.5293e-05
[2019-02-10 01:52:14] Ep. 16 : Up. 472000 : Sen. 7,530,398 : Cost 43.84666061 : Time 457.23s : 44084.12 words/s : L.r. 5.5234e-05
[2019-02-10 01:59:50] Ep. 16 : Up. 473000 : Sen. 8,792,340 : Cost 43.12048340 : Time 456.78s : 44115.97 words/s : L.r. 5.5176e-05
[2019-02-10 02:07:29] Ep. 16 : Up. 474000 : Sen. 10,046,230 : Cost 43.64281082 : Time 458.43s : 44232.94 words/s : L.r. 5.5118e-05
[2019-02-10 02:15:04] Ep. 16 : Up. 475000 : Sen. 11,293,067 : Cost 43.56944656 : Time 455.17s : 44156.83 words/s : L.r. 5.5060e-05
[2019-02-10 02:15:04] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-10 02:15:05] Saving model weights and runtime parameters to ./model.npz
[2019-02-10 02:15:06] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-10 02:15:10] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-10 02:15:11] [valid] Ep. 16 : Up. 475000 : ce-mean-words : 1.52003 : new best
[2019-02-10 02:15:47] [valid] Ep. 16 : Up. 475000 : bleu-detok : 26.5102 : stalled 10 times (last best: 26.5813)
[2019-02-10 02:23:27] Ep. 16 : Up. 476000 : Sen. 12,582,886 : Cost 42.57030106 : Time 502.93s : 40421.44 words/s : L.r. 5.5002e-05
[2019-02-10 02:31:04] Ep. 16 : Up. 477000 : Sen. 13,832,794 : Cost 44.02261353 : Time 457.45s : 44320.03 words/s : L.r. 5.4944e-05
[2019-02-10 02:38:43] Ep. 16 : Up. 478000 : Sen. 15,095,356 : Cost 43.14752197 : Time 458.52s : 44102.21 words/s : L.r. 5.4887e-05
[2019-02-10 02:46:20] Ep. 16 : Up. 479000 : Sen. 16,351,541 : Cost 43.57345581 : Time 457.38s : 44188.27 words/s : L.r. 5.4829e-05
[2019-02-10 02:53:59] Ep. 16 : Up. 480000 : Sen. 17,603,073 : Cost 43.85696411 : Time 458.96s : 44306.64 words/s : L.r. 5.4772e-05
[2019-02-10 02:53:59] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-10 02:54:00] Saving model weights and runtime parameters to ./model.npz
[2019-02-10 02:54:02] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-10 02:54:05] [valid] Ep. 16 : Up. 480000 : ce-mean-words : 1.52015 : stalled 1 times (last best: 1.52003)
[2019-02-10 02:54:41] [valid] Ep. 16 : Up. 480000 : bleu-detok : 26.5479 : stalled 11 times (last best: 26.5813)
[2019-02-10 03:02:21] Ep. 16 : Up. 481000 : Sen. 18,896,667 : Cost 42.43247604 : Time 501.42s : 40414.48 words/s : L.r. 5.4715e-05
[2019-02-10 03:09:58] Ep. 16 : Up. 482000 : Sen. 20,129,124 : Cost 44.38404083 : Time 457.24s : 44193.70 words/s : L.r. 5.4659e-05
[2019-02-10 03:17:36] Ep. 16 : Up. 483000 : Sen. 21,393,457 : Cost 42.92832565 : Time 457.88s : 43924.33 words/s : L.r. 5.4602e-05
[2019-02-10 03:25:14] Ep. 16 : Up. 484000 : Sen. 22,646,237 : Cost 43.89551544 : Time 458.50s : 44357.48 words/s : L.r. 5.4545e-05
[2019-02-10 03:32:51] Ep. 16 : Up. 485000 : Sen. 23,913,227 : Cost 43.17051315 : Time 457.16s : 44241.63 words/s : L.r. 5.4489e-05
[2019-02-10 03:32:51] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-10 03:32:53] Saving model weights and runtime parameters to ./model.npz
[2019-02-10 03:32:54] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-10 03:32:58] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-10 03:32:58] [valid] Ep. 16 : Up. 485000 : ce-mean-words : 1.51912 : new best
[2019-02-10 03:33:35] [valid] Ep. 16 : Up. 485000 : bleu-detok : 26.5625 : stalled 12 times (last best: 26.5813)
[2019-02-10 03:41:10] Ep. 16 : Up. 486000 : Sen. 25,168,807 : Cost 43.24502945 : Time 498.62s : 40217.64 words/s : L.r. 5.4433e-05
[2019-02-10 03:48:46] Ep. 16 : Up. 487000 : Sen. 26,422,736 : Cost 43.42060852 : Time 456.36s : 44165.44 words/s : L.r. 5.4377e-05
[2019-02-10 03:56:23] Ep. 16 : Up. 488000 : Sen. 27,711,361 : Cost 42.40195084 : Time 457.11s : 44193.33 words/s : L.r. 5.4321e-05
[2019-02-10 04:04:02] Ep. 16 : Up. 489000 : Sen. 28,946,808 : Cost 44.43928909 : Time 458.24s : 44356.64 words/s : L.r. 5.4266e-05
[2019-02-10 04:11:37] Ep. 16 : Up. 490000 : Sen. 30,204,691 : Cost 43.14136124 : Time 455.57s : 44058.50 words/s : L.r. 5.4210e-05
[2019-02-10 04:11:37] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-10 04:11:39] Saving model weights and runtime parameters to ./model.npz
[2019-02-10 04:11:40] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-10 04:11:44] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-10 04:11:44] [valid] Ep. 16 : Up. 490000 : ce-mean-words : 1.51828 : new best
[2019-02-10 04:12:21] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-10 04:12:22] [valid] Ep. 16 : Up. 490000 : bleu-detok : 26.6066 : new best
[2019-02-10 04:20:01] Ep. 16 : Up. 491000 : Sen. 31,454,779 : Cost 44.10253525 : Time 503.69s : 40424.34 words/s : L.r. 5.4155e-05
[2019-02-10 04:27:38] Ep. 16 : Up. 492000 : Sen. 32,730,721 : Cost 42.83143616 : Time 456.72s : 44140.70 words/s : L.r. 5.4100e-05
[2019-02-10 04:35:20] Ep. 16 : Up. 493000 : Sen. 33,992,672 : Cost 43.71821594 : Time 461.99s : 44279.36 words/s : L.r. 5.4045e-05
[2019-02-10 04:42:57] Ep. 16 : Up. 494000 : Sen. 35,266,214 : Cost 42.80578613 : Time 457.48s : 44063.59 words/s : L.r. 5.3991e-05
[2019-02-10 04:50:36] Ep. 16 : Up. 495000 : Sen. 36,521,395 : Cost 43.97658539 : Time 458.69s : 44446.67 words/s : L.r. 5.3936e-05
[2019-02-10 04:50:36] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-10 04:50:37] Saving model weights and runtime parameters to ./model.npz
[2019-02-10 04:50:38] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-10 04:50:42] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-10 04:50:43] [valid] Ep. 16 : Up. 495000 : ce-mean-words : 1.51767 : new best
[2019-02-10 04:51:19] [valid] Ep. 16 : Up. 495000 : bleu-detok : 26.5846 : stalled 1 times (last best: 26.6066)
[2019-02-10 04:58:58] Ep. 16 : Up. 496000 : Sen. 37,764,472 : Cost 43.87565994 : Time 501.77s : 40314.06 words/s : L.r. 5.3882e-05
[2019-02-10 05:06:33] Ep. 16 : Up. 497000 : Sen. 39,022,106 : Cost 43.21361923 : Time 454.97s : 44052.21 words/s : L.r. 5.3827e-05
[2019-02-10 05:07:11] Seen 39117679 samples
[2019-02-10 05:07:11] Starting epoch 17
[2019-02-10 05:07:11] [data] Shuffling data
[2019-02-10 05:07:13] [data] Done shuffling 39221657 sentences (cached in RAM)
[2019-02-10 05:15:23] Ep. 17 : Up. 498000 : Sen. 1,135,140 : Cost 43.51827240 : Time 530.76s : 37428.92 words/s : L.r. 5.3773e-05
[2019-02-10 05:23:01] Ep. 17 : Up. 499000 : Sen. 2,393,654 : Cost 43.19773483 : Time 457.36s : 44187.36 words/s : L.r. 5.3719e-05
[2019-02-10 05:30:36] Ep. 17 : Up. 500000 : Sen. 3,652,397 : Cost 43.15182877 : Time 455.28s : 44130.56 words/s : L.r. 5.3666e-05
[2019-02-10 05:30:36] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-10 05:30:37] Saving model weights and runtime parameters to ./model.npz
[2019-02-10 05:30:38] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-10 05:30:42] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-10 05:30:43] [valid] Ep. 17 : Up. 500000 : ce-mean-words : 1.51747 : new best
[2019-02-10 05:31:19] [valid] Ep. 17 : Up. 500000 : bleu-detok : 26.5493 : stalled 2 times (last best: 26.6066)
[2019-02-10 05:38:58] Ep. 17 : Up. 501000 : Sen. 4,915,918 : Cost 43.19682693 : Time 502.23s : 40345.98 words/s : L.r. 5.3612e-05
[2019-02-10 05:46:35] Ep. 17 : Up. 502000 : Sen. 6,186,368 : Cost 42.83074188 : Time 456.72s : 44183.74 words/s : L.r. 5.3559e-05
[2019-02-10 05:54:16] Ep. 17 : Up. 503000 : Sen. 7,444,115 : Cost 43.63976669 : Time 460.68s : 44220.65 words/s : L.r. 5.3505e-05
[2019-02-10 06:01:51] Ep. 17 : Up. 504000 : Sen. 8,691,013 : Cost 43.61069107 : Time 455.75s : 44147.08 words/s : L.r. 5.3452e-05
[2019-02-10 06:09:30] Ep. 17 : Up. 505000 : Sen. 9,958,383 : Cost 43.09852219 : Time 458.19s : 44180.25 words/s : L.r. 5.3399e-05
[2019-02-10 06:09:30] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-10 06:09:31] Saving model weights and runtime parameters to ./model.npz
[2019-02-10 06:09:32] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-10 06:09:36] [valid] Ep. 17 : Up. 505000 : ce-mean-words : 1.51769 : stalled 1 times (last best: 1.51747)
[2019-02-10 06:10:12] [valid] Ep. 17 : Up. 505000 : bleu-detok : 26.489 : stalled 3 times (last best: 26.6066)
[2019-02-10 06:17:50] Ep. 17 : Up. 506000 : Sen. 11,228,340 : Cost 42.98856735 : Time 500.27s : 40429.90 words/s : L.r. 5.3347e-05
[2019-02-10 06:25:27] Ep. 17 : Up. 507000 : Sen. 12,492,495 : Cost 42.91831207 : Time 456.90s : 44098.49 words/s : L.r. 5.3294e-05
[2019-02-10 06:33:06] Ep. 17 : Up. 508000 : Sen. 13,742,330 : Cost 44.00128555 : Time 459.28s : 44350.39 words/s : L.r. 5.3241e-05
[2019-02-10 06:40:42] Ep. 17 : Up. 509000 : Sen. 14,994,360 : Cost 43.44900513 : Time 455.55s : 44206.15 words/s : L.r. 5.3189e-05
[2019-02-10 06:48:17] Ep. 17 : Up. 510000 : Sen. 16,243,428 : Cost 43.37844086 : Time 455.94s : 44096.18 words/s : L.r. 5.3137e-05
[2019-02-10 06:48:17] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-10 06:48:19] Saving model weights and runtime parameters to ./model.npz
[2019-02-10 06:48:20] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-10 06:48:24] [valid] Ep. 17 : Up. 510000 : ce-mean-words : 1.51771 : stalled 2 times (last best: 1.51747)
[2019-02-10 06:49:00] [valid] Ep. 17 : Up. 510000 : bleu-detok : 26.3967 : stalled 4 times (last best: 26.6066)
[2019-02-10 06:56:41] Ep. 17 : Up. 511000 : Sen. 17,514,639 : Cost 43.40818787 : Time 503.13s : 40584.15 words/s : L.r. 5.3085e-05
[2019-02-10 07:04:18] Ep. 17 : Up. 512000 : Sen. 18,777,767 : Cost 43.35709000 : Time 457.17s : 44271.10 words/s : L.r. 5.3033e-05
[2019-02-10 07:11:54] Ep. 17 : Up. 513000 : Sen. 20,033,912 : Cost 43.10122299 : Time 455.96s : 43985.11 words/s : L.r. 5.2981e-05
[2019-02-10 07:19:31] Ep. 17 : Up. 514000 : Sen. 21,291,678 : Cost 43.37059021 : Time 457.39s : 44134.90 words/s : L.r. 5.2930e-05
[2019-02-10 07:27:08] Ep. 17 : Up. 515000 : Sen. 22,555,434 : Cost 43.10477829 : Time 456.81s : 44175.36 words/s : L.r. 5.2878e-05
[2019-02-10 07:27:08] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-10 07:27:09] Saving model weights and runtime parameters to ./model.npz
[2019-02-10 07:27:10] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-10 07:27:14] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-10 07:27:15] [valid] Ep. 17 : Up. 515000 : ce-mean-words : 1.51679 : new best
[2019-02-10 07:27:51] [valid] Ep. 17 : Up. 515000 : bleu-detok : 26.5731 : stalled 5 times (last best: 26.6066)
[2019-02-10 07:35:28] Ep. 17 : Up. 516000 : Sen. 23,809,532 : Cost 43.50323868 : Time 499.97s : 40380.83 words/s : L.r. 5.2827e-05
[2019-02-10 07:43:06] Ep. 17 : Up. 517000 : Sen. 25,059,853 : Cost 43.77185440 : Time 458.24s : 44258.88 words/s : L.r. 5.2776e-05
[2019-02-10 07:50:44] Ep. 17 : Up. 518000 : Sen. 26,304,745 : Cost 43.97307968 : Time 457.99s : 44284.49 words/s : L.r. 5.2725e-05
[2019-02-10 07:58:21] Ep. 17 : Up. 519000 : Sen. 27,585,525 : Cost 42.58463287 : Time 457.06s : 44124.30 words/s : L.r. 5.2674e-05
[2019-02-10 08:06:00] Ep. 17 : Up. 520000 : Sen. 28,839,284 : Cost 43.81457901 : Time 459.17s : 44252.90 words/s : L.r. 5.2623e-05
[2019-02-10 08:06:00] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-10 08:06:02] Saving model weights and runtime parameters to ./model.npz
[2019-02-10 08:06:03] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-10 08:06:07] [valid] Ep. 17 : Up. 520000 : ce-mean-words : 1.51688 : stalled 1 times (last best: 1.51679)
[2019-02-10 08:06:42] [valid] Ep. 17 : Up. 520000 : bleu-detok : 26.5529 : stalled 6 times (last best: 26.6066)
[2019-02-10 08:14:20] Ep. 17 : Up. 521000 : Sen. 30,113,955 : Cost 42.80385590 : Time 499.78s : 40446.94 words/s : L.r. 5.2573e-05
[2019-02-10 08:21:59] Ep. 17 : Up. 522000 : Sen. 31,391,995 : Cost 42.77049255 : Time 458.83s : 44130.83 words/s : L.r. 5.2523e-05
[2019-02-10 08:29:38] Ep. 17 : Up. 523000 : Sen. 32,614,105 : Cost 44.92745972 : Time 458.62s : 44306.08 words/s : L.r. 5.2472e-05
[2019-02-10 08:37:16] Ep. 17 : Up. 524000 : Sen. 33,892,254 : Cost 42.93948364 : Time 458.13s : 44234.09 words/s : L.r. 5.2422e-05
[2019-02-10 08:44:52] Ep. 17 : Up. 525000 : Sen. 35,142,774 : Cost 43.41442108 : Time 456.45s : 44128.50 words/s : L.r. 5.2372e-05
[2019-02-10 08:44:52] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-10 08:44:54] Saving model weights and runtime parameters to ./model.npz
[2019-02-10 08:44:55] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-10 08:44:58] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-10 08:44:59] [valid] Ep. 17 : Up. 525000 : ce-mean-words : 1.51656 : new best
[2019-02-10 08:45:36] [valid] Ep. 17 : Up. 525000 : bleu-detok : 26.4783 : stalled 7 times (last best: 26.6066)
[2019-02-10 08:53:14] Ep. 17 : Up. 526000 : Sen. 36,404,983 : Cost 43.31202316 : Time 501.92s : 40350.11 words/s : L.r. 5.2322e-05
[2019-02-10 09:00:52] Ep. 17 : Up. 527000 : Sen. 37,652,884 : Cost 44.24436951 : Time 458.25s : 44426.20 words/s : L.r. 5.2273e-05
[2019-02-10 09:08:30] Ep. 17 : Up. 528000 : Sen. 38,942,681 : Cost 42.13742065 : Time 457.24s : 44068.63 words/s : L.r. 5.2223e-05
[2019-02-10 09:09:41] Seen 39117679 samples
[2019-02-10 09:09:41] Starting epoch 18
[2019-02-10 09:09:41] [data] Shuffling data
[2019-02-10 09:09:43] [data] Done shuffling 39221657 sentences (cached in RAM)
[2019-02-10 09:17:19] Ep. 18 : Up. 529000 : Sen. 1,055,808 : Cost 43.16960526 : Time 529.66s : 37268.86 words/s : L.r. 5.2174e-05
[2019-02-10 09:24:58] Ep. 18 : Up. 530000 : Sen. 2,314,763 : Cost 43.31007385 : Time 458.80s : 44183.04 words/s : L.r. 5.2125e-05
[2019-02-10 09:24:58] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-10 09:24:59] Saving model weights and runtime parameters to ./model.npz
[2019-02-10 09:25:01] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-10 09:25:05] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-10 09:25:05] [valid] Ep. 18 : Up. 530000 : ce-mean-words : 1.51626 : new best
[2019-02-10 09:25:42] [valid] Ep. 18 : Up. 530000 : bleu-detok : 26.4742 : stalled 8 times (last best: 26.6066)
[2019-02-10 09:33:20] Ep. 18 : Up. 531000 : Sen. 3,568,663 : Cost 43.52521515 : Time 501.55s : 40292.36 words/s : L.r. 5.2076e-05
[2019-02-10 09:40:57] Ep. 18 : Up. 532000 : Sen. 4,827,800 : Cost 43.21937180 : Time 457.26s : 44216.12 words/s : L.r. 5.2027e-05
[2019-02-10 09:48:35] Ep. 18 : Up. 533000 : Sen. 6,095,753 : Cost 42.99209976 : Time 458.09s : 44137.87 words/s : L.r. 5.1978e-05
[2019-02-10 09:56:10] Ep. 18 : Up. 534000 : Sen. 7,339,117 : Cost 43.46069717 : Time 455.04s : 44184.36 words/s : L.r. 5.1929e-05
[2019-02-10 10:03:51] Ep. 18 : Up. 535000 : Sen. 8,622,930 : Cost 42.85703659 : Time 460.99s : 44299.99 words/s : L.r. 5.1881e-05
[2019-02-10 10:03:51] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-10 10:03:52] Saving model weights and runtime parameters to ./model.npz
[2019-02-10 10:03:53] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-10 10:03:57] [valid] Ep. 18 : Up. 535000 : ce-mean-words : 1.51674 : stalled 1 times (last best: 1.51626)
[2019-02-10 10:04:33] [valid] Ep. 18 : Up. 535000 : bleu-detok : 26.5204 : stalled 9 times (last best: 26.6066)
[2019-02-10 10:12:11] Ep. 18 : Up. 536000 : Sen. 9,870,603 : Cost 43.81244278 : Time 499.78s : 40423.71 words/s : L.r. 5.1832e-05
[2019-02-10 10:19:48] Ep. 18 : Up. 537000 : Sen. 11,138,494 : Cost 42.95417023 : Time 457.10s : 44212.04 words/s : L.r. 5.1784e-05
[2019-02-10 10:27:26] Ep. 18 : Up. 538000 : Sen. 12,392,588 : Cost 43.62410355 : Time 458.22s : 44229.46 words/s : L.r. 5.1736e-05
[2019-02-10 10:35:02] Ep. 18 : Up. 539000 : Sen. 13,623,511 : Cost 44.10881805 : Time 456.07s : 44134.07 words/s : L.r. 5.1688e-05
[2019-02-10 10:42:40] Ep. 18 : Up. 540000 : Sen. 14,902,172 : Cost 42.53749466 : Time 457.51s : 44136.89 words/s : L.r. 5.1640e-05
[2019-02-10 10:42:40] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-10 10:42:41] Saving model weights and runtime parameters to ./model.npz
[2019-02-10 10:42:42] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-10 10:42:46] [valid] Ep. 18 : Up. 540000 : ce-mean-words : 1.51643 : stalled 2 times (last best: 1.51626)
[2019-02-10 10:43:23] [valid] Ep. 18 : Up. 540000 : bleu-detok : 26.459 : stalled 10 times (last best: 26.6066)
[2019-02-10 10:51:02] Ep. 18 : Up. 541000 : Sen. 16,162,482 : Cost 43.34375381 : Time 502.62s : 40311.55 words/s : L.r. 5.1592e-05
[2019-02-10 10:58:41] Ep. 18 : Up. 542000 : Sen. 17,410,167 : Cost 44.00449753 : Time 458.28s : 44397.30 words/s : L.r. 5.1544e-05
[2019-02-10 11:06:17] Ep. 18 : Up. 543000 : Sen. 18,674,705 : Cost 42.81727600 : Time 456.45s : 43958.48 words/s : L.r. 5.1497e-05
[2019-02-10 11:13:54] Ep. 18 : Up. 544000 : Sen. 19,947,045 : Cost 42.72029495 : Time 456.54s : 44174.67 words/s : L.r. 5.1450e-05
[2019-02-10 11:21:31] Ep. 18 : Up. 545000 : Sen. 21,205,893 : Cost 43.38077164 : Time 457.51s : 44240.47 words/s : L.r. 5.1402e-05
[2019-02-10 11:21:31] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-10 11:21:32] Saving model weights and runtime parameters to ./model.npz
[2019-02-10 11:21:34] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-10 11:21:37] [valid] Ep. 18 : Up. 545000 : ce-mean-words : 1.51631 : stalled 3 times (last best: 1.51626)
[2019-02-10 11:22:13] [valid] Ep. 18 : Up. 545000 : bleu-detok : 26.5259 : stalled 11 times (last best: 26.6066)
[2019-02-10 11:28:01] [marian] Marian v1.7.7 45d3ce8 2019-02-03 11:18:10 +0000
[2019-02-10 11:28:01] [marian] Running on gpu-e-62 as process 76698 with command line:
[2019-02-10 11:28:01] [marian] /home/cs-grun1/marian/marian-dev/build-176fix/marian --model ./model.npz --type transformer --train-sets /home/cs-grun1/wmt19/data/corpus00.uniq.clean.nrm.csen.en.gz /home/cs-grun1/wmt19/data/corpus00.uniq.clean.nrm.csen.cs.gz --shuffle-in-ram --vocabs ./vocab.encs.spm ./vocab.encs.spm --dim-vocabs 32000 32000 --max-length 120 --mini-batch-fit -w 10000 --mini-batch 1000 --maxi-batch 1000 --devices 0 1 2 3 --sync-sgd --layer-normalization --tied-embeddings-all --exponential-smoothing --transformer-dropout 0.1 --label-smoothing 0.1 --transformer-preprocess n --transformer-postprocess da --transformer-heads 8 --enc-depth 6 --dec-depth 6 --learn-rate 0.0003 --lr-report --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --valid-freq 5000 --save-freq 5000 --disp-freq 1000 --disp-first 10 --valid-metrics ce-mean-words bleu-detok --valid-translation-output ./devset.bpe.cs.output --quiet-translation --valid-sets /home/cs-grun1/wmt19/data/newstest2016.en /home/cs-grun1/wmt19/data/newstest2016.cs --valid-mini-batch 32 --beam-size 8 --normalize 1 --early-stopping 5 --overwrite --keep-best --log ./train.log --valid-log ./valid.log
[2019-02-10 11:28:01] [config] after-batches: 0
[2019-02-10 11:28:01] [config] after-epochs: 0
[2019-02-10 11:28:01] [config] allow-unk: false
[2019-02-10 11:28:01] [config] beam-size: 8
[2019-02-10 11:28:01] [config] bert-class-symbol: "[CLS]"
[2019-02-10 11:28:01] [config] bert-mask-symbol: "[MASK]"
[2019-02-10 11:28:01] [config] bert-masking-fraction: 0.15
[2019-02-10 11:28:01] [config] bert-sep-symbol: "[SEP]"
[2019-02-10 11:28:01] [config] best-deep: false
[2019-02-10 11:28:01] [config] clip-gemm: 0
[2019-02-10 11:28:01] [config] clip-norm: 5
[2019-02-10 11:28:01] [config] cost-type: ce-mean
[2019-02-10 11:28:01] [config] cpu-threads: 0
[2019-02-10 11:28:01] [config] data-weighting: ""
[2019-02-10 11:28:01] [config] data-weighting-type: sentence
[2019-02-10 11:28:01] [config] dec-cell: gru
[2019-02-10 11:28:01] [config] dec-cell-base-depth: 2
[2019-02-10 11:28:01] [config] dec-cell-high-depth: 1
[2019-02-10 11:28:01] [config] dec-depth: 6
[2019-02-10 11:28:01] [config] devices:
[2019-02-10 11:28:01] [config]   - 0
[2019-02-10 11:28:01] [config]   - 1
[2019-02-10 11:28:01] [config]   - 2
[2019-02-10 11:28:01] [config]   - 3
[2019-02-10 11:28:01] [config] dim-emb: 512
[2019-02-10 11:28:01] [config] dim-rnn: 1024
[2019-02-10 11:28:01] [config] dim-vocabs:
[2019-02-10 11:28:01] [config]   - 32000
[2019-02-10 11:28:01] [config]   - 32000
[2019-02-10 11:28:01] [config] disp-first: 10
[2019-02-10 11:28:01] [config] disp-freq: 1000
[2019-02-10 11:28:01] [config] disp-label-counts: false
[2019-02-10 11:28:01] [config] dropout-rnn: 0
[2019-02-10 11:28:01] [config] dropout-src: 0
[2019-02-10 11:28:01] [config] dropout-trg: 0
[2019-02-10 11:28:01] [config] dump-config: ""
[2019-02-10 11:28:01] [config] early-stopping: 5
[2019-02-10 11:28:01] [config] embedding-fix-src: false
[2019-02-10 11:28:01] [config] embedding-fix-trg: false
[2019-02-10 11:28:01] [config] embedding-normalization: false
[2019-02-10 11:28:01] [config] embedding-vectors:
[2019-02-10 11:28:01] [config]   []
[2019-02-10 11:28:01] [config] enc-cell: gru
[2019-02-10 11:28:01] [config] enc-cell-depth: 1
[2019-02-10 11:28:01] [config] enc-depth: 6
[2019-02-10 11:28:01] [config] enc-type: bidirectional
[2019-02-10 11:28:01] [config] exponential-smoothing: 0.0001
[2019-02-10 11:28:01] [config] grad-dropping-momentum: 0
[2019-02-10 11:28:01] [config] grad-dropping-rate: 0
[2019-02-10 11:28:01] [config] grad-dropping-warmup: 100
[2019-02-10 11:28:01] [config] guided-alignment: none
[2019-02-10 11:28:01] [config] guided-alignment-cost: mse
[2019-02-10 11:28:01] [config] guided-alignment-weight: 0.1
[2019-02-10 11:28:01] [config] ignore-model-config: false
[2019-02-10 11:28:01] [config] input-types:
[2019-02-10 11:28:01] [config]   []
[2019-02-10 11:28:01] [config] interpolate-env-vars: false
[2019-02-10 11:28:01] [config] keep-best: true
[2019-02-10 11:28:01] [config] label-smoothing: 0.1
[2019-02-10 11:28:01] [config] layer-normalization: true
[2019-02-10 11:28:01] [config] learn-rate: 0.0003
[2019-02-10 11:28:01] [config] log: ./train.log
[2019-02-10 11:28:01] [config] log-level: info
[2019-02-10 11:28:01] [config] log-time-zone: ""
[2019-02-10 11:28:01] [config] lr-decay: 0
[2019-02-10 11:28:01] [config] lr-decay-freq: 50000
[2019-02-10 11:28:01] [config] lr-decay-inv-sqrt:
[2019-02-10 11:28:01] [config]   - 16000
[2019-02-10 11:28:01] [config] lr-decay-repeat-warmup: false
[2019-02-10 11:28:01] [config] lr-decay-reset-optimizer: false
[2019-02-10 11:28:01] [config] lr-decay-start:
[2019-02-10 11:28:01] [config]   - 10
[2019-02-10 11:28:01] [config]   - 1
[2019-02-10 11:28:01] [config] lr-decay-strategy: epoch+stalled
[2019-02-10 11:28:01] [config] lr-report: true
[2019-02-10 11:28:01] [config] lr-warmup: 16000
[2019-02-10 11:28:01] [config] lr-warmup-at-reload: false
[2019-02-10 11:28:01] [config] lr-warmup-cycle: false
[2019-02-10 11:28:01] [config] lr-warmup-start-rate: 0
[2019-02-10 11:28:01] [config] max-length: 120
[2019-02-10 11:28:01] [config] max-length-crop: false
[2019-02-10 11:28:01] [config] max-length-factor: 3
[2019-02-10 11:28:01] [config] maxi-batch: 1000
[2019-02-10 11:28:01] [config] maxi-batch-sort: trg
[2019-02-10 11:28:01] [config] mini-batch: 1000
[2019-02-10 11:28:01] [config] mini-batch-fit: true
[2019-02-10 11:28:01] [config] mini-batch-fit-step: 10
[2019-02-10 11:28:01] [config] mini-batch-overstuff: 1
[2019-02-10 11:28:01] [config] mini-batch-track-lr: false
[2019-02-10 11:28:01] [config] mini-batch-understuff: 1
[2019-02-10 11:28:01] [config] mini-batch-warmup: 0
[2019-02-10 11:28:01] [config] mini-batch-words: 0
[2019-02-10 11:28:01] [config] mini-batch-words-ref: 0
[2019-02-10 11:28:01] [config] model: ./model.npz
[2019-02-10 11:28:01] [config] multi-loss-type: sum
[2019-02-10 11:28:01] [config] multi-node: false
[2019-02-10 11:28:01] [config] multi-node-overlap: true
[2019-02-10 11:28:01] [config] n-best: false
[2019-02-10 11:28:01] [config] no-nccl: false
[2019-02-10 11:28:01] [config] no-reload: false
[2019-02-10 11:28:01] [config] no-restore-corpus: false
[2019-02-10 11:28:01] [config] no-shuffle: false
[2019-02-10 11:28:01] [config] normalize: 1
[2019-02-10 11:28:01] [config] num-devices: 0
[2019-02-10 11:28:01] [config] optimizer: adam
[2019-02-10 11:28:01] [config] optimizer-delay: 1
[2019-02-10 11:28:01] [config] optimizer-params:
[2019-02-10 11:28:01] [config]   - 0.9
[2019-02-10 11:28:01] [config]   - 0.98
[2019-02-10 11:28:01] [config]   - 1e-09
[2019-02-10 11:28:01] [config] overwrite: true
[2019-02-10 11:28:01] [config] pretrained-model: ""
[2019-02-10 11:28:01] [config] quiet: false
[2019-02-10 11:28:01] [config] quiet-translation: true
[2019-02-10 11:28:01] [config] relative-paths: false
[2019-02-10 11:28:01] [config] right-left: false
[2019-02-10 11:28:01] [config] save-freq: 5000
[2019-02-10 11:28:01] [config] seed: 0
[2019-02-10 11:28:01] [config] sentencepiece-alphas:
[2019-02-10 11:28:01] [config]   []
[2019-02-10 11:28:01] [config] sentencepiece-max-lines: 10000000
[2019-02-10 11:28:01] [config] sentencepiece-options: ""
[2019-02-10 11:28:01] [config] shuffle-in-ram: true
[2019-02-10 11:28:01] [config] skip: false
[2019-02-10 11:28:01] [config] sqlite: ""
[2019-02-10 11:28:01] [config] sqlite-drop: false
[2019-02-10 11:28:01] [config] sync-sgd: true
[2019-02-10 11:28:01] [config] tempdir: /tmp
[2019-02-10 11:28:01] [config] tied-embeddings: false
[2019-02-10 11:28:01] [config] tied-embeddings-all: true
[2019-02-10 11:28:01] [config] tied-embeddings-src: false
[2019-02-10 11:28:01] [config] train-sets:
[2019-02-10 11:28:01] [config]   - /home/cs-grun1/wmt19/data/corpus00.uniq.clean.nrm.csen.en.gz
[2019-02-10 11:28:01] [config]   - /home/cs-grun1/wmt19/data/corpus00.uniq.clean.nrm.csen.cs.gz
[2019-02-10 11:28:01] [config] transformer-aan-activation: swish
[2019-02-10 11:28:01] [config] transformer-aan-depth: 2
[2019-02-10 11:28:01] [config] transformer-aan-nogate: false
[2019-02-10 11:28:01] [config] transformer-decoder-autoreg: self-attention
[2019-02-10 11:28:01] [config] transformer-dim-aan: 2048
[2019-02-10 11:28:01] [config] transformer-dim-ffn: 2048
[2019-02-10 11:28:01] [config] transformer-dropout: 0.1
[2019-02-10 11:28:01] [config] transformer-dropout-attention: 0
[2019-02-10 11:28:01] [config] transformer-dropout-ffn: 0
[2019-02-10 11:28:01] [config] transformer-ffn-activation: swish
[2019-02-10 11:28:01] [config] transformer-ffn-depth: 2
[2019-02-10 11:28:01] [config] transformer-guided-alignment-layer: last
[2019-02-10 11:28:01] [config] transformer-heads: 8
[2019-02-10 11:28:01] [config] transformer-no-projection: false
[2019-02-10 11:28:01] [config] transformer-postprocess: da
[2019-02-10 11:28:01] [config] transformer-postprocess-emb: d
[2019-02-10 11:28:01] [config] transformer-preprocess: n
[2019-02-10 11:28:01] [config] transformer-tied-layers:
[2019-02-10 11:28:01] [config]   []
[2019-02-10 11:28:01] [config] transformer-train-positions: false
[2019-02-10 11:28:01] [config] type: transformer
[2019-02-10 11:28:01] [config] ulr: false
[2019-02-10 11:28:01] [config] ulr-dim-emb: 0
[2019-02-10 11:28:01] [config] ulr-dropout: 0
[2019-02-10 11:28:01] [config] ulr-keys-vectors: ""
[2019-02-10 11:28:01] [config] ulr-query-vectors: ""
[2019-02-10 11:28:01] [config] ulr-softmax-temperature: 1
[2019-02-10 11:28:01] [config] ulr-trainable-transformation: false
[2019-02-10 11:28:01] [config] valid-freq: 5000
[2019-02-10 11:28:01] [config] valid-log: ./valid.log
[2019-02-10 11:28:01] [config] valid-max-length: 1000
[2019-02-10 11:28:01] [config] valid-metrics:
[2019-02-10 11:28:01] [config]   - ce-mean-words
[2019-02-10 11:28:01] [config]   - bleu-detok
[2019-02-10 11:28:01] [config] valid-mini-batch: 32
[2019-02-10 11:28:01] [config] valid-script-path: ""
[2019-02-10 11:28:01] [config] valid-sets:
[2019-02-10 11:28:01] [config]   - /home/cs-grun1/wmt19/data/newstest2016.en
[2019-02-10 11:28:01] [config]   - /home/cs-grun1/wmt19/data/newstest2016.cs
[2019-02-10 11:28:01] [config] valid-translation-output: ./devset.bpe.cs.output
[2019-02-10 11:28:01] [config] version: v1.7.7 45d3ce8 2019-02-03 11:18:10 +0000
[2019-02-10 11:28:01] [config] vocabs:
[2019-02-10 11:28:01] [config]   - ./vocab.encs.spm
[2019-02-10 11:28:01] [config]   - ./vocab.encs.spm
[2019-02-10 11:28:01] [config] word-penalty: 0
[2019-02-10 11:28:01] [config] workspace: 10000
[2019-02-10 11:28:01] [config] Loaded model has been created with Marian v1.7.7 45d3ce8 2019-02-03 11:18:10 +0000
[2019-02-10 11:28:01] Using synchronous training
[2019-02-10 11:28:01] [data] Loading SentencePiece vocabulary from file ./vocab.encs.spm
[2019-02-10 11:28:01] [data] Setting vocabulary size for input 0 to 32000
[2019-02-10 11:28:01] [data] Loading SentencePiece vocabulary from file ./vocab.encs.spm
[2019-02-10 11:28:01] [data] Setting vocabulary size for input 1 to 32000
[2019-02-10 11:28:02] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-02-10 11:28:02] [batching] Collecting statistics for batch fitting with step size 10
[2019-02-10 11:28:02] [memory] Extending reserved space to 10112 MB (device gpu0)
[2019-02-10 11:28:03] [memory] Extending reserved space to 10112 MB (device gpu1)
[2019-02-10 11:28:04] [memory] Extending reserved space to 10112 MB (device gpu2)
[2019-02-10 11:28:04] [memory] Extending reserved space to 10112 MB (device gpu3)
[2019-02-10 11:28:05] [comm] Using NCCL 2.3.7 for GPU communication
[2019-02-10 11:28:05] [comm] NCCLCommunicator constructed successfully.
[2019-02-10 11:28:05] [training] Using 4 GPUs
[2019-02-10 11:28:05] [memory] Reserving 230 MB, device gpu0
[2019-02-10 11:28:05] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-02-10 11:28:05] [memory] Reserving 230 MB, device gpu0
[2019-02-10 11:28:26] [batching] Done. Typical MB size is 27396 target words
[2019-02-10 11:28:26] [memory] Extending reserved space to 10112 MB (device gpu0)
[2019-02-10 11:28:26] [memory] Extending reserved space to 10112 MB (device gpu1)
[2019-02-10 11:28:26] [memory] Extending reserved space to 10112 MB (device gpu2)
[2019-02-10 11:28:26] [memory] Extending reserved space to 10112 MB (device gpu3)
[2019-02-10 11:28:26] [comm] Using NCCL 2.3.7 for GPU communication
[2019-02-10 11:28:26] [comm] NCCLCommunicator constructed successfully.
[2019-02-10 11:28:26] [training] Using 4 GPUs
[2019-02-10 11:28:26] Loading model from ./model.npz.orig.npz
[2019-02-10 11:28:27] Loading model from ./model.npz.orig.npz
[2019-02-10 11:28:27] Loading model from ./model.npz.orig.npz
[2019-02-10 11:28:28] Loading model from ./model.npz.orig.npz
[2019-02-10 11:28:28] Loading Adam parameters from ./model.npz.optimizer.npz
[2019-02-10 11:28:29] [memory] Reserving 115 MB, device gpu0
[2019-02-10 11:28:29] [memory] Reserving 115 MB, device gpu1
[2019-02-10 11:28:29] [memory] Reserving 115 MB, device gpu2
[2019-02-10 11:28:29] [memory] Reserving 115 MB, device gpu3
[2019-02-10 11:28:29] [training] Model reloaded from ./model.npz
[2019-02-10 11:28:29] [data] Restoring the corpus state to epoch 18, batch 545000
[2019-02-10 11:28:29] [data] Shuffling data
[2019-02-10 11:29:08] [data] Done reading 39221657 sentences
[2019-02-10 11:29:10] [data] Done shuffling 39221657 sentences (cached in RAM)
[2019-02-10 11:57:49] Training started
[2019-02-10 11:57:49] [training] Batches are processed as 1 process(es) x 4 devices/process
[2019-02-10 11:57:49] [memory] Reserving 230 MB, device gpu3
[2019-02-10 11:57:49] [memory] Reserving 230 MB, device gpu0
[2019-02-10 11:57:49] [memory] Reserving 230 MB, device gpu2
[2019-02-10 11:57:49] [memory] Reserving 230 MB, device gpu1
[2019-02-10 11:57:49] [memory] Reserving 230 MB, device gpu0
[2019-02-10 11:57:49] [memory] Reserving 230 MB, device gpu3
[2019-02-10 11:57:49] [memory] Reserving 230 MB, device gpu2
[2019-02-10 11:57:49] [memory] Reserving 230 MB, device gpu1
[2019-02-10 11:57:49] Loading model from ./model.npz
[2019-02-10 11:57:50] [memory] Reserving 230 MB, device cpu0
[2019-02-10 11:57:50] [memory] Reserving 57 MB, device gpu0
[2019-02-10 11:57:50] [memory] Reserving 57 MB, device gpu1
[2019-02-10 11:57:50] [memory] Reserving 57 MB, device gpu2
[2019-02-10 11:57:50] [memory] Reserving 57 MB, device gpu3
[2019-02-10 12:05:28] Ep. 18 : Up. 546000 : Sen. 22,447,033 : Cost 44.08633804 : Time 2246.09s : 9035.51 words/s : L.r. 5.1355e-05
[2019-02-10 12:13:03] Ep. 18 : Up. 547000 : Sen. 23,716,911 : Cost 42.58894730 : Time 454.99s : 44041.09 words/s : L.r. 5.1308e-05
[2019-02-10 12:20:40] Ep. 18 : Up. 548000 : Sen. 24,973,609 : Cost 43.51871490 : Time 457.16s : 44360.40 words/s : L.r. 5.1261e-05
[2019-02-10 12:28:18] Ep. 18 : Up. 549000 : Sen. 26,249,015 : Cost 42.78683853 : Time 457.76s : 44148.32 words/s : L.r. 5.1215e-05
[2019-02-10 12:35:55] Ep. 18 : Up. 550000 : Sen. 27,494,798 : Cost 44.03005219 : Time 457.61s : 44374.10 words/s : L.r. 5.1168e-05
[2019-02-10 12:35:55] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-10 12:35:56] Saving model weights and runtime parameters to ./model.npz
[2019-02-10 12:35:58] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-10 12:36:02] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-10 12:36:03] [valid] Ep. 18 : Up. 550000 : ce-mean-words : 1.51559 : new best
[2019-02-10 12:36:40] [valid] Ep. 18 : Up. 550000 : bleu-detok : 26.4778 : stalled 11 times (last best: 26.6066)
[2019-02-10 12:44:18] Ep. 18 : Up. 551000 : Sen. 28,763,125 : Cost 43.15561676 : Time 503.15s : 40301.22 words/s : L.r. 5.1122e-05
[2019-02-10 12:51:55] Ep. 18 : Up. 552000 : Sen. 30,024,456 : Cost 43.16542816 : Time 456.91s : 44194.81 words/s : L.r. 5.1075e-05
[2019-02-10 12:59:32] Ep. 18 : Up. 553000 : Sen. 31,279,716 : Cost 43.24727631 : Time 456.64s : 44192.64 words/s : L.r. 5.1029e-05
[2019-02-10 13:07:12] Ep. 18 : Up. 554000 : Sen. 32,559,707 : Cost 43.09627151 : Time 460.04s : 44271.10 words/s : L.r. 5.0983e-05
[2019-02-10 13:14:50] Ep. 18 : Up. 555000 : Sen. 33,799,791 : Cost 43.90723801 : Time 457.82s : 44145.46 words/s : L.r. 5.0937e-05
[2019-02-10 13:14:50] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-10 13:14:51] Saving model weights and runtime parameters to ./model.npz
[2019-02-10 13:14:52] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-10 13:14:56] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-10 13:14:57] [valid] Ep. 18 : Up. 555000 : ce-mean-words : 1.51491 : new best
[2019-02-10 13:15:33] [valid] Ep. 18 : Up. 555000 : bleu-detok : 26.4976 : stalled 12 times (last best: 26.6066)
[2019-02-10 13:23:13] Ep. 18 : Up. 556000 : Sen. 35,063,592 : Cost 43.49969101 : Time 502.90s : 40413.98 words/s : L.r. 5.0891e-05
[2019-02-10 13:30:51] Ep. 18 : Up. 557000 : Sen. 36,331,494 : Cost 43.02907562 : Time 458.18s : 44166.05 words/s : L.r. 5.0846e-05
[2019-02-10 13:38:28] Ep. 18 : Up. 558000 : Sen. 37,599,345 : Cost 42.93615341 : Time 456.78s : 44214.67 words/s : L.r. 5.0800e-05
[2019-02-10 13:46:04] Ep. 18 : Up. 559000 : Sen. 38,850,677 : Cost 43.71604538 : Time 455.98s : 44294.30 words/s : L.r. 5.0755e-05
[2019-02-10 13:47:48] Seen 39117679 samples
[2019-02-10 13:47:48] Starting epoch 19
[2019-02-10 13:47:48] [data] Shuffling data
[2019-02-10 13:47:50] [data] Done shuffling 39221657 sentences (cached in RAM)
[2019-02-10 13:54:55] Ep. 19 : Up. 560000 : Sen. 959,401 : Cost 43.24028015 : Time 531.51s : 37143.47 words/s : L.r. 5.0709e-05
[2019-02-10 13:54:55] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-10 13:54:56] Saving model weights and runtime parameters to ./model.npz
[2019-02-10 13:54:58] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-10 13:55:01] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-10 13:55:02] [valid] Ep. 19 : Up. 560000 : ce-mean-words : 1.51411 : new best
[2019-02-10 13:55:38] [valid] Ep. 19 : Up. 560000 : bleu-detok : 26.5274 : stalled 13 times (last best: 26.6066)
[2019-02-10 14:03:18] Ep. 19 : Up. 561000 : Sen. 2,233,339 : Cost 42.84401321 : Time 502.72s : 40420.97 words/s : L.r. 5.0664e-05
[2019-02-10 14:10:50] Ep. 19 : Up. 562000 : Sen. 3,486,642 : Cost 42.86227417 : Time 452.29s : 44068.76 words/s : L.r. 5.0619e-05
[2019-02-10 14:18:27] Ep. 19 : Up. 563000 : Sen. 4,712,500 : Cost 44.23413086 : Time 456.43s : 44229.34 words/s : L.r. 5.0574e-05
[2019-02-10 14:26:06] Ep. 19 : Up. 564000 : Sen. 5,986,220 : Cost 42.95314026 : Time 459.73s : 44144.83 words/s : L.r. 5.0529e-05
[2019-02-10 14:33:46] Ep. 19 : Up. 565000 : Sen. 7,238,004 : Cost 43.61602783 : Time 460.20s : 44155.70 words/s : L.r. 5.0484e-05
[2019-02-10 14:33:46] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-10 14:33:48] Saving model weights and runtime parameters to ./model.npz
[2019-02-10 14:33:49] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-10 14:33:53] [valid] Ep. 19 : Up. 565000 : ce-mean-words : 1.51431 : stalled 1 times (last best: 1.51411)
[2019-02-10 14:34:29] [valid] Ep. 19 : Up. 565000 : bleu-detok : 26.4181 : stalled 14 times (last best: 26.6066)
[2019-02-10 14:42:06] Ep. 19 : Up. 566000 : Sen. 8,524,969 : Cost 42.36268616 : Time 499.87s : 40446.85 words/s : L.r. 5.0440e-05
[2019-02-10 14:49:46] Ep. 19 : Up. 567000 : Sen. 9,782,930 : Cost 43.59198761 : Time 459.35s : 44251.29 words/s : L.r. 5.0395e-05
[2019-02-10 14:57:23] Ep. 19 : Up. 568000 : Sen. 11,029,828 : Cost 43.51517105 : Time 456.93s : 44125.91 words/s : L.r. 5.0351e-05
[2019-02-10 15:05:01] Ep. 19 : Up. 569000 : Sen. 12,286,608 : Cost 43.40287399 : Time 458.27s : 44138.86 words/s : L.r. 5.0307e-05
[2019-02-10 15:12:39] Ep. 19 : Up. 570000 : Sen. 13,546,292 : Cost 43.35758972 : Time 457.70s : 44208.91 words/s : L.r. 5.0262e-05
[2019-02-10 15:12:39] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-10 15:12:40] Saving model weights and runtime parameters to ./model.npz
[2019-02-10 15:12:41] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-10 15:12:46] [valid] Ep. 19 : Up. 570000 : ce-mean-words : 1.51457 : stalled 2 times (last best: 1.51411)
[2019-02-10 15:13:23] [valid] Ep. 19 : Up. 570000 : bleu-detok : 26.45 : stalled 15 times (last best: 26.6066)
[2019-02-10 15:20:59] Ep. 19 : Up. 571000 : Sen. 14,808,458 : Cost 42.90668106 : Time 500.79s : 40184.15 words/s : L.r. 5.0218e-05
[2019-02-10 15:28:36] Ep. 19 : Up. 572000 : Sen. 16,061,714 : Cost 43.39147949 : Time 457.07s : 44152.07 words/s : L.r. 5.0175e-05
[2019-02-10 15:36:17] Ep. 19 : Up. 573000 : Sen. 17,318,853 : Cost 43.77838898 : Time 461.01s : 44280.12 words/s : L.r. 5.0131e-05
[2019-02-10 15:43:55] Ep. 19 : Up. 574000 : Sen. 18,594,123 : Cost 42.54938126 : Time 457.59s : 44037.42 words/s : L.r. 5.0087e-05
[2019-02-10 15:51:33] Ep. 19 : Up. 575000 : Sen. 19,848,288 : Cost 43.46902847 : Time 458.25s : 44137.97 words/s : L.r. 5.0043e-05
[2019-02-10 15:51:33] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-10 15:51:35] Saving model weights and runtime parameters to ./model.npz
[2019-02-10 15:51:36] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-10 15:51:40] [valid] Ep. 19 : Up. 575000 : ce-mean-words : 1.51442 : stalled 3 times (last best: 1.51411)
[2019-02-10 15:52:16] [valid] Ep. 19 : Up. 575000 : bleu-detok : 26.4407 : stalled 16 times (last best: 26.6066)
[2019-02-10 15:59:52] Ep. 19 : Up. 576000 : Sen. 21,112,439 : Cost 43.03729248 : Time 498.89s : 40425.44 words/s : L.r. 5.0000e-05
[2019-02-10 16:07:29] Ep. 19 : Up. 577000 : Sen. 22,384,853 : Cost 42.69001007 : Time 457.26s : 44200.85 words/s : L.r. 4.9957e-05
[2019-02-10 16:15:07] Ep. 19 : Up. 578000 : Sen. 23,621,232 : Cost 44.12998581 : Time 457.15s : 44241.97 words/s : L.r. 4.9913e-05
[2019-02-10 16:22:47] Ep. 19 : Up. 579000 : Sen. 24,905,499 : Cost 42.78139114 : Time 460.12s : 44275.07 words/s : L.r. 4.9870e-05
[2019-02-10 16:30:26] Ep. 19 : Up. 580000 : Sen. 26,152,448 : Cost 43.89708328 : Time 459.17s : 44171.32 words/s : L.r. 4.9827e-05
[2019-02-10 16:30:26] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-10 16:30:27] Saving model weights and runtime parameters to ./model.npz
[2019-02-10 16:30:28] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-10 16:30:32] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-10 16:30:33] [valid] Ep. 19 : Up. 580000 : ce-mean-words : 1.51399 : new best
[2019-02-10 16:31:10] [valid] Ep. 19 : Up. 580000 : bleu-detok : 26.5229 : stalled 17 times (last best: 26.6066)
[2019-02-10 16:38:48] Ep. 19 : Up. 581000 : Sen. 27,448,438 : Cost 41.94120407 : Time 501.78s : 40145.89 words/s : L.r. 4.9784e-05
[2019-02-10 16:46:25] Ep. 19 : Up. 582000 : Sen. 28,674,962 : Cost 44.38153458 : Time 457.76s : 44223.51 words/s : L.r. 4.9742e-05
[2019-02-10 16:54:05] Ep. 19 : Up. 583000 : Sen. 29,935,517 : Cost 43.43961334 : Time 459.70s : 44171.08 words/s : L.r. 4.9699e-05
[2019-02-10 17:01:43] Ep. 19 : Up. 584000 : Sen. 31,211,993 : Cost 42.85404587 : Time 457.80s : 44205.76 words/s : L.r. 4.9656e-05
[2019-02-10 17:09:20] Ep. 19 : Up. 585000 : Sen. 32,458,127 : Cost 43.42300797 : Time 456.71s : 44029.78 words/s : L.r. 4.9614e-05
[2019-02-10 17:09:20] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-10 17:09:21] Saving model weights and runtime parameters to ./model.npz
[2019-02-10 17:09:22] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-10 17:09:26] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-10 17:09:27] [valid] Ep. 19 : Up. 585000 : ce-mean-words : 1.51301 : new best
[2019-02-10 17:10:03] [valid] Ep. 19 : Up. 585000 : bleu-detok : 26.4484 : stalled 18 times (last best: 26.6066)
[2019-02-10 17:17:42] Ep. 19 : Up. 586000 : Sen. 33,718,931 : Cost 43.51718903 : Time 502.54s : 40463.03 words/s : L.r. 4.9572e-05
[2019-02-10 17:25:20] Ep. 19 : Up. 587000 : Sen. 34,982,755 : Cost 43.10360718 : Time 457.47s : 44214.13 words/s : L.r. 4.9529e-05
[2019-02-10 17:32:58] Ep. 19 : Up. 588000 : Sen. 36,229,614 : Cost 43.76814270 : Time 458.11s : 44248.87 words/s : L.r. 4.9487e-05
[2019-02-10 17:40:33] Ep. 19 : Up. 589000 : Sen. 37,515,516 : Cost 42.35978317 : Time 455.37s : 44216.81 words/s : L.r. 4.9445e-05
[2019-02-10 17:48:12] Ep. 19 : Up. 590000 : Sen. 38,768,130 : Cost 43.62520218 : Time 458.92s : 44243.09 words/s : L.r. 4.9403e-05
[2019-02-10 17:48:12] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-10 17:48:13] Saving model weights and runtime parameters to ./model.npz
[2019-02-10 17:48:15] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-10 17:48:19] Saving model weights and runtime parameters to ./model.npz.best-ce-mean-words.npz
[2019-02-10 17:48:20] [valid] Ep. 19 : Up. 590000 : ce-mean-words : 1.51264 : new best
[2019-02-10 17:48:56] Saving model weights and runtime parameters to ./model.npz.best-bleu-detok.npz
[2019-02-10 17:48:57] [valid] Ep. 19 : Up. 590000 : bleu-detok : 26.647 : new best
[2019-02-10 17:51:12] Seen 39117679 samples
[2019-02-10 17:51:12] Starting epoch 20
[2019-02-10 17:51:12] [data] Shuffling data
[2019-02-10 17:51:14] [data] Done shuffling 39221657 sentences (cached in RAM)
[2019-02-10 17:57:48] Ep. 20 : Up. 591000 : Sen. 874,648 : Cost 43.52024078 : Time 576.14s : 34316.10 words/s : L.r. 4.9361e-05
[2019-02-10 18:05:28] Ep. 20 : Up. 592000 : Sen. 2,148,940 : Cost 42.97687149 : Time 460.23s : 44288.30 words/s : L.r. 4.9320e-05
[2019-02-10 18:13:06] Ep. 20 : Up. 593000 : Sen. 3,404,478 : Cost 43.34640884 : Time 457.26s : 44287.42 words/s : L.r. 4.9278e-05
[2019-02-10 18:20:42] Ep. 20 : Up. 594000 : Sen. 4,650,290 : Cost 43.49178696 : Time 456.46s : 44094.27 words/s : L.r. 4.9237e-05
[2019-02-10 18:28:20] Ep. 20 : Up. 595000 : Sen. 5,933,058 : Cost 42.42644501 : Time 457.50s : 44242.42 words/s : L.r. 4.9195e-05
[2019-02-10 18:28:20] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-10 18:28:21] Saving model weights and runtime parameters to ./model.npz
[2019-02-10 18:28:22] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-10 18:28:26] [valid] Ep. 20 : Up. 595000 : ce-mean-words : 1.51271 : stalled 1 times (last best: 1.51264)
[2019-02-10 18:29:01] [valid] Ep. 20 : Up. 595000 : bleu-detok : 26.5165 : stalled 1 times (last best: 26.647)
[2019-02-10 18:36:39] Ep. 20 : Up. 596000 : Sen. 7,161,178 : Cost 44.17071533 : Time 499.18s : 40470.19 words/s : L.r. 4.9154e-05
[2019-02-10 18:44:16] Ep. 20 : Up. 597000 : Sen. 8,457,158 : Cost 42.06397629 : Time 457.21s : 44270.27 words/s : L.r. 4.9113e-05
[2019-02-10 18:51:54] Ep. 20 : Up. 598000 : Sen. 9,712,400 : Cost 43.42948532 : Time 457.79s : 44342.29 words/s : L.r. 4.9072e-05
[2019-02-10 18:59:30] Ep. 20 : Up. 599000 : Sen. 10,953,129 : Cost 43.67113876 : Time 456.58s : 44005.43 words/s : L.r. 4.9031e-05
[2019-02-10 19:07:09] Ep. 20 : Up. 600000 : Sen. 12,208,557 : Cost 43.50761795 : Time 458.63s : 44241.32 words/s : L.r. 4.8990e-05
[2019-02-10 19:07:09] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-10 19:07:10] Saving model weights and runtime parameters to ./model.npz
[2019-02-10 19:07:12] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-10 19:07:15] [valid] Ep. 20 : Up. 600000 : ce-mean-words : 1.51352 : stalled 2 times (last best: 1.51264)
[2019-02-10 19:07:52] [valid] Ep. 20 : Up. 600000 : bleu-detok : 26.4821 : stalled 2 times (last best: 26.647)
[2019-02-10 19:15:30] Ep. 20 : Up. 601000 : Sen. 13,467,948 : Cost 43.31322098 : Time 500.65s : 40484.04 words/s : L.r. 4.8949e-05
[2019-02-10 19:23:06] Ep. 20 : Up. 602000 : Sen. 14,743,024 : Cost 42.69271469 : Time 456.23s : 44204.32 words/s : L.r. 4.8908e-05
[2019-02-10 19:30:43] Ep. 20 : Up. 603000 : Sen. 15,993,401 : Cost 43.32486725 : Time 456.87s : 44134.54 words/s : L.r. 4.8868e-05
[2019-02-10 19:38:20] Ep. 20 : Up. 604000 : Sen. 17,262,664 : Cost 42.91037369 : Time 457.16s : 44278.32 words/s : L.r. 4.8827e-05
[2019-02-10 19:45:55] Ep. 20 : Up. 605000 : Sen. 18,498,896 : Cost 43.64625549 : Time 454.81s : 44068.61 words/s : L.r. 4.8787e-05
[2019-02-10 19:45:55] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-10 19:45:56] Saving model weights and runtime parameters to ./model.npz
[2019-02-10 19:45:57] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-10 19:46:01] [valid] Ep. 20 : Up. 605000 : ce-mean-words : 1.51359 : stalled 3 times (last best: 1.51264)
[2019-02-10 19:46:38] [valid] Ep. 20 : Up. 605000 : bleu-detok : 26.562 : stalled 3 times (last best: 26.647)
[2019-02-10 19:54:18] Ep. 20 : Up. 606000 : Sen. 19,765,578 : Cost 43.25961685 : Time 503.43s : 40413.78 words/s : L.r. 4.8747e-05
[2019-02-10 20:01:55] Ep. 20 : Up. 607000 : Sen. 21,023,309 : Cost 43.29119492 : Time 456.58s : 44240.60 words/s : L.r. 4.8707e-05
[2019-02-10 20:09:34] Ep. 20 : Up. 608000 : Sen. 22,271,892 : Cost 43.85436630 : Time 459.19s : 44295.44 words/s : L.r. 4.8666e-05
[2019-02-10 20:17:12] Ep. 20 : Up. 609000 : Sen. 23,538,753 : Cost 42.92383194 : Time 457.77s : 44101.47 words/s : L.r. 4.8626e-05
[2019-02-10 20:24:50] Ep. 20 : Up. 610000 : Sen. 24,801,340 : Cost 43.16939926 : Time 458.47s : 44106.48 words/s : L.r. 4.8587e-05
[2019-02-10 20:24:50] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-10 20:24:51] Saving model weights and runtime parameters to ./model.npz
[2019-02-10 20:24:53] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-10 20:24:57] [valid] Ep. 20 : Up. 610000 : ce-mean-words : 1.51329 : stalled 4 times (last best: 1.51264)
[2019-02-10 20:25:33] [valid] Ep. 20 : Up. 610000 : bleu-detok : 26.5015 : stalled 4 times (last best: 26.647)
[2019-02-10 20:33:09] Ep. 20 : Up. 611000 : Sen. 26,069,047 : Cost 42.80373383 : Time 498.66s : 40397.07 words/s : L.r. 4.8547e-05
[2019-02-10 20:40:48] Ep. 20 : Up. 612000 : Sen. 27,324,286 : Cost 43.59022141 : Time 458.98s : 44313.32 words/s : L.r. 4.8507e-05
[2019-02-10 20:48:23] Ep. 20 : Up. 613000 : Sen. 28,585,926 : Cost 42.82504272 : Time 455.43s : 44020.99 words/s : L.r. 4.8468e-05
[2019-02-10 20:56:00] Ep. 20 : Up. 614000 : Sen. 29,835,827 : Cost 43.59066010 : Time 456.87s : 44249.59 words/s : L.r. 4.8428e-05
[2019-02-10 21:03:38] Ep. 20 : Up. 615000 : Sen. 31,090,348 : Cost 43.55911636 : Time 457.87s : 44304.52 words/s : L.r. 4.8389e-05
[2019-02-10 21:03:38] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-10 21:03:39] Saving model weights and runtime parameters to ./model.npz
[2019-02-10 21:03:41] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-10 21:03:44] [valid] Ep. 20 : Up. 615000 : ce-mean-words : 1.51287 : stalled 5 times (last best: 1.51264)
[2019-02-10 21:04:21] [valid] Ep. 20 : Up. 615000 : bleu-detok : 26.4691 : stalled 5 times (last best: 26.647)
[2019-02-10 21:04:21] Training finished
[2019-02-10 21:04:22] Saving model weights and runtime parameters to ./model.npz.orig.npz
[2019-02-10 21:04:24] Saving model weights and runtime parameters to ./model.npz
[2019-02-10 21:04:25] Saving Adam parameters to ./model.npz.optimizer.npz
[2019-02-10 21:09:13] [marian] Marian v1.7.7 45d3ce8 2019-02-03 11:18:10 +0000
[2019-02-10 21:09:13] [marian] Running on gpu-e-62 as process 156303 with command line:
[2019-02-10 21:09:13] [marian] /home/cs-grun1/marian/marian-dev/build-176fix/marian --model ./model.npz --type transformer --train-sets /home/cs-grun1/wmt19/data/corpus00.uniq.clean.nrm.csen.en.gz /home/cs-grun1/wmt19/data/corpus00.uniq.clean.nrm.csen.cs.gz --shuffle-in-ram --vocabs ./vocab.encs.spm ./vocab.encs.spm --dim-vocabs 32000 32000 --max-length 120 --mini-batch-fit -w 10000 --mini-batch 1000 --maxi-batch 1000 --devices 0 1 2 3 --sync-sgd --layer-normalization --tied-embeddings-all --exponential-smoothing --transformer-dropout 0.1 --label-smoothing 0.1 --transformer-preprocess n --transformer-postprocess da --transformer-heads 8 --enc-depth 6 --dec-depth 6 --learn-rate 0.0003 --lr-report --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --valid-freq 5000 --save-freq 5000 --disp-freq 1000 --disp-first 10 --valid-metrics ce-mean-words bleu-detok --valid-translation-output ./devset.bpe.cs.output --quiet-translation --valid-sets /home/cs-grun1/wmt19/data/newstest2016.en /home/cs-grun1/wmt19/data/newstest2016.cs --valid-mini-batch 32 --beam-size 8 --normalize 1 --early-stopping 5 --overwrite --keep-best --log ./train.log --valid-log ./valid.log
[2019-02-10 21:09:13] [config] after-batches: 0
[2019-02-10 21:09:13] [config] after-epochs: 0
[2019-02-10 21:09:13] [config] allow-unk: false
[2019-02-10 21:09:13] [config] beam-size: 8
[2019-02-10 21:09:13] [config] bert-class-symbol: "[CLS]"
[2019-02-10 21:09:13] [config] bert-mask-symbol: "[MASK]"
[2019-02-10 21:09:13] [config] bert-masking-fraction: 0.15
[2019-02-10 21:09:13] [config] bert-sep-symbol: "[SEP]"
[2019-02-10 21:09:13] [config] best-deep: false
[2019-02-10 21:09:13] [config] clip-gemm: 0
[2019-02-10 21:09:13] [config] clip-norm: 5
[2019-02-10 21:09:13] [config] cost-type: ce-mean
[2019-02-10 21:09:13] [config] cpu-threads: 0
[2019-02-10 21:09:13] [config] data-weighting: ""
[2019-02-10 21:09:13] [config] data-weighting-type: sentence
[2019-02-10 21:09:13] [config] dec-cell: gru
[2019-02-10 21:09:13] [config] dec-cell-base-depth: 2
[2019-02-10 21:09:13] [config] dec-cell-high-depth: 1
[2019-02-10 21:09:13] [config] dec-depth: 6
[2019-02-10 21:09:13] [config] devices:
[2019-02-10 21:09:13] [config]   - 0
[2019-02-10 21:09:13] [config]   - 1
[2019-02-10 21:09:13] [config]   - 2
[2019-02-10 21:09:13] [config]   - 3
[2019-02-10 21:09:13] [config] dim-emb: 512
[2019-02-10 21:09:13] [config] dim-rnn: 1024
[2019-02-10 21:09:13] [config] dim-vocabs:
[2019-02-10 21:09:13] [config]   - 32000
[2019-02-10 21:09:13] [config]   - 32000
[2019-02-10 21:09:13] [config] disp-first: 10
[2019-02-10 21:09:13] [config] disp-freq: 1000
[2019-02-10 21:09:13] [config] disp-label-counts: false
[2019-02-10 21:09:13] [config] dropout-rnn: 0
[2019-02-10 21:09:13] [config] dropout-src: 0
[2019-02-10 21:09:13] [config] dropout-trg: 0
[2019-02-10 21:09:13] [config] dump-config: ""
[2019-02-10 21:09:13] [config] early-stopping: 5
[2019-02-10 21:09:13] [config] embedding-fix-src: false
[2019-02-10 21:09:13] [config] embedding-fix-trg: false
[2019-02-10 21:09:13] [config] embedding-normalization: false
[2019-02-10 21:09:13] [config] embedding-vectors:
[2019-02-10 21:09:13] [config]   []
[2019-02-10 21:09:13] [config] enc-cell: gru
[2019-02-10 21:09:13] [config] enc-cell-depth: 1
[2019-02-10 21:09:13] [config] enc-depth: 6
[2019-02-10 21:09:13] [config] enc-type: bidirectional
[2019-02-10 21:09:13] [config] exponential-smoothing: 0.0001
[2019-02-10 21:09:13] [config] grad-dropping-momentum: 0
[2019-02-10 21:09:13] [config] grad-dropping-rate: 0
[2019-02-10 21:09:13] [config] grad-dropping-warmup: 100
[2019-02-10 21:09:13] [config] guided-alignment: none
[2019-02-10 21:09:13] [config] guided-alignment-cost: mse
[2019-02-10 21:09:13] [config] guided-alignment-weight: 0.1
[2019-02-10 21:09:13] [config] ignore-model-config: false
[2019-02-10 21:09:13] [config] input-types:
[2019-02-10 21:09:13] [config]   []
[2019-02-10 21:09:13] [config] interpolate-env-vars: false
[2019-02-10 21:09:13] [config] keep-best: true
[2019-02-10 21:09:13] [config] label-smoothing: 0.1
[2019-02-10 21:09:13] [config] layer-normalization: true
[2019-02-10 21:09:13] [config] learn-rate: 0.0003
[2019-02-10 21:09:13] [config] log: ./train.log
[2019-02-10 21:09:13] [config] log-level: info
[2019-02-10 21:09:13] [config] log-time-zone: ""
[2019-02-10 21:09:13] [config] lr-decay: 0
[2019-02-10 21:09:13] [config] lr-decay-freq: 50000
[2019-02-10 21:09:13] [config] lr-decay-inv-sqrt:
[2019-02-10 21:09:13] [config]   - 16000
[2019-02-10 21:09:13] [config] lr-decay-repeat-warmup: false
[2019-02-10 21:09:13] [config] lr-decay-reset-optimizer: false
[2019-02-10 21:09:13] [config] lr-decay-start:
[2019-02-10 21:09:13] [config]   - 10
[2019-02-10 21:09:13] [config]   - 1
[2019-02-10 21:09:13] [config] lr-decay-strategy: epoch+stalled
[2019-02-10 21:09:13] [config] lr-report: true
[2019-02-10 21:09:13] [config] lr-warmup: 16000
[2019-02-10 21:09:13] [config] lr-warmup-at-reload: false
[2019-02-10 21:09:13] [config] lr-warmup-cycle: false
[2019-02-10 21:09:13] [config] lr-warmup-start-rate: 0
[2019-02-10 21:09:13] [config] max-length: 120
[2019-02-10 21:09:13] [config] max-length-crop: false
[2019-02-10 21:09:13] [config] max-length-factor: 3
[2019-02-10 21:09:13] [config] maxi-batch: 1000
[2019-02-10 21:09:13] [config] maxi-batch-sort: trg
[2019-02-10 21:09:13] [config] mini-batch: 1000
[2019-02-10 21:09:13] [config] mini-batch-fit: true
[2019-02-10 21:09:13] [config] mini-batch-fit-step: 10
[2019-02-10 21:09:13] [config] mini-batch-overstuff: 1
[2019-02-10 21:09:13] [config] mini-batch-track-lr: false
[2019-02-10 21:09:13] [config] mini-batch-understuff: 1
[2019-02-10 21:09:13] [config] mini-batch-warmup: 0
[2019-02-10 21:09:13] [config] mini-batch-words: 0
[2019-02-10 21:09:13] [config] mini-batch-words-ref: 0
[2019-02-10 21:09:13] [config] model: ./model.npz
[2019-02-10 21:09:13] [config] multi-loss-type: sum
[2019-02-10 21:09:13] [config] multi-node: false
[2019-02-10 21:09:13] [config] multi-node-overlap: true
[2019-02-10 21:09:13] [config] n-best: false
[2019-02-10 21:09:13] [config] no-nccl: false
[2019-02-10 21:09:13] [config] no-reload: false
[2019-02-10 21:09:13] [config] no-restore-corpus: false
[2019-02-10 21:09:13] [config] no-shuffle: false
[2019-02-10 21:09:13] [config] normalize: 1
[2019-02-10 21:09:13] [config] num-devices: 0
[2019-02-10 21:09:13] [config] optimizer: adam
[2019-02-10 21:09:13] [config] optimizer-delay: 1
[2019-02-10 21:09:13] [config] optimizer-params:
[2019-02-10 21:09:13] [config]   - 0.9
[2019-02-10 21:09:13] [config]   - 0.98
[2019-02-10 21:09:13] [config]   - 1e-09
[2019-02-10 21:09:13] [config] overwrite: true
[2019-02-10 21:09:13] [config] pretrained-model: ""
[2019-02-10 21:09:13] [config] quiet: false
[2019-02-10 21:09:13] [config] quiet-translation: true
[2019-02-10 21:09:13] [config] relative-paths: false
[2019-02-10 21:09:13] [config] right-left: false
[2019-02-10 21:09:13] [config] save-freq: 5000
[2019-02-10 21:09:13] [config] seed: 0
[2019-02-10 21:09:13] [config] sentencepiece-alphas:
[2019-02-10 21:09:13] [config]   []
[2019-02-10 21:09:13] [config] sentencepiece-max-lines: 10000000
[2019-02-10 21:09:13] [config] sentencepiece-options: ""
[2019-02-10 21:09:13] [config] shuffle-in-ram: true
[2019-02-10 21:09:13] [config] skip: false
[2019-02-10 21:09:13] [config] sqlite: ""
[2019-02-10 21:09:13] [config] sqlite-drop: false
[2019-02-10 21:09:13] [config] sync-sgd: true
[2019-02-10 21:09:13] [config] tempdir: /tmp
[2019-02-10 21:09:13] [config] tied-embeddings: false
[2019-02-10 21:09:13] [config] tied-embeddings-all: true
[2019-02-10 21:09:13] [config] tied-embeddings-src: false
[2019-02-10 21:09:13] [config] train-sets:
[2019-02-10 21:09:13] [config]   - /home/cs-grun1/wmt19/data/corpus00.uniq.clean.nrm.csen.en.gz
[2019-02-10 21:09:13] [config]   - /home/cs-grun1/wmt19/data/corpus00.uniq.clean.nrm.csen.cs.gz
[2019-02-10 21:09:13] [config] transformer-aan-activation: swish
[2019-02-10 21:09:13] [config] transformer-aan-depth: 2
[2019-02-10 21:09:13] [config] transformer-aan-nogate: false
[2019-02-10 21:09:13] [config] transformer-decoder-autoreg: self-attention
[2019-02-10 21:09:13] [config] transformer-dim-aan: 2048
[2019-02-10 21:09:13] [config] transformer-dim-ffn: 2048
[2019-02-10 21:09:13] [config] transformer-dropout: 0.1
[2019-02-10 21:09:13] [config] transformer-dropout-attention: 0
[2019-02-10 21:09:13] [config] transformer-dropout-ffn: 0
[2019-02-10 21:09:13] [config] transformer-ffn-activation: swish
[2019-02-10 21:09:13] [config] transformer-ffn-depth: 2
[2019-02-10 21:09:13] [config] transformer-guided-alignment-layer: last
[2019-02-10 21:09:13] [config] transformer-heads: 8
[2019-02-10 21:09:13] [config] transformer-no-projection: false
[2019-02-10 21:09:13] [config] transformer-postprocess: da
[2019-02-10 21:09:13] [config] transformer-postprocess-emb: d
[2019-02-10 21:09:13] [config] transformer-preprocess: n
[2019-02-10 21:09:13] [config] transformer-tied-layers:
[2019-02-10 21:09:13] [config]   []
[2019-02-10 21:09:13] [config] transformer-train-positions: false
[2019-02-10 21:09:13] [config] type: transformer
[2019-02-10 21:09:13] [config] ulr: false
[2019-02-10 21:09:13] [config] ulr-dim-emb: 0
[2019-02-10 21:09:13] [config] ulr-dropout: 0
[2019-02-10 21:09:13] [config] ulr-keys-vectors: ""
[2019-02-10 21:09:13] [config] ulr-query-vectors: ""
[2019-02-10 21:09:13] [config] ulr-softmax-temperature: 1
[2019-02-10 21:09:13] [config] ulr-trainable-transformation: false
[2019-02-10 21:09:13] [config] valid-freq: 5000
[2019-02-10 21:09:13] [config] valid-log: ./valid.log
[2019-02-10 21:09:13] [config] valid-max-length: 1000
[2019-02-10 21:09:13] [config] valid-metrics:
[2019-02-10 21:09:13] [config]   - ce-mean-words
[2019-02-10 21:09:13] [config]   - bleu-detok
[2019-02-10 21:09:13] [config] valid-mini-batch: 32
[2019-02-10 21:09:13] [config] valid-script-path: ""
[2019-02-10 21:09:13] [config] valid-sets:
[2019-02-10 21:09:13] [config]   - /home/cs-grun1/wmt19/data/newstest2016.en
[2019-02-10 21:09:13] [config]   - /home/cs-grun1/wmt19/data/newstest2016.cs
[2019-02-10 21:09:13] [config] valid-translation-output: ./devset.bpe.cs.output
[2019-02-10 21:09:13] [config] version: v1.7.7 45d3ce8 2019-02-03 11:18:10 +0000
[2019-02-10 21:09:13] [config] vocabs:
[2019-02-10 21:09:13] [config]   - ./vocab.encs.spm
[2019-02-10 21:09:13] [config]   - ./vocab.encs.spm
[2019-02-10 21:09:13] [config] word-penalty: 0
[2019-02-10 21:09:13] [config] workspace: 10000
[2019-02-10 21:09:13] [config] Loaded model has been created with Marian v1.7.7 45d3ce8 2019-02-03 11:18:10 +0000
[2019-02-10 21:09:13] Using synchronous training
[2019-02-10 21:09:13] [data] Loading SentencePiece vocabulary from file ./vocab.encs.spm
[2019-02-10 21:09:13] [data] Setting vocabulary size for input 0 to 32000
[2019-02-10 21:09:13] [data] Loading SentencePiece vocabulary from file ./vocab.encs.spm
[2019-02-10 21:09:13] [data] Setting vocabulary size for input 1 to 32000
[2019-02-10 21:09:13] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-02-10 21:09:13] [batching] Collecting statistics for batch fitting with step size 10
[2019-02-10 21:09:14] [memory] Extending reserved space to 10112 MB (device gpu0)
[2019-02-10 21:09:14] [memory] Extending reserved space to 10112 MB (device gpu1)
[2019-02-10 21:09:15] [memory] Extending reserved space to 10112 MB (device gpu2)
[2019-02-10 21:09:16] [memory] Extending reserved space to 10112 MB (device gpu3)
[2019-02-10 21:09:16] [comm] Using NCCL 2.3.7 for GPU communication
[2019-02-10 21:09:16] [comm] NCCLCommunicator constructed successfully.
[2019-02-10 21:09:16] [training] Using 4 GPUs
[2019-02-10 21:09:16] [memory] Reserving 230 MB, device gpu0
[2019-02-10 21:09:16] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-02-10 21:09:16] [memory] Reserving 230 MB, device gpu0
[2019-02-10 21:09:37] [batching] Done. Typical MB size is 27396 target words
[2019-02-10 21:09:37] [memory] Extending reserved space to 10112 MB (device gpu0)
[2019-02-10 21:09:37] [memory] Extending reserved space to 10112 MB (device gpu1)
[2019-02-10 21:09:37] [memory] Extending reserved space to 10112 MB (device gpu2)
[2019-02-10 21:09:37] [memory] Extending reserved space to 10112 MB (device gpu3)
[2019-02-10 21:09:37] [comm] Using NCCL 2.3.7 for GPU communication
[2019-02-10 21:09:37] [comm] NCCLCommunicator constructed successfully.
[2019-02-10 21:09:37] [training] Using 4 GPUs
[2019-02-10 21:09:37] Loading model from ./model.npz.orig.npz
[2019-02-10 21:09:38] Loading model from ./model.npz.orig.npz
[2019-02-10 21:09:38] Loading model from ./model.npz.orig.npz
[2019-02-10 21:09:39] Loading model from ./model.npz.orig.npz
[2019-02-10 21:09:39] Loading Adam parameters from ./model.npz.optimizer.npz
[2019-02-10 21:09:39] [memory] Reserving 115 MB, device gpu0
[2019-02-10 21:09:39] [memory] Reserving 115 MB, device gpu1
[2019-02-10 21:09:39] [memory] Reserving 115 MB, device gpu2
[2019-02-10 21:09:39] [memory] Reserving 115 MB, device gpu3
[2019-02-10 21:09:39] [training] Model reloaded from ./model.npz
[2019-02-10 21:09:39] [data] Restoring the corpus state to epoch 20, batch 615000
[2019-02-10 21:09:39] [data] Shuffling data
[2019-02-10 21:10:18] [data] Done reading 39221657 sentences
[2019-02-10 21:10:20] [data] Done shuffling 39221657 sentences (cached in RAM)
[2019-02-10 21:51:26] Training started
[2019-02-10 21:51:26] Training finished
[2019-02-10 21:55:46] [marian] Marian v1.7.7 45d3ce8 2019-02-03 11:18:10 +0000
[2019-02-10 21:55:46] [marian] Running on gpu-e-62 as process 163277 with command line:
[2019-02-10 21:55:46] [marian] /home/cs-grun1/marian/marian-dev/build-176fix/marian --model ./model.npz --type transformer --train-sets /home/cs-grun1/wmt19/data/corpus00.uniq.clean.nrm.csen.en.gz /home/cs-grun1/wmt19/data/corpus00.uniq.clean.nrm.csen.cs.gz --shuffle-in-ram --vocabs ./vocab.encs.spm ./vocab.encs.spm --dim-vocabs 32000 32000 --max-length 120 --mini-batch-fit -w 10000 --mini-batch 1000 --maxi-batch 1000 --devices 0 1 2 3 --sync-sgd --layer-normalization --tied-embeddings-all --exponential-smoothing --transformer-dropout 0.1 --label-smoothing 0.1 --transformer-preprocess n --transformer-postprocess da --transformer-heads 8 --enc-depth 6 --dec-depth 6 --learn-rate 0.0003 --lr-report --lr-warmup 16000 --lr-decay-inv-sqrt 16000 --optimizer-params 0.9 0.98 1e-09 --clip-norm 5 --valid-freq 5000 --save-freq 5000 --disp-freq 1000 --disp-first 10 --valid-metrics ce-mean-words bleu-detok --valid-translation-output ./devset.bpe.cs.output --quiet-translation --valid-sets /home/cs-grun1/wmt19/data/newstest2016.en /home/cs-grun1/wmt19/data/newstest2016.cs --valid-mini-batch 32 --beam-size 8 --normalize 1 --early-stopping 5 --overwrite --keep-best --log ./train.log --valid-log ./valid.log
[2019-02-10 21:55:46] [config] after-batches: 0
[2019-02-10 21:55:46] [config] after-epochs: 0
[2019-02-10 21:55:46] [config] allow-unk: false
[2019-02-10 21:55:46] [config] beam-size: 8
[2019-02-10 21:55:46] [config] bert-class-symbol: "[CLS]"
[2019-02-10 21:55:46] [config] bert-mask-symbol: "[MASK]"
[2019-02-10 21:55:46] [config] bert-masking-fraction: 0.15
[2019-02-10 21:55:46] [config] bert-sep-symbol: "[SEP]"
[2019-02-10 21:55:46] [config] best-deep: false
[2019-02-10 21:55:46] [config] clip-gemm: 0
[2019-02-10 21:55:46] [config] clip-norm: 5
[2019-02-10 21:55:46] [config] cost-type: ce-mean
[2019-02-10 21:55:46] [config] cpu-threads: 0
[2019-02-10 21:55:46] [config] data-weighting: ""
[2019-02-10 21:55:46] [config] data-weighting-type: sentence
[2019-02-10 21:55:46] [config] dec-cell: gru
[2019-02-10 21:55:46] [config] dec-cell-base-depth: 2
[2019-02-10 21:55:46] [config] dec-cell-high-depth: 1
[2019-02-10 21:55:46] [config] dec-depth: 6
[2019-02-10 21:55:46] [config] devices:
[2019-02-10 21:55:46] [config]   - 0
[2019-02-10 21:55:46] [config]   - 1
[2019-02-10 21:55:46] [config]   - 2
[2019-02-10 21:55:46] [config]   - 3
[2019-02-10 21:55:46] [config] dim-emb: 512
[2019-02-10 21:55:46] [config] dim-rnn: 1024
[2019-02-10 21:55:46] [config] dim-vocabs:
[2019-02-10 21:55:46] [config]   - 32000
[2019-02-10 21:55:46] [config]   - 32000
[2019-02-10 21:55:46] [config] disp-first: 10
[2019-02-10 21:55:46] [config] disp-freq: 1000
[2019-02-10 21:55:46] [config] disp-label-counts: false
[2019-02-10 21:55:46] [config] dropout-rnn: 0
[2019-02-10 21:55:46] [config] dropout-src: 0
[2019-02-10 21:55:46] [config] dropout-trg: 0
[2019-02-10 21:55:46] [config] dump-config: ""
[2019-02-10 21:55:46] [config] early-stopping: 5
[2019-02-10 21:55:46] [config] embedding-fix-src: false
[2019-02-10 21:55:46] [config] embedding-fix-trg: false
[2019-02-10 21:55:46] [config] embedding-normalization: false
[2019-02-10 21:55:46] [config] embedding-vectors:
[2019-02-10 21:55:46] [config]   []
[2019-02-10 21:55:46] [config] enc-cell: gru
[2019-02-10 21:55:46] [config] enc-cell-depth: 1
[2019-02-10 21:55:46] [config] enc-depth: 6
[2019-02-10 21:55:46] [config] enc-type: bidirectional
[2019-02-10 21:55:46] [config] exponential-smoothing: 0.0001
[2019-02-10 21:55:46] [config] grad-dropping-momentum: 0
[2019-02-10 21:55:46] [config] grad-dropping-rate: 0
[2019-02-10 21:55:46] [config] grad-dropping-warmup: 100
[2019-02-10 21:55:46] [config] guided-alignment: none
[2019-02-10 21:55:46] [config] guided-alignment-cost: mse
[2019-02-10 21:55:46] [config] guided-alignment-weight: 0.1
[2019-02-10 21:55:46] [config] ignore-model-config: false
[2019-02-10 21:55:46] [config] input-types:
[2019-02-10 21:55:46] [config]   []
[2019-02-10 21:55:46] [config] interpolate-env-vars: false
[2019-02-10 21:55:46] [config] keep-best: true
[2019-02-10 21:55:46] [config] label-smoothing: 0.1
[2019-02-10 21:55:46] [config] layer-normalization: true
[2019-02-10 21:55:46] [config] learn-rate: 0.0003
[2019-02-10 21:55:46] [config] log: ./train.log
[2019-02-10 21:55:46] [config] log-level: info
[2019-02-10 21:55:46] [config] log-time-zone: ""
[2019-02-10 21:55:46] [config] lr-decay: 0
[2019-02-10 21:55:46] [config] lr-decay-freq: 50000
[2019-02-10 21:55:46] [config] lr-decay-inv-sqrt:
[2019-02-10 21:55:46] [config]   - 16000
[2019-02-10 21:55:46] [config] lr-decay-repeat-warmup: false
[2019-02-10 21:55:46] [config] lr-decay-reset-optimizer: false
[2019-02-10 21:55:46] [config] lr-decay-start:
[2019-02-10 21:55:46] [config]   - 10
[2019-02-10 21:55:46] [config]   - 1
[2019-02-10 21:55:46] [config] lr-decay-strategy: epoch+stalled
[2019-02-10 21:55:46] [config] lr-report: true
[2019-02-10 21:55:46] [config] lr-warmup: 16000
[2019-02-10 21:55:46] [config] lr-warmup-at-reload: false
[2019-02-10 21:55:46] [config] lr-warmup-cycle: false
[2019-02-10 21:55:46] [config] lr-warmup-start-rate: 0
[2019-02-10 21:55:46] [config] max-length: 120
[2019-02-10 21:55:46] [config] max-length-crop: false
[2019-02-10 21:55:46] [config] max-length-factor: 3
[2019-02-10 21:55:46] [config] maxi-batch: 1000
[2019-02-10 21:55:46] [config] maxi-batch-sort: trg
[2019-02-10 21:55:46] [config] mini-batch: 1000
[2019-02-10 21:55:46] [config] mini-batch-fit: true
[2019-02-10 21:55:46] [config] mini-batch-fit-step: 10
[2019-02-10 21:55:46] [config] mini-batch-overstuff: 1
[2019-02-10 21:55:46] [config] mini-batch-track-lr: false
[2019-02-10 21:55:46] [config] mini-batch-understuff: 1
[2019-02-10 21:55:46] [config] mini-batch-warmup: 0
[2019-02-10 21:55:46] [config] mini-batch-words: 0
[2019-02-10 21:55:46] [config] mini-batch-words-ref: 0
[2019-02-10 21:55:46] [config] model: ./model.npz
[2019-02-10 21:55:46] [config] multi-loss-type: sum
[2019-02-10 21:55:46] [config] multi-node: false
[2019-02-10 21:55:46] [config] multi-node-overlap: true
[2019-02-10 21:55:46] [config] n-best: false
[2019-02-10 21:55:46] [config] no-nccl: false
[2019-02-10 21:55:46] [config] no-reload: false
[2019-02-10 21:55:46] [config] no-restore-corpus: false
[2019-02-10 21:55:46] [config] no-shuffle: false
[2019-02-10 21:55:46] [config] normalize: 1
[2019-02-10 21:55:46] [config] num-devices: 0
[2019-02-10 21:55:46] [config] optimizer: adam
[2019-02-10 21:55:46] [config] optimizer-delay: 1
[2019-02-10 21:55:46] [config] optimizer-params:
[2019-02-10 21:55:46] [config]   - 0.9
[2019-02-10 21:55:46] [config]   - 0.98
[2019-02-10 21:55:46] [config]   - 1e-09
[2019-02-10 21:55:46] [config] overwrite: true
[2019-02-10 21:55:46] [config] pretrained-model: ""
[2019-02-10 21:55:46] [config] quiet: false
[2019-02-10 21:55:46] [config] quiet-translation: true
[2019-02-10 21:55:46] [config] relative-paths: false
[2019-02-10 21:55:46] [config] right-left: false
[2019-02-10 21:55:46] [config] save-freq: 5000
[2019-02-10 21:55:46] [config] seed: 0
[2019-02-10 21:55:46] [config] sentencepiece-alphas:
[2019-02-10 21:55:46] [config]   []
[2019-02-10 21:55:46] [config] sentencepiece-max-lines: 10000000
[2019-02-10 21:55:46] [config] sentencepiece-options: ""
[2019-02-10 21:55:46] [config] shuffle-in-ram: true
[2019-02-10 21:55:46] [config] skip: false
[2019-02-10 21:55:46] [config] sqlite: ""
[2019-02-10 21:55:46] [config] sqlite-drop: false
[2019-02-10 21:55:46] [config] sync-sgd: true
[2019-02-10 21:55:46] [config] tempdir: /tmp
[2019-02-10 21:55:46] [config] tied-embeddings: false
[2019-02-10 21:55:46] [config] tied-embeddings-all: true
[2019-02-10 21:55:46] [config] tied-embeddings-src: false
[2019-02-10 21:55:46] [config] train-sets:
[2019-02-10 21:55:46] [config]   - /home/cs-grun1/wmt19/data/corpus00.uniq.clean.nrm.csen.en.gz
[2019-02-10 21:55:46] [config]   - /home/cs-grun1/wmt19/data/corpus00.uniq.clean.nrm.csen.cs.gz
[2019-02-10 21:55:46] [config] transformer-aan-activation: swish
[2019-02-10 21:55:46] [config] transformer-aan-depth: 2
[2019-02-10 21:55:46] [config] transformer-aan-nogate: false
[2019-02-10 21:55:46] [config] transformer-decoder-autoreg: self-attention
[2019-02-10 21:55:46] [config] transformer-dim-aan: 2048
[2019-02-10 21:55:46] [config] transformer-dim-ffn: 2048
[2019-02-10 21:55:46] [config] transformer-dropout: 0.1
[2019-02-10 21:55:46] [config] transformer-dropout-attention: 0
[2019-02-10 21:55:46] [config] transformer-dropout-ffn: 0
[2019-02-10 21:55:46] [config] transformer-ffn-activation: swish
[2019-02-10 21:55:46] [config] transformer-ffn-depth: 2
[2019-02-10 21:55:46] [config] transformer-guided-alignment-layer: last
[2019-02-10 21:55:46] [config] transformer-heads: 8
[2019-02-10 21:55:46] [config] transformer-no-projection: false
[2019-02-10 21:55:46] [config] transformer-postprocess: da
[2019-02-10 21:55:46] [config] transformer-postprocess-emb: d
[2019-02-10 21:55:46] [config] transformer-preprocess: n
[2019-02-10 21:55:46] [config] transformer-tied-layers:
[2019-02-10 21:55:46] [config]   []
[2019-02-10 21:55:46] [config] transformer-train-positions: false
[2019-02-10 21:55:46] [config] type: transformer
[2019-02-10 21:55:46] [config] ulr: false
[2019-02-10 21:55:46] [config] ulr-dim-emb: 0
[2019-02-10 21:55:46] [config] ulr-dropout: 0
[2019-02-10 21:55:46] [config] ulr-keys-vectors: ""
[2019-02-10 21:55:46] [config] ulr-query-vectors: ""
[2019-02-10 21:55:46] [config] ulr-softmax-temperature: 1
[2019-02-10 21:55:46] [config] ulr-trainable-transformation: false
[2019-02-10 21:55:46] [config] valid-freq: 5000
[2019-02-10 21:55:46] [config] valid-log: ./valid.log
[2019-02-10 21:55:46] [config] valid-max-length: 1000
[2019-02-10 21:55:46] [config] valid-metrics:
[2019-02-10 21:55:46] [config]   - ce-mean-words
[2019-02-10 21:55:46] [config]   - bleu-detok
[2019-02-10 21:55:46] [config] valid-mini-batch: 32
[2019-02-10 21:55:46] [config] valid-script-path: ""
[2019-02-10 21:55:46] [config] valid-sets:
[2019-02-10 21:55:46] [config]   - /home/cs-grun1/wmt19/data/newstest2016.en
[2019-02-10 21:55:46] [config]   - /home/cs-grun1/wmt19/data/newstest2016.cs
[2019-02-10 21:55:46] [config] valid-translation-output: ./devset.bpe.cs.output
[2019-02-10 21:55:46] [config] version: v1.7.7 45d3ce8 2019-02-03 11:18:10 +0000
[2019-02-10 21:55:46] [config] vocabs:
[2019-02-10 21:55:46] [config]   - ./vocab.encs.spm
[2019-02-10 21:55:46] [config]   - ./vocab.encs.spm
[2019-02-10 21:55:46] [config] word-penalty: 0
[2019-02-10 21:55:46] [config] workspace: 10000
[2019-02-10 21:55:46] [config] Loaded model has been created with Marian v1.7.7 45d3ce8 2019-02-03 11:18:10 +0000
[2019-02-10 21:55:46] Using synchronous training
[2019-02-10 21:55:46] [data] Loading SentencePiece vocabulary from file ./vocab.encs.spm
[2019-02-10 21:55:46] [data] Setting vocabulary size for input 0 to 32000
[2019-02-10 21:55:46] [data] Loading SentencePiece vocabulary from file ./vocab.encs.spm
[2019-02-10 21:55:46] [data] Setting vocabulary size for input 1 to 32000
[2019-02-10 21:55:46] Compiled without MPI support. Falling back to FakeMPIWrapper
[2019-02-10 21:55:46] [batching] Collecting statistics for batch fitting with step size 10
[2019-02-10 21:55:47] [memory] Extending reserved space to 10112 MB (device gpu0)
[2019-02-10 21:55:47] [memory] Extending reserved space to 10112 MB (device gpu1)
[2019-02-10 21:55:48] [memory] Extending reserved space to 10112 MB (device gpu2)
[2019-02-10 21:55:49] [memory] Extending reserved space to 10112 MB (device gpu3)
[2019-02-10 21:55:49] [comm] Using NCCL 2.3.7 for GPU communication
[2019-02-10 21:55:49] [comm] NCCLCommunicator constructed successfully.
[2019-02-10 21:55:49] [training] Using 4 GPUs
[2019-02-10 21:55:49] [memory] Reserving 230 MB, device gpu0
[2019-02-10 21:55:49] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2019-02-10 21:55:49] [memory] Reserving 230 MB, device gpu0
[2019-02-10 21:56:10] [batching] Done. Typical MB size is 27396 target words
[2019-02-10 21:56:10] [memory] Extending reserved space to 10112 MB (device gpu0)
[2019-02-10 21:56:10] [memory] Extending reserved space to 10112 MB (device gpu1)
[2019-02-10 21:56:10] [memory] Extending reserved space to 10112 MB (device gpu2)
[2019-02-10 21:56:10] [memory] Extending reserved space to 10112 MB (device gpu3)
[2019-02-10 21:56:10] [comm] Using NCCL 2.3.7 for GPU communication
[2019-02-10 21:56:10] [comm] NCCLCommunicator constructed successfully.
[2019-02-10 21:56:10] [training] Using 4 GPUs
[2019-02-10 21:56:10] Loading model from ./model.npz.orig.npz
[2019-02-10 21:56:11] Loading model from ./model.npz.orig.npz
[2019-02-10 21:56:11] Loading model from ./model.npz.orig.npz
[2019-02-10 21:56:12] Loading model from ./model.npz.orig.npz
[2019-02-10 21:56:12] Loading Adam parameters from ./model.npz.optimizer.npz
[2019-02-10 21:56:13] [memory] Reserving 115 MB, device gpu0
[2019-02-10 21:56:13] [memory] Reserving 115 MB, device gpu1
[2019-02-10 21:56:13] [memory] Reserving 115 MB, device gpu2
[2019-02-10 21:56:13] [memory] Reserving 115 MB, device gpu3
[2019-02-10 21:56:13] [training] Model reloaded from ./model.npz
[2019-02-10 21:56:13] [data] Restoring the corpus state to epoch 20, batch 615000
[2019-02-10 21:56:13] [data] Shuffling data
[2019-02-10 21:56:51] [data] Done reading 39221657 sentences
[2019-02-10 21:56:53] [data] Done shuffling 39221657 sentences (cached in RAM)
[2019-02-10 22:38:06] Training started
[2019-02-10 22:38:06] Training finished
